(Files content cropped to 300k characters)

================================================
FILE: README.md
================================================
<div style="display:flex;flex-direction:column;">
  <a href="https://oisy.com/">
    <img src="./src/frontend/static/images/meta-share-v3.jpg" alt="OISY Wallet logo" role="presentation"/>
  </a>

<br/>
<br/>

[![Internet Computer portal](https://img.shields.io/badge/Internet-Computer-grey?logo=internet%20computer)](https://internetcomputer.org)
[![GitHub Backend Tests Workflow Status](https://img.shields.io/github/actions/workflow/status/dfinity/oisy-wallet/backend-tests.yml?logo=github&label=Backend%20Tests)](https://github.com/dfinity/oisy-wallet/actions/workflows/backend-tests.yml)
[![GitHub Frontend Tests Workflow Status](https://img.shields.io/github/actions/workflow/status/dfinity/oisy-wallet/frontend-checks.yml?logo=github&label=Frontend%20Tests)](https://github.com/dfinity/oisy-wallet/actions/workflows/frontend-checks.yml)

</div>

---

## What is the OISY wallet

OISY is a new browser-based, network-custodial and multi-chain wallet powered by Internet Computer's [chain fusion](https://internetcomputer.org/chainfusion) technology.

## Features

The OISY wallet provides a convenient user experience known from custodial wallets but without their strong trust assumptions. In contrast, OISY provides trust assumptions based on network custody, and comparable to self-custody. Different from self-custody wallets though, OISY requires no browser extensions or additional mobile app, a standard off-the-shelf web browser is sufficient. In conclusion, OISY provides an attractive user experience with a low entry barrier, yet requires no strong trust assumptions.

Building on ICP, OISY achieves a unique set of features:

- **Browser-based:** no matter your browser and operating system preferences, OISY allows you to receive, hold, and send native ICP, ICRC-1, ETH, ERC20 (and in the near future BTC).

- **Cross-device:** due to the use of Internet Identity, OISY can easily be used across all devices you have linked to your Internet Identity.

- **Network custody:** the key controlling your multi-chain assets is not controlled by a single entity nor has it ever existed as such. The key was generated using advanced cryptography that distributed key-shares among dedicated ICP replica nodes and signatures are created using [threshold ECDSA](https://internetcomputer.org/docs/current/developer-docs/integrations/t-ecdsa/).

- **Fully on-chain:** not only the keys but the entire wallet application is stored on-chain and served directly to your browser. The entire wallet is secured by a decentralized trust model, which guarantees that neither the front-end, nor the back-end have been tampered with.

- **Interoperable:** OISY integrates with the [WalletConnect](https://walletconnect.com/) protocol allowing you to use it as a wallet for many established web3 services, such as Uniswap. The OISY team is actively working on integrating OISY with [ICP's signer standards](https://github.com/dfinity/wg-identity-authentication/blob/main/topics/signer_standards_overview.md) allowing OISY to interact with [ICP's rich dapp ecosystem](https://internetcomputer.org/ecosystem).

- **Free to use and develop:** OISY is open-source software and licensed under [Apache 2.0](LICENSE). Feel free to fork it or propose improvements.

## ICP building blocks used

What are the unique ICP technical building blocks enabling the creation of OISY?

- **Chain-key signatures:** the world's best threshold ECDSA signature [protocol suite](https://eprint.iacr.org/2022/506) (only available on ICP) enables smart contracts to perform cryptographic signatures without a single entity having full access to the private key. Read more about [chain-key cryptography](https://internetcomputer.org/how-it-works/chain-key-technology/) or start building based on [chain-key signature sample code](https://github.com/dfinity/examples/tree/master/rust/threshold-ecdsa).

- **Internet Identity (II):** based on ICP's threshold BLS signature schemes and WebAuthn, Internet Identity (II) is an authentication and key management system with strong privacy and security guarantees. Using [WebAuthn](https://www.w3.org/TR/webauthn-3), users can conveniently create secure sessions with their fingerprint or other biometric identifiers. Read more about [Internet Identity technology](https://internetcomputer.org/internet-identity) or [start integrating II](https://internetcomputer.org/docs/current/developer-docs/integrations/internet-identity/integrate-identity) into your canister smart contract.

- **Web applications served from chain:** ICP is not only designed to run _backends_, such as ledgers, on chain, its low storage cost and low latency allow it to serve _frontends_, such as HTML files and images, from chain, too. Read more about [smart contracts serving web applications](https://internetcomputer.org/how-it-works/smart-contracts-serve-the-web/) or directly start [building your first decentralized web frontend](https://internetcomputer.org/docs/current/developer-docs/frontend/).

- (Upcoming) **HTTP outcalls:** for now, OISY calls centralized Ethereum endpoints, such as Infura or Alchemy, from the frontend. In the future, OISY might be improved to use [HTTP outcalls](https://internetcomputer.org/https-outcalls) to call these endpoints in a decentralized fashion. Check out the [HTTP outcalls sample code](https://internetcomputer.org/docs/current/developer-docs/integrations/https-outcalls/https-outcalls-how-to-use) to explore how to use Web 2.0 services on ICP.

## Submit your dApp

To file a request to have your dApp listed in the dApps explorer of OISY Wallet, please submit this [dApp Submission Request](https://github.com/dfinity/oisy-wallet/issues/new?assignees=&labels=&projects=&template=dapp_submission_request.md&title=Request+a+dApp+to+be+listed+on+the+OISY+Wallet+dApp+Explorer).

## Status

The platform, its software and all content found on it are provided on an “as is” and “as available” basis.
OISY Wallet does not give any warranties, whether express or implied, as to the suitability or usability of the application, its software or any of its content.

## Build and run yourself

### Prerequisites

- [x] Install the [IC SDK](https://internetcomputer.org/docs/current/developer-docs/setup/install/index.mdx).

### Start the local replica

Open a new terminal window _in the project directory_, and run the following command to start the local replica. The replica will not start unless [dfx.json](dfx.json) exists in the current directory.

```
dfx start --background
```

When you're done with development, or you're switching to a different dfx project, running

```
dfx stop
```

from the project directory will stop the local replica.

### Run OISY locally

Make sure you switch back to the project root directory.

First, install the frontend dependencies by running

```
npm ci
```

To build and deploy the project locally, first create a `.env.development` file by copying the [.env.example](.env.example) file. Once you've correctly set the api keys for all the different services that OISY needs, then run:

```
npm run deploy
```

It should output something like the following

```
...
Deployed canisters.
URLs:
  Frontend canister via browser
    frontend: http://127.0.0.1:4943/?canisterId=br5f7-7uaaa-aaaaa-qaaca-cai
  Backend canister via Candid interface:
    backend: http://127.0.0.1:4943/?canisterId=bd3sg-teaaa-aaaaa-qaaba-cai&id=bkyz2-fmaaa-aaaaa-qaaaq-cai
    internet_identity: http://127.0.0.1:4943/?canisterId=bd3sg-teaaa-aaaaa-qaaba-cai&id=be2us-64aaa-aaaaa-qaabq-cai
```

Click on the **frontend** URL to access the OISY Wallet that is running locally.

### Local development

See [HACKING](HACKING.md)

#### Backend

The backend is written in Rust and you can find it under the [backend folder](./src/backend/). It uses the [tECDSA API](https://internetcomputer.org/docs/current/developer-docs/integrations/t-ecdsa/t-ecdsa-how-it-works) provided by IC. To find out more about tECDSA, you can read the [Eurocrypt 2022 paper](https://eprint.iacr.org/2021/1330.pdf).

If you want to locally deploy the backend only, you use the following command

```
dfx deploy backend
```

### Frontend

The frontend is written entirely in Svelte. You can serve the frontend in development mode like you normally develop a svelte app using the command

```
npm run dev
```

## Dependencies

[//]: # 'TODO: Add fonts that are bought and owned by DFINITY too.'

### [Iconly Pro](https://iconly.pro/)

Some Iconly icons are used in the project, **not included**. You must obtain a license separately.  
The license for this project is bought and owned by the DFINITY Foundation, please see terms and conditions [here](https://iconly.pro/pages/terms).



================================================
FILE: canister_e2e_ids.json
================================================
{
	"backend": {
		"local": "tdxud-2yaaa-aaaad-aadiq-cai"
	},
	"signer": {
		"local": "tdxud-2yaaa-aaaad-aadiq-cai"
	},
	"ckbtc_index": {
		"local": "mm444-5iaaa-aaaar-qaabq-cai"
	},
	"ckbtc_kyt": {
		"local": "pvm5g-xaaaa-aaaar-qaaia-cai"
	},
	"ckbtc_ledger": {
		"local": "mc6ru-gyaaa-aaaar-qaaaq-cai"
	},
	"ckbtc_minter": {
		"local": "ml52i-qqaaa-aaaar-qaaba-cai"
	},
	"cketh_index": {
		"local": "sh5u2-cqaaa-aaaar-qacna-cai"
	},
	"cketh_ledger": {
		"local": "apia6-jaaaa-aaaar-qabma-cai"
	},
	"cketh_minter": {
		"local": "jzenf-aiaaa-aaaar-qaa7q-cai"
	},
	"ckusdc_index": {
		"local": "ycvkf-paaaa-aaaar-qaelq-cai"
	},
	"ckusdc_ledger": {
		"local": "yfumr-cyaaa-aaaar-qaela-cai"
	},
	"icp_index": {
		"local": "qhbym-qaaaa-aaaaa-aaafq-cai"
	},
	"icp_ledger": {
		"local": "ryjl3-tyaaa-aaaaa-aaaba-cai"
	},
	"internet_identity": {
		"local": "rdmx6-jaaaa-aaaaa-aaadq-cai"
	},
	"rewards": {
		"local": "vi6cu-aiaaa-aaaad-aad7q-cai"
	},
	"xtc-ledger": {
		"local": "aanaa-xaaaa-aaaah-aaeiq-cai"
	},
	"sol_rpc": {
		"local": "tghme-zyaaa-aaaar-qarca-cai"
	}
}



================================================
FILE: canister_ids.json
================================================
{
	"airdrop_deprecated": {
		"ic": "fiefn-syaaa-aaaan-qectq-cai",
		"staging": "t7tos-nyaaa-aaaad-aadkq-cai"
	},
	"backend": {
		"audit": "vhcnk-oqaaa-aaaah-araya-cai",
		"beta": "yrinv-sqaaa-aaaan-qzmxq-cai",
		"e2e": "odvuj-myaaa-aaaal-qskqq-cai",
		"ic": "doked-biaaa-aaaar-qag2a-cai",
		"staging": "d3nvo-aaaaa-aaaar-qagzq-cai",
		"test_be_1": "jloto-byaaa-aaaap-anryq-cai"
	},
	"frontend": {
		"audit": "vadl6-diaaa-aaaah-arayq-cai",
		"beta": "v7iq7-yiaaa-aaaan-qmrtq-cai",
		"e2e": "okw7v-2qaaa-aaaal-qskra-cai",
		"ic": "cha4i-riaaa-aaaan-qeccq-cai",
		"staging": "tewsx-xaaaa-aaaad-aadia-cai",
		"test_fe_1": "6qzfn-gyaaa-aaaar-qaisa-cai",
		"test_fe_2": "6xydz-laaaa-aaaar-qaisq-cai",
		"test_fe_3": "dxvmu-wiaaa-aaaah-aqzaa-cai",
		"test_fe_4": "gwqec-uqaaa-aaaak-qlnza-cai",
		"test_fe_5": "c4fs2-pqaaa-aaaal-qsl7a-cai",
		"test_fe_6": "ehrur-ziaaa-aaaaj-az7lq-cai"
	}
}



================================================
FILE: Cargo.toml
================================================
[workspace]
members = [
    "src/backend",
    "src/cycles_ledger/client",
    "src/cycles_ledger/pic",
    "src/cycles_ledger/types",
    "src/shared"
]
resolver = "2"

[workspace.dependencies]
bs58 = "0.5.1"
ic-cdk = "0.17.2"
ic-cdk-macros = "0.17.2"
ic-cdk-timers = "0.9.0"
ic-cycles-ledger-client = { path = "src/cycles_ledger/client" }
ic-cycles-ledger-pic = { path = "src/cycles_ledger/pic" }
ic-cycles-ledger-types = { path = "src/cycles_ledger/types" }
ic-ledger-types = "0.13.0"
ic-stable-structures = "0.6.9"
ic-metrics-encoder = "1.1.1"
ic-canister-sig-creation = "1.2.0"
ic-verifiable-credentials = "1.0.1"
candid = "0.10.19"
candid_parser = "0.1"
ethers-core = "= 2.0.11"
futures = "0.3"
serde = "1"
serde_bytes = "0.11"
getrandom = { version = "0.2", features = ["custom"] }
hex = "0.4"
sha2 = "0.10.9"
k256 = "0.13"
lazy_static = "1.5.0"
# dfx 0.26.1 bundles pocket-ic server 8.0 which uses pocket-ic library 7.0
# See:
# Server version: ~/.cache/dfinity/versions/0.26.0/pocket-ic --version
# Library version: https://docs.google.com/document/d/1VYmHUTjrgbzRHtsAyRrI5cj-gWGs7ktTnutPvUMJioU/edit?pli=1&tab=t.0#heading=h.5wf28dvt742x
pocket-ic = "7.0"
pretty_assertions = "1.4.1"
strum = "0.26.3"
strum_macros = "0.26.4"
bitcoin = "0.32.7"
paste = "1.0.15"

[workspace.lints.rust]
deprecated = "allow" # Why is this allowed?
warnings = "deny"

[workspace.lints.clippy]
pedantic = { level = "warn", priority = -1 }
module_name_repetitions = "allow"
struct_field_names = "allow"



================================================
FILE: clippy.toml
================================================
disallowed-macros = [
    { path = "std::print", reason = "Use ic_cdk::print instead" },
    { path = "std::println", reason = "Use ic_cdk::println instead" },
    { path = "std::eprint", reason = "Use ic_cdk::eprint instead" },
    { path = "std::eprintln", reason = "Use ic_cdk::eprintln instead" },
    { path = "std::assert_eq", reason = "Use pretty_assertions::assert_eq instead" },
]
disallowed-methods = [
    { path = "dfn_core::api::print", reason = "Use ic_cdk::print or ic_cdk::println instead" },
    { path = "ic_cdk::api::management_canister::ecdsa::sign_with_ecdsa", reason = "Threshold signatures may be made by the chain fusion signer only." },
    { path = "ic_cdk::api::management_canister::schnorr::sign_with_schnorr", reason = "Threshold signatures may be made by the chain fusion signer only." },
]



================================================
FILE: dev-tools.json
================================================
{
	"rustup": {
		"method": "curl",
		"version": "1.28.1",
		"url": "https://raw.githubusercontent.com/rust-lang/rustup/${VERSION}/rustup-init.sh",
		"pipe": [["sh"]]
	},
	"rust": {
		"method": "sh",
		"note": "See also: rust-toolchain.toml",
		"version": "nightly-2025-04-01"
	},
	"didc": {
		"method": "curl",
		"version": "0.4.0",
		"url": "https://github.com/dfinity/candid/releases/download/2024-07-29/didc-linux64"
	},
	"shellcheck": {
		"method": "apt"
	},
	"shfmt": {
		"method": "go",
		"version": "v3.5.1",
		"source": "mvdan.cc/sh/v3/cmd/shfmt"
	},
	"yq": {
		"method": "curl",
		"version": "4.33.3",
		"url": "https://github.com/mikefarah/yq/releases/download/v${VERSION}/yq_linux_amd64"
	},
	"cargo-binstall": {
		"method": "sh",
		"version": "1.7.4"
	},
	"solana": {
		"method": "sh",
		"version": "2.0.16"
	},
	"ic-wasm": {
		"method": "cargo-binstall",
		"version": "0.8.5"
	},
	"cargo-audit": {
		"method": "cargo-binstall",
		"version": "0.21.2"
	},
	"cargo-edit": {
		"method": "cargo-binstall",
		"version": "0.13.0"
	},
	"cargo-sort": {
		"method": "cargo-binstall",
		"version": "1.0.9"
	},
	"candid-extractor": {
		"method": "cargo-binstall",
		"version": "0.1.4"
	},
	"zizmor": {
		"method": "cargo-binstall",
		"version": "1.5.2"
	}
}



================================================
FILE: dfx.json
================================================
{
	"dfx": "0.26.1",
	"canisters": {
		"signer": {
			"type": "custom",
			"build": "scripts/build.signer.sh",
			"candid": "target/signer.did",
			"wasm": "target/signer.wasm.gz",
			"init_arg_file": "target/signer.arg.did",
			"shrink": false,
			"specified_id": "grghe-syaaa-aaaar-qabyq-cai",
			"remote": {
				"id": {
					"ic": "grghe-syaaa-aaaar-qabyq-cai",
					"beta": "grghe-syaaa-aaaar-qabyq-cai",
					"test_be_1": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_1": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_2": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_3": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_4": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_5": "tdxud-2yaaa-aaaad-aadiq-cai",
					"test_fe_6": "tdxud-2yaaa-aaaad-aadiq-cai",
					"audit": "tdxud-2yaaa-aaaad-aadiq-cai",
					"staging": "tdxud-2yaaa-aaaad-aadiq-cai",
					"e2e": "tdxud-2yaaa-aaaad-aadiq-cai"
				}
			}
		},
		"kong_backend": {
			"type": "custom",
			"build": "scripts/build.kong_backend.sh",
			"candid": "target/kong_backend.did",
			"wasm": "target/kong_backend.wasm.gz",
			"shrink": false,
			"specified_id": "l4lgk-raaaa-aaaar-qahpq-cai",
			"remote": {
				"id": {
					"ic": "2ipq2-uqaaa-aaaar-qailq-cai",
					"beta": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_be_1": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_1": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_2": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_3": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_4": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_5": "2ipq2-uqaaa-aaaar-qailq-cai",
					"test_fe_6": "2ipq2-uqaaa-aaaar-qailq-cai",
					"audit": "2ipq2-uqaaa-aaaar-qailq-cai",
					"staging": "2ipq2-uqaaa-aaaar-qailq-cai",
					"e2e": "2ipq2-uqaaa-aaaar-qailq-cai"
				}
			}
		},
		"icp_swap_pool": {
			"type": "custom",
			"build": "scripts/build.icp_swap_pool.sh",
			"candid": "target/icp_swap_pool.did",
			"wasm": "target/icp_swap_pool.wasm.gz",
			"init_arg_file": "target/icp_swap_pool.arg.did",
			"shrink": false,
			"specified_id": "xmiu5-jqaaa-aaaag-qbz7q-cai",
			"remote": {
				"id": {
					"ic": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"beta": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"test_be_1": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"test_fe_1": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"test_fe_2": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"test_fe_3": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"test_fe_4": "xmiu5-jqaaa-aaaag-qbz7q-cai",
					"staging": "xmiu5-jqaaa-aaaag-qbz7q-cai"
				}
			}
		},
		"icp_swap_factory": {
			"type": "custom",
			"build": "scripts/build.icp_swap_factory.sh",
			"candid": "target/icp_swap_factory.did",
			"wasm": "target/icp_swap_factory.wasm.gz",
			"init_arg_file": "target/icp_swap_factory.arg.did",
			"shrink": false,
			"specified_id": "4mmnk-kiaaa-aaaag-qbllq-cai",
			"remote": {
				"id": {
					"ic": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"beta": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"test_be_1": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"test_fe_1": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"test_fe_2": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"test_fe_3": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"test_fe_4": "4mmnk-kiaaa-aaaag-qbllq-cai",
					"staging": "4mmnk-kiaaa-aaaag-qbllq-cai"
				}
			}
		},
		"backend": {
			"candid": "src/backend/backend.did",
			"package": "backend",
			"type": "custom",
			"optimize": "cycles",
			"gzip": true,
			"wasm": "out/backend.wasm.gz",
			"init_arg_file": "out/backend.args.did",
			"build": "scripts/build.backend.sh",
			"remote": {
				"id": {
					"test_fe_1": "d3nvo-aaaaa-aaaar-qagzq-cai",
					"test_fe_2": "d3nvo-aaaaa-aaaar-qagzq-cai",
					"test_fe_3": "d3nvo-aaaaa-aaaar-qagzq-cai",
					"test_fe_4": "d3nvo-aaaaa-aaaar-qagzq-cai",
					"test_fe_5": "d3nvo-aaaaa-aaaar-qagzq-cai",
					"test_fe_6": "d3nvo-aaaaa-aaaar-qagzq-cai"
				}
			}
		},
		"frontend": {
			"candid": "https://raw.githubusercontent.com/dfinity/sdk/release-0.20.0/src/distributed/assetstorage.did",
			"frontend": {
				"entrypoint": "build/index.html"
			},
			"source": ["build/"],
			"type": "assets",
			"remote": {
				"id": {
					"test_be_1": "tewsx-xaaaa-aaaad-aadia-cai"
				}
			}
		},
		"orbit": {
			"type": "custom",
			"candid": "https://raw.githubusercontent.com/dfinity/orbit/%40orbit/station-v0.0.2-alpha.5/apps/wallet/src/generated/station/station.did",
			"wasm": "https://github.com/dfinity/orbit/releases/download/%40orbit%2Fstation-v0.0.2-alpha.5/station.wasm.gz",
			"remote": {
				"id": {
					"__default": "2vxsx-fae",
					"staging": "4jngj-yiaaa-aaaal-ajk5q-cai",
					"audit": "yo6ep-dyaaa-aaaal-ajs6q-cai",
					"ic": "xtnlb-waaaa-aaaal-ajm7q-cai"
				}
			}
		},
		"internet_identity": {
			"type": "custom",
			"candid": "https://github.com/dfinity/internet-identity/releases/download/release-2024-10-25/internet_identity.did",
			"wasm": "https://github.com/dfinity/internet-identity/releases/download/release-2024-10-25/internet_identity_dev.wasm.gz",
			"init_arg": "(opt record { captcha_config = opt record { max_unsolved_captchas= 50:nat64; captcha_trigger = variant {Static = variant {CaptchaDisabled}}}})",
			"specified_id": "rdmx6-jaaaa-aaaaa-aaadq-cai",
			"remote": {
				"candid": "internet_identity.did",
				"id": {
					"test_be_1": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_1": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_2": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_3": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_4": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_5": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"test_fe_6": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"audit": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"staging": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"beta": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"ic": "rdmx6-jaaaa-aaaaa-aaadq-cai",
					"e2e": "rdmx6-jaaaa-aaaaa-aaadq-cai"
				}
			}
		},
		"cycles_ledger": {
			"type": "custom",
			"candid": "https://github.com/dfinity/cycles-ledger/releases/download/cycles-ledger-v1.0.1/cycles-ledger.did",
			"wasm": "https://github.com/dfinity/cycles-ledger/releases/download/cycles-ledger-v1.0.1/cycles-ledger.wasm.gz",
			"init_arg": "( variant { Init = record { index_id = null; max_blocks_per_request = 9_999 : nat64 }},)",
			"specified_id": "um5iw-rqaaa-aaaaq-qaaba-cai",
			"remote": {
				"id": {
					"test_be_1": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_1": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_2": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_3": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_4": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_5": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"test_fe_6": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"audit": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"staging": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"beta": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"ic": "um5iw-rqaaa-aaaaq-qaaba-cai",
					"e2e": "um5iw-rqaaa-aaaaq-qaaba-cai"
				}
			}
		},
		"cycles_depositor": {
			"type": "custom",
			"build": "scripts/build.cycles_depositor.sh",
			"init_arg_file": "out/cycles_depositor.args.did",
			"wasm": "out/cycles_depositor.wasm",
			"candid": "out/cycles_depositor.did",
			"remote": {
				"id": {
					"test_be_1": "2vxsx-fae",
					"test_fe_1": "2vxsx-fae",
					"test_fe_2": "2vxsx-fae",
					"test_fe_3": "2vxsx-fae",
					"test_fe_4": "2vxsx-fae",
					"test_fe_5": "2vxsx-fae",
					"test_fe_6": "2vxsx-fae",
					"audit": "2vxsx-fae",
					"staging": "2vxsx-fae",
					"beta": "2vxsx-fae",
					"ic": "2vxsx-fae",
					"e2e": "2vxsx-fae"
				}
			}
		},
		"pouh_issuer": {
			"type": "custom",
			"candid": "https://github.com/dfinity/verifiable-credentials-sdk/releases/download/release-2024-07-01/dummy_issuer.did",
			"wasm": "https://github.com/dfinity/verifiable-credentials-sdk/releases/download/release-2024-07-01/dummy_issuer.wasm.gz",
			"shrink": false,
			"specified_id": "qbw6f-caaaa-aaaah-qdcwa-cai",
			"remote": {
				"id": {
					"test_be_1": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_1": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_2": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_3": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_4": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_5": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"test_fe_6": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"audit": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"staging": "qbw6f-caaaa-aaaah-qdcwa-cai",
					"beta": "qgxyr-pyaaa-aaaah-qdcwq-cai",
					"ic": "qgxyr-pyaaa-aaaah-qdcwq-cai",
					"e2e": "qgxyr-pyaaa-aaaah-qdcwq-cai"
				}
			}
		},
		"sol_rpc": {
			"type": "custom",
			"build": "scripts/build.sol_rpc.sh",
			"candid": "target/sol_rpc.did",
			"wasm": "target/sol_rpc.wasm.gz",
			"init_arg_file": "target/sol_rpc.arg.did",
			"shrink": false,
			"specified_id": "tghme-zyaaa-aaaar-qarca-cai",
			"remote": {
				"id": {
					"ic": "tghme-zyaaa-aaaar-qarca-cai",
					"beta": "tghme-zyaaa-aaaar-qarca-cai",
					"test_be_1": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_1": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_2": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_3": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_4": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_5": "tghme-zyaaa-aaaar-qarca-cai",
					"test_fe_6": "tghme-zyaaa-aaaar-qarca-cai",
					"audit": "tghme-zyaaa-aaaar-qarca-cai",
					"staging": "tghme-zyaaa-aaaar-qarca-cai",
					"e2e": "tghme-zyaaa-aaaar-qarca-cai"
				}
			}
		},
		"icp_ledger": {
			"type": "custom",
			"build": "scripts/build.icp_ledger.sh",
			"candid": "target/ic/icp_ledger.did",
			"wasm": "target/ic/icp_ledger.wasm",
			"specified_id": "ryjl3-tyaaa-aaaaa-aaaba-cai",
			"init_arg_file": "target/ic/icp_ledger.args.did",
			"remote": {
				"id": {
					"test_be_1": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_1": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_2": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_3": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_4": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_5": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"test_fe_6": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"audit": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"staging": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"beta": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"ic": "ryjl3-tyaaa-aaaaa-aaaba-cai",
					"e2e": "ryjl3-tyaaa-aaaaa-aaaba-cai"
				}
			}
		},
		"icp_index": {
			"dependencies": ["icp_ledger"],
			"type": "custom",
			"build": "scripts/build.icp_index.sh",
			"candid": "target/ic/icp_index.did",
			"wasm": "target/ic/icp_index.wasm",
			"init_arg_file": "target/ic/icp_index.args.did",
			"specified_id": "qhbym-qaaaa-aaaaa-aaafq-cai",
			"remote": {
				"id": {
					"test_be_1": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_1": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_2": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_3": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_4": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_5": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"test_fe_6": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"audit": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"staging": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"beta": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"ic": "qhbym-qaaaa-aaaaa-aaafq-cai",
					"e2e": "qhbym-qaaaa-aaaaa-aaafq-cai"
				}
			}
		},
		"ckbtc_minter": {
			"type": "custom",
			"build": "scripts/build.ckbtc_minter.sh",
			"candid": "target/ic/ckbtc_minter.did",
			"wasm": "target/ic/ckbtc_minter.wasm",
			"init_arg_file": "target/ic/ckbtc_minter.args.did",
			"specified_id": "ml52i-qqaaa-aaaar-qaaba-cai",
			"remote": {
				"id": {
					"ic": "mqygn-kiaaa-aaaar-qaadq-cai",
					"test_be_1": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_1": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_2": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_3": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_4": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_5": "ml52i-qqaaa-aaaar-qaaba-cai",
					"test_fe_6": "ml52i-qqaaa-aaaar-qaaba-cai",
					"audit": "ml52i-qqaaa-aaaar-qaaba-cai",
					"staging": "ml52i-qqaaa-aaaar-qaaba-cai",
					"e2e": "ml52i-qqaaa-aaaar-qaaba-cai"
				}
			}
		},
		"ckbtc_ledger": {
			"type": "custom",
			"candid": "target/ic/ckbtc_ledger.did",
			"wasm": "target/ic/ckbtc_ledger.wasm",
			"specified_id": "mc6ru-gyaaa-aaaar-qaaaq-cai",
			"remote": {
				"id": {
					"ic": "mxzaz-hqaaa-aaaar-qaada-cai",
					"test_be_1": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_1": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_2": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_3": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_4": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_5": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"test_fe_6": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"audit": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"staging": "mc6ru-gyaaa-aaaar-qaaaq-cai",
					"e2e": "mc6ru-gyaaa-aaaar-qaaaq-cai"
				}
			}
		},
		"ckbtc_index": {
			"type": "custom",
			"build": "scripts/build.ckbtc_index.sh",
			"candid": "target/ic/ckbtc_index.did",
			"wasm": "target/ic/ckbtc_index.wasm",
			"init_arg_file": "target/ic/ckbtc_index.args.did",
			"specified_id": "mm444-5iaaa-aaaar-qaabq-cai",
			"remote": {
				"id": {
					"ic": "n5wcd-faaaa-aaaar-qaaea-cai",
					"test_be_1": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_1": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_2": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_3": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_4": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_5": "mm444-5iaaa-aaaar-qaabq-cai",
					"test_fe_6": "mm444-5iaaa-aaaar-qaabq-cai",
					"audit": "mm444-5iaaa-aaaar-qaabq-cai",
					"staging": "mm444-5iaaa-aaaar-qaabq-cai",
					"e2e": "mm444-5iaaa-aaaar-qaabq-cai"
				}
			}
		},
		"ckbtc_kyt": {
			"type": "custom",
			"build": "scripts/build.ckbtc_kyt.sh",
			"candid": "target/ic/ckbtc_kyt.did",
			"wasm": "target/ic/ckbtc_kyt.wasm",
			"init_arg_file": "target/ic/ckbtc_kyt.args.did",
			"specified_id": "pvm5g-xaaaa-aaaar-qaaia-cai",
			"remote": {
				"id": {
					"ic": "pjihx-aaaaa-aaaar-qaaka-cai",
					"test_be_1": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_1": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_2": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_3": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_4": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_5": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"test_fe_6": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"audit": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"staging": "pvm5g-xaaaa-aaaar-qaaia-cai",
					"e2e": "pvm5g-xaaaa-aaaar-qaaia-cai"
				}
			}
		},
		"cketh_minter": {
			"type": "custom",
			"build": "scripts/build.cketh_minter.sh",
			"candid": "target/ic/cketh_minter.did",
			"wasm": "target/ic/cketh_minter.wasm",
			"init_arg_file": "target/ic/cketh_minter.args.did",
			"specified_id": "jzenf-aiaaa-aaaar-qaa7q-cai",
			"remote": {
				"id": {
					"ic": "sv3dd-oaaaa-aaaar-qacoa-cai",
					"test_be_1": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_1": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_2": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_3": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_4": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_5": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"test_fe_6": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"audit": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"staging": "jzenf-aiaaa-aaaar-qaa7q-cai",
					"e2e": "jzenf-aiaaa-aaaar-qaa7q-cai"
				}
			}
		},
		"cketh_ledger": {
			"description": "Sepoila testnet ckETH ledger canister",
			"dependencies": ["cketh_minter"],
			"type": "custom",
			"candid": "target/ic/cketh_ledger.did",
			"build": "scripts/build.cketh_ledger.sh",
			"wasm": "target/ic/cketh_ledger.wasm",
			"init_arg_file": "target/ic/cketh_ledger.args.did",
			"specified_id": "apia6-jaaaa-aaaar-qabma-cai",
			"remote": {
				"id": {
					"ic": "ss2fx-dyaaa-aaaar-qacoq-cai",
					"test_be_1": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_1": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_2": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_3": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_4": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_5": "apia6-jaaaa-aaaar-qabma-cai",
					"test_fe_6": "apia6-jaaaa-aaaar-qabma-cai",
					"audit": "apia6-jaaaa-aaaar-qabma-cai",
					"staging": "apia6-jaaaa-aaaar-qabma-cai",
					"e2e": "apia6-jaaaa-aaaar-qabma-cai"
				}
			}
		},
		"cketh_index": {
			"description": "Sepoila testnet ckETH index canister",
			"dependencies": ["cketh_ledger"],
			"type": "custom",
			"build": "scripts/build.cketh_index.sh",
			"init_arg_file": "target/ic/cketh_index.args.did",
			"candid": "target/ic/cketh_index.did",
			"wasm": "target/ic/cketh_index.wasm",
			"specified_id": "sh5u2-cqaaa-aaaar-qacna-cai",
			"remote": {
				"id": {
					"ic": "s3zol-vqaaa-aaaar-qacpa-cai",
					"test_be_1": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_1": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_2": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_3": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_4": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_5": "sh5u2-cqaaa-aaaar-qacna-cai",
					"test_fe_6": "sh5u2-cqaaa-aaaar-qacna-cai",
					"audit": "sh5u2-cqaaa-aaaar-qacna-cai",
					"staging": "sh5u2-cqaaa-aaaar-qacna-cai",
					"e2e": "sh5u2-cqaaa-aaaar-qacna-cai"
				}
			}
		},
		"ckusdc_ledger": {
			"dependencies": ["cketh_minter"],
			"type": "custom",
			"build": "scripts/build.ckusdc_ledger.sh",
			"candid": "target/ic/cketh_ledger.did",
			"wasm": "target/ic/cketh_ledger.wasm",
			"init_arg_file": "target/ic/ckusdc_ledger.args.did",
			"specified_id": "yfumr-cyaaa-aaaar-qaela-cai",
			"remote": {
				"id": {
					"ic": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_be_1": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_1": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_2": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_3": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_4": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_5": "yfumr-cyaaa-aaaar-qaela-cai",
					"test_fe_6": "yfumr-cyaaa-aaaar-qaela-cai",
					"audit": "yfumr-cyaaa-aaaar-qaela-cai",
					"staging": "yfumr-cyaaa-aaaar-qaela-cai"
				}
			}
		},
		"ckusdc_index": {
			"dependencies": ["ckusdc_ledger"],
			"type": "custom",
			"build": "scripts/build.ckusdc_index.sh",
			"candid": "target/ic/cketh_index.did",
			"wasm": "target/ic/cketh_index.wasm",
			"init_arg_file": "target/ic/ckusdc_index.args.did",
			"specified_id": "ycvkf-paaaa-aaaar-qaelq-cai",
			"remote": {
				"id": {
					"ic": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_be_1": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_1": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_2": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_3": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_4": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_5": "ycvkf-paaaa-aaaar-qaelq-cai",
					"test_fe_6": "ycvkf-paaaa-aaaar-qaelq-cai",
					"audit": "ycvkf-paaaa-aaaar-qaelq-cai",
					"staging": "ycvkf-paaaa-aaaar-qaelq-cai"
				}
			}
		},
		"xtc_ledger": {
			"type": "custom",
			"build": "scripts/build.xtc_ledger.sh",
			"candid": "target/xtc_ledger.did",
			"wasm": "target/xtc_ledger.wasm.gz",
			"specified_id": "aanaa-xaaaa-aaaah-aaeiq-cai",
			"remote": {
				"id": {
					"test_be_1": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_1": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_2": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_3": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_4": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_5": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"test_fe_6": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"audit": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"staging": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"beta": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"ic": "aanaa-xaaaa-aaaah-aaeiq-cai",
					"e2e": "aanaa-xaaaa-aaaah-aaeiq-cai"
				}
			}
		},
		"rewards": {
			"type": "custom",
			"candid": "https://github.com/dfinity/oisy-wallet/releases/download/rc0.5.10/rewards.did",
			"wasm": "https://github.com/dfinity/oisy-wallet/releases/download/rc0.5.10/rewards.wasm.gz",
			"remote": {
				"id": {
					"ic": "nynz6-haaaa-aaaan-qzqda-cai",
					"beta": "nynz6-haaaa-aaaan-qzqda-cai",
					"staging": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_be_1": "k2sla-fiaaa-aaaag-atvfa-cai",
					"test_fe_1": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_fe_2": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_fe_3": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_fe_4": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_fe_5": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"test_fe_6": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"e2e": "vi6cu-aiaaa-aaaad-aad7q-cai",
					"audit": "vi6cu-aiaaa-aaaad-aad7q-cai"
				}
			}
		},
		"llm": {
			"type": "custom",
			"build": "scripts/build.llm.sh",
			"candid": "target/llm.did",
			"wasm": "target/llm.wasm.gz",
			"init_arg_file": "target/llm.arg.did",
			"specified_id": "w36hm-eqaaa-aaaal-qr76a-cai",
			"shrink": false,
			"remote": {
				"id": {
					"ic": "w36hm-eqaaa-aaaal-qr76a-cai",
					"beta": "w36hm-eqaaa-aaaal-qr76a-cai",
					"staging": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_be_1": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_1": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_2": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_3": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_4": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_5": "w36hm-eqaaa-aaaal-qr76a-cai",
					"test_fe_6": "w36hm-eqaaa-aaaal-qr76a-cai",
					"e2e": "w36hm-eqaaa-aaaal-qr76a-cai",
					"audit": "w36hm-eqaaa-aaaal-qr76a-cai"
				}
			}
		},
		"gldt_stake": {
			"type": "custom",
			"build": "scripts/build.gldt_stake.sh",
			"candid": "target/gldt_stake.did",
			"wasm": "target/gdlt_stake.wasm.gz",
			"init_arg_file": "target/gldt_stake.arg.did",
			"specified_id": "sqpxs-piaaa-aaaaj-qneva-cai",
			"shrink": false,
			"remote": {
				"id": {
					"ic": "sqpxs-piaaa-aaaaj-qneva-cai",
					"beta": "sqpxs-piaaa-aaaaj-qneva-cai",
					"staging": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_be_1": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_1": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_2": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_3": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_4": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_5": "sqpxs-piaaa-aaaaj-qneva-cai",
					"test_fe_6": "sqpxs-piaaa-aaaaj-qneva-cai",
					"e2e": "sqpxs-piaaa-aaaaj-qneva-cai",
					"audit": "sqpxs-piaaa-aaaaj-qneva-cai"
				}
			}
		}
	},
	"defaults": {
		"build": {
			"args": "",
			"packtool": ""
		}
	},
	"version": 1,
	"networks": {
		"old-backend": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_1": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_2": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_3": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_4": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_5": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_fe_6": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"test_be_1": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"audit": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"staging": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"beta": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"e2e": {
			"providers": ["https://icp0.io"],
			"type": "persistent"
		},
		"local": {
			"bind": "127.0.0.1:4943",
			"type": "ephemeral"
		}
	}
}



================================================
FILE: Dockerfile
================================================
#
# Reproducible builds of the Oisy backend canister
#

FROM --platform=linux/amd64 ubuntu@sha256:bbf3d1baa208b7649d1d0264ef7d522e1dc0deeeaaf6085bf8e4618867f03494 AS base
# Note: The above is ubuntu 22.04

ENV TZ=UTC

# Install required tools
RUN DEBIAN_FRONTEND=noninteractive apt update && apt install -y \
    curl \
    ca-certificates \
    build-essential \
    pkg-config \
    libssl-dev \
    llvm-dev \
    liblmdb-dev \
    clang \
    cmake \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Gets dfx version
#
# Note: This can be done in 'deps' but is slow because unrelated changes to dfx.json can cause a rebuild.
FROM base AS tool_versions
SHELL ["bash", "-c"]
RUN mkdir -p config
COPY dfx.json dfx.json
RUN jq -r .dfx dfx.json > config/dfx_version

# Install tools && warm up the build cache
FROM base AS deps
SHELL ["bash", "-c"]
# Install dfx
# Note: dfx is installed in `$HOME/.local/share/dfx/bin` but we can't reference `$HOME` here so we hardcode `/root`.
COPY --from=tool_versions /config/*_version config/
ENV PATH="/root/.local/share/dfx/bin:/root/.local/bin:${PATH}"
RUN DFXVM_INIT_YES=true DFX_VERSION="$(cat config/dfx_version)" sh -c "$(curl -fsSL https://sdk.dfinity.org/install.sh)" && dfx --version

# Install node
RUN curl --fail -sSf https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
ENV NVM_DIR=/root/.nvm
COPY .node-version .node-version
RUN . "$NVM_DIR/nvm.sh" && nvm install "$(cat .node-version)"
RUN . "$NVM_DIR/nvm.sh" && nvm use "v$(cat .node-version)"
RUN . "$NVM_DIR/nvm.sh" && nvm alias default "v$(cat .node-version)"
RUN ln -s "$NVM_DIR/versions/node/v$(cat .node-version)" "$NVM_DIR/versions/node/default"
ENV PATH="$NVM_DIR/versions/node/default/bin/:${PATH}"
RUN node --version
RUN npm --version

# Install Rust and Cargo in /opt
ENV RUSTUP_HOME=/opt/rustup \
    CARGO_HOME=/cargo \
    PATH=/cargo/bin:$PATH

# Copy resources	
COPY ./docker ./docker	

# Setup toolchain and ic-wasm
COPY rust-toolchain.toml .
COPY dev-tools.json .
COPY scripts/setup scripts/setup-cargo-binstall scripts/setup-rust scripts/
RUN scripts/setup rust
RUN scripts/setup cargo-binstall
RUN scripts/setup candid-extractor
RUN scripts/setup ic-wasm
RUN scripts/setup didc
RUN scripts/setup yq

# Pre-build all cargo dependencies. Because cargo doesn't have a build option
# to build only the dependencies, we pretend that our project is a simple, empty
# `lib.rs`. When we COPY the actual files we make sure to `touch` lib.rs so
# that cargo knows to rebuild it with the new content.
COPY Cargo.lock .
COPY Cargo.toml .
COPY src/backend/Cargo.toml src/backend/Cargo.toml
COPY src/cycles_ledger/client/Cargo.toml src/cycles_ledger/client/Cargo.toml
COPY src/cycles_ledger/pic/Cargo.toml src/cycles_ledger/pic/Cargo.toml
COPY src/cycles_ledger/types/Cargo.toml src/cycles_ledger/types/Cargo.toml
COPY src/shared/Cargo.toml src/shared/Cargo.toml
COPY scripts/build.backend.wasm.sh scripts/
RUN mkdir -p src/backend/src \
    && touch src/backend/src/lib.rs \
    && mkdir -p src/cycles_ledger/client/src \
    && touch src/cycles_ledger/client/src/lib.rs \
    && mkdir -p src/cycles_ledger/pic/src \
    && touch src/cycles_ledger/pic/src/lib.rs \
    && mkdir -p src/cycles_ledger/types/src \
    && touch src/cycles_ledger/types/src/lib.rs \
    && mkdir -p src/shared/src \
    && touch src/shared/src/lib.rs
RUN cargo fetch
RUN scripts/build.backend.wasm.sh
RUN rm -rf src

FROM deps AS build_backend
COPY src src
COPY scripts/build.backend.* scripts/
COPY scripts/build.report.sh scripts/
# Cache the rust build, to make the dfx build fast:
RUN scripts/build.backend.wasm.sh
# Variables that don't affect the rust build:
COPY dfx.json dfx.json
COPY canister_ids.json canister_ids.json
COPY ./in/tags in/tags
COPY ./in/commit in/commit
ENV DFX_NETWORK=ic
COPY scripts/commit-metadata scripts/
RUN touch src/*/src/lib.rs src/*/*/src/lib.rs
RUN dfx build backend --network "$DFX_NETWORK"

FROM scratch AS backend
COPY --from=build_backend out/ /



================================================
FILE: Dockerfile.frontend
================================================
FROM --platform=linux/amd64 ubuntu@sha256:bbf3d1baa208b7649d1d0264ef7d522e1dc0deeeaaf6085bf8e4618867f03494 AS deps
# Note: The above is ubuntu 22.04

# Install required tools
RUN DEBIAN_FRONTEND=noninteractive apt update && apt install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install node
RUN curl --fail -sSf https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
ENV NVM_DIR=/root/.nvm
COPY .node-version .node-version
RUN . "$NVM_DIR/nvm.sh" && nvm install "$(cat .node-version)"
RUN . "$NVM_DIR/nvm.sh" && nvm use "v$(cat .node-version)"
RUN . "$NVM_DIR/nvm.sh" && nvm alias default "v$(cat .node-version)"
RUN ln -s "$NVM_DIR/versions/node/v$(cat .node-version)" "$NVM_DIR/versions/node/default"
ENV PATH="$NVM_DIR/versions/node/default/bin/:${PATH}"
RUN node --version
RUN npm --version

FROM deps AS build_frontend

COPY package.json package-lock.json .
RUN npm ci

COPY .env.* *.js *.cjs *.mjs *.ts *.json .npmrc .nvmrc .
COPY src/frontend/ src/frontend
COPY src/declarations/ src/declarations
COPY scripts/ scripts/

ARG network="staging"
ENV ENV=$network
ENV DFX_NETWORK=$network

RUN echo $ENV
RUN echo $DFX_NETWORK

RUN npm ci
RUN npm run build
RUN scripts/build.frontend-report.sh > build/build-report.txt


FROM scratch AS scratch_frontend
COPY --from=build_frontend /build /frontend



================================================
FILE: env.utils.ts
================================================
import { readFileSync } from 'node:fs';

/**
 * Read a JSON file with canister IDs and transform it into a dictionary. Optionally add prefix to all dictionary keys.
 */
export const readCanisterIds = ({
	filePath,
	prefix
}: {
	filePath: string;
	prefix?: string;
}): Record<string, string> => {
	try {
		interface Details {
			ic?: string;
			beta?: string;
			staging?: string;
			local?: string;
		}

		const config: Record<string, Details> = JSON.parse(readFileSync(filePath, 'utf8'));

		return Object.entries(config).reduce((acc, current: [string, Details]) => {
			const [canisterName, canisterDetails] = current;

			const ids = Object.entries(canisterDetails).reduce(
				(acc, [network, id]) => ({
					...acc,
					[`${prefix ?? ''}${network.toUpperCase().replaceAll('-', '_')}_${canisterName
						.replaceAll('-', '_')
						.replaceAll("'", '')
						.toUpperCase()}_CANISTER_ID`]: id
				}),
				{}
			);

			return {
				...acc,
				...ids
			};
		}, {});
	} catch (e) {
		console.warn(`Could not get canister ID from ${filePath}: ${e}`);
		return {};
	}
};



================================================
FILE: eslint-local-rules.cjs
================================================
// eslint-disable-next-line @typescript-eslint/no-require-imports
module.exports = require("@dfinity/eslint-config-oisy-wallet/eslint-local-rules");


================================================
FILE: eslint.config.mjs
================================================
import { default as svelteConfig } from '@dfinity/eslint-config-oisy-wallet/svelte';
import { default as vitestConfig } from '@dfinity/eslint-config-oisy-wallet/vitest';

export default [
	...vitestConfig,
	...svelteConfig,

	{
		rules: {
			'local-rules/use-option-type-wrapper': 'error',
			// TODO: re-enable this rule when it includes `expect` statements nested in callable functions.
			'vitest/expect-expect': ['off']
		}
	},

	{
		files: ['src/frontend/src/**/*'],
		rules: {
			'local-rules/no-relative-imports': 'error'
		}
	},

	{
		rules: {
			'no-restricted-syntax': [
				'error',
				{
					selector: "Literal[raw='0n']",
					message: 'Use the shared constant `ZERO` instead of `0n`.'
				}
			]
		}
	},

	{
		ignores: [
			'**/.DS_Store',
			'**/node_modules',
			'build',
			'.dfx',
			'.svelte-kit',
			'package',
			'**/.env',
			'**/.env.*',
			'!**/.env.example',
			'**/pnpm-lock.yaml',
			'**/package-lock.json',
			'**/yarn.lock',
			'src/declarations/**/*',
			'src/frontend/src/env/tokens/tokens.sns.json',
			'**/playwright-report',
			'**/coverage',
			'**/.vitest-reports'
		]
	}
];



================================================
FILE: HACKING.md
================================================
# Hacking

This document lists a couple of useful information for development and deployment purpose.

## Table of content

- [Deployment](#deployment)
- [Internationalization](#internationalization)
- [Faucets](#faucets)
- [Testing](#testing)
- [Integrate ckERC20 Tokens](#integrate-ckerc20-tokens)
- [Bitcoin](#bitcoin)
- [Routes Styles](#routes-styles)
- [Add EVM Networks](#add-evm-networks)
- [Build Frontend locally with Docker](#build-frontend-locally-with-docker)

## Deployment

Following terminal commands are useful to deploy `frontend` and `backend`.

### Local development

> To perform local development, you'll need a `.env.development` file.

```bash
npm run deploy
```

> [!NOTE]
> For macOS, you might need to manually install `llvm` and patch `clang` lib path. See example for `zsh` shell:

```bash
brew install llvm

echo 'export CC=$(brew --prefix llvm)/bin/clang' >> ~/.zshrc
echo 'export AR=$(brew --prefix llvm)/bin/llvm-ar' >> ~/.zshrc
echo 'export PATH=$(brew --prefix llvm)/bin:$PATH' >> ~/.zshrc
```

### Staging

> To perform staging development, you'll need a `.env.staging` file.

```bash
dfx deploy frontend --network staging --wallet cvthj-wyaaa-aaaad-aaaaq-cai
dfx deploy backend --network staging
```

### Beta

> To perform staging development, you'll need a `.env.beta` file.
> Note that beta frontend points to production (IC) backend.

```bash
dfx deploy frontend --network beta --wallet yit3i-lyaaa-aaaan-qeavq-cai
```

### IC

Ensure that you have [`dfx-orbit`](https://github.com/dfinity/orbit/tree/main/tools/dfx-orbit) installed and are using the correct station:

```
dfx-orbit station show
```

> To perform production development, you'll need a `.env.production` file for the frontend. Then:

```bash
DOCKER_BUILDKIT=1 docker build -f Dockerfile.frontend --progress=plain --build-arg network=ic -o target/ .

dfx-oisy request deploy frontend --network ic --wallet yit3i-lyaaa-aaaan-qeavq-cai
```

For the backend:

```bash
scripts/docker-build

dfx-orbit request canister install backend --mode upgrade --wasm out/backend.wasm.gz --arg-file out/backend.args.did
```

## Internationalization

Translations are handled in JSON file - for example [en.json](src/frontend/src/lib/i18n/en.json). We selected this format because they can easily be edited by third parties even without developer skills.

To add support for an additional language, proceed as following:

> Note that OISY's repo **does not** accept external contributions yet.

1. Copy `en.json` to a new filename reflecting the language ISO code (such as for example `zh-cn.json` for simplified Chinese).
2. Translate each key of the newly created file.
3. Replace the file imported in [i18n.store.ts](src/frontend/src/lib/stores/i18n.store.ts).

In the future, OISY might be extended to support multiple languages on production.

### Adding additional keys

Translations are handled in JSON files but, as we are consuming these through a store, their representation have to exist as interfaces. To ease the process we have developed a script which extracts the declarations automatically. In case you would add new keys, `run npm run i18n` to generate the interfaces.

## Faucets

A list of useful faucets:

- Ethereum and EVM networks:
  - ETH: [Alchemy mixed faucets](https://www.alchemy.com/faucets/)
  - BNB: [BNB Testnet Faucet](https://www.bnbchain.org/en/testnet-faucet)
  - Polygon: [Polygon Testnet Faucet](https://faucet.polygon.technology/)
  - USDC and EURC: [Circle faucet](https://faucet.circle.com/)
  - ERC20: [Weenus 💪 Token Faucet](https://github.com/bokkypoobah/WeenusTokenFaucet)
  - Others:
    - ChainLink: [all faucets](https://faucets.chain.link/)
- Bitcoin: [Coinfaucet](https://coinfaucet.eu/en/btc-testnet/)
- SOL: [Solana Foundation Faucet](https://faucet.solana.com/) or [Sol Faucet](https://solfaucet.com/)
- TESTICP: [TESTICP Faucet](https://nqoci-rqaaa-aaaap-qp53q-cai.icp0.io/)
- TICRC1: [TICRC1 Faucet](https://pwwqf-yaaaa-aaaap-qp5wq-cai.icp0.io/)

## Testing

This section provides information about testing procedures.

### E2E visual comparisons

To implement a test that compares snapshots, follow these steps:

1. Add an e2e test in the `./e2e` directory.
2. Implement the test using `await expect(page).toHaveScreenshot()` to compare screenshots.
3. Run the e2e test locally using `npm run e2e:snapshots` to generate the screenshots.
4. Run the e2e test locally again using `npm run e2e` to validate the test.
5. Add the generated screenshots to Git.
6. Create a PR for your changes.
7. Open the GitHub Actions page and navigate to [Update E2E snapshots](https://github.com/dfinity/oisy-wallet/actions/workflows/update-snapshots.yml).
8. Manually trigger the generation of screenshots for the CI by running the workflow using your PR or branch.

This last step will generate the screenshots for the CI and add them to your PR. You can trigger this job again anytime you make changes, regardless of whether the test itself changes.

#### Notes

- We develop on macOS, while GitHub Actions use Linux. Therefore, there are two sets of screenshots: `darwin` for macOS and `linux` for Linux.
- For more information, refer to the Playwright [documentation](https://playwright.dev/docs/test-snapshots).

## Integrate ckERC20 Tokens

While the weekly GitHub Action that runs the job [./scripts/build.tokens.ckerc20.ts] helps discover new ckERC20 tokens deployed on the IC mainnet for testnet purposes or through proposals for effective production usage, some manual steps are still required to integrate them within OISY.

The steps are as follows:

1. **Collect the Ethereum logo** for the specific token as an SVG, ideally from an official source. Ensure using the logo in OISY respects brand/trade guidelines.
2. **Verify the SVG asset size** is acceptable (small) and **copy** it into [src/frontend/src/icp-eth/assets].
3. Create a new source environment file in [src/frontend/src/env] by cloning [src/frontend/src/env/tokens.usdc.env.ts] and renaming `usdc` to the token's name.
4. **Adapt the content of the tokens:**
   1. Find the contract address on the ckETH dashboard [production](https://sv3dd-oaaaa-aaaar-qacoa-cai.raw.icp0.io/dashboard) or [testnet](https://jzenf-aiaaa-aaaar-qaa7q-cai.raw.icp0.io/dashboard) in the table "Supported ckERC20 tokens".
   2. Obtain the token name, decimals, and symbol on Etherscan using the contract address (Select "Contract > Read contract" to query various information from the ABI).
5. **Set up the token** for the Ethereum network by listing the new token in the twin tokens arrays of [src/frontend/src/env/tokens.erc20.env.ts].
6. **Create the mapping for the new token** in [src/frontend/src/env/networks.icrc.env.ts]. This step sets up the token as a ck token, statically establishes the link between the token on the Ethereum network and its twin token on the IC network, and lists the token in the ICRC tokens and ledgers.

Note that setting up the twin token counterpart or collecting their logo is unnecessary. This information is automatically fetched at runtime from the ckETH orchestrator and the related ledger.

To help with steps 3 to 5, one can use the script [./scripts/add.tokens.erc20.mjs] (or [./scripts/add.tokens.erc20.sh]) to generate the environment files for the new tokens. It requires the EtherScan API key to fetch the token information from the Ethereum network, to be set in the `.env` file as `VITE_ETHERSCAN_API_KEY`.
The script will run through the supported ckERC20 tokens in the production dashboard and will automatically generate the necessary environment files for the new tokens that have a respective testnet token, and that do not yet exist in the repository.
Please be aware of the instructions provided by the script and follow them accordingly, if there are any, and possibly double-check the generated files.

## Bitcoin

Some setup is necessary to be able to develop locally with Bitcoin tokens.

There are three necessary items before starting to develop locally:

- Environment variables.
- Local Bitcoin node running (regtest).
- Start dfx with bitcoin.

### Bitcoin Environment Variables

The following var should be disabled or completely absent in `.env.development`.

```
VITE_BITCOIN_MAINNET_DISABLED=false    # or remove this line
```

### Bitcoin Development

There are some important notes related to the BTC development:

1. Wallet workers:
   - Locally, only the Regtest network wallet worker is launched
   - On all other ens (staging, beta, prod), we launch Testnet and Mainnet workers
2. Transactions:
   - To test them locally, you need to hardcode a mainnet BTC address with some txs inside. In the future, we plan to create mocks and use them during the local development.
   - Currently, only Mainnet transactions (uncertified) can be loaded on staging/beta/prod, since the Blockchain API we're using to fetch this data doesn't provide txs for testnet.

### Local Bitcoin Node (Or Regtest)

To interact with a Bitcoun network, we can set up a local test node.

The script to set it up and start running it is `./scripts/setup.bitcoin-node.sh`.

The first time you will run it withuot arguments:

```bash
./scripts/setup.bitcoin-node.sh
```

This script will download and set up a local bitcoin node from [Bitcoin.org](https://bitcoin.org/en/download).

Running this script again will start the node without doing the initial setup again.

**Resetting Node:**

It's recommended to reset the node from time to time:

```bash
./scripts/setup.bitcoin-node.sh --reset
```

### Start dfx with Bitcoin

Dfx needs to be aware that a Bitcoin node is running.

There is a script to run dfx with Bitcoin:

```bash
./scripts/dfx.start-with-bitcoin.sh
```

You can also run it by cleaning up the state:

```bash
./scripts/dfx.start-with-bitcoin.sh --clean
```

You would normally do this along resetting the bitcoin node as mentioned before.

**IMPORTANT: If you were running a local replica before without bitcoin, use the `--clean` flag.**

### Mining Bitcoins

To start testing Bitcoin feature you'll need some tokens.

For that, you can get the address of your test user from the UI and get yourlsef some bitcoins:

```bash
./scripts/add.tokens.bitcoin.sh --amount <amount-in-blocks> --address <test-user-address>
```

**One block equals 50 Bitcoin.**

### Mining After Transactions

Tokens transferred are not immediately available in the new destination.

Before they become available, there must be a new block mined. You can mine one:

```bash
./scripts/add.tokens.bitcoin.sh
```

# Routes Styles

The designer, or the foundation, might want to use different background colors for specific routes, such as using white generally speaking in the wallet and light blue on the signer (`/sign`) route.

On the other hand, we want to prerender the background color because, if we don’t, the user will experience a "glitchy" loading effect where the dapp initially loads with a white background before applying the correct color.

That's why, when there is such a specific requests, some CSS can be defined at the route level. CSS which is then prerendered within the generated HTML page at build time.

For example, if I wanted to add a route `/hello` with a red background, we would add the following files in `src`:

```
src/routes/(group)/hello/+page.svelte
src/routes/(group)/hello/+oisy.page.css
```

And in the CSS:

```css
:root {
	background: red;
}
```

Furthermore, given that parsing happens at build time, the developer might want to load the style at runtime for local development purposes. This can be achieved by importing the style in the related `+layout.svelte`:

```javascript
<script lang="ts">
	import { LOCAL } from '$lib/constants/app.constants';

	onMount(async () => {
		if (!LOCAL) {
			return;
		}
		await import('./+oisy.page.css');
	});
</script>
```

## Add EVM Networks

Below a summary of how to add a new EVM network (side-chains or layer-2).

### Pre-requisites

Before starting the integration, ensure the following:

- You have the **Chain ID** for both **mainnet** and any **testnet(s)**.
- The network is supported by key infrastructure providers:
  - [Alchemy](https://www.alchemy.com/)
  - [Infura](https://www.infura.io/)
  - [Etherscan](https://docs.etherscan.io/etherscan-v2)
- The network is already integrated in the [`ethers.js`](https://github.com/ethers-io/ethers.js) library.  
  If not, submit a request to the library maintainers or implement a custom extension as needed.

### Create network object(s)

Location: `src/frontend/src/env/networks/networks-evm/`

#### Steps

- Create a new file: `networks.<network>.env.ts`
- Copy contents from an existing EVM network file (e.g., `networks.bsc.env.ts`)
- Update the following fields:
  - `SYMBOL` – short identifier (e.g., `'BSC'`, `'ARB'`)
  - `NAME` – name of the network
  - `CHAIN ID` - chainId of the network
  - `ICONS` – for all themes &rarr; They should be in SVG format and placed in the `src/frontend/src/lib/assets/networks/{light,dark}` folder.
  - `EXPLORER URL` – to have these values, the `src/frontend/src/env/explorers.env.ts` file should be updated.
  - `PROVIDERS`:
    - `infura`
    - `alchemy`
    - `alchemyJsonRpcUrl`
  - `EXCHANGE` (Coingecko ID) - Update the `CoingeckoPlatformId` type if needed
  - `BUY` (Onramper ID) - Update the `OnramperNetworkId` type if needed

- Add testnet object(s): if there are testnets, create a similar object for each one.

Finally, make sure that the objects `SUPPORTED_<network>_NETWORKS` and `SUPPORTED_<network>_NETWORK_IDS` exist and are accordingly updated, at the end of the file.

For example, this is the mainnet object of `networks.bsc.env.ts`:

```typescript
export const BSC_MAINNET_NETWORK_SYMBOL = 'BSC';

export const BSC_MAINNET_NETWORK_ID: NetworkId = parseNetworkId(BSC_MAINNET_NETWORK_SYMBOL);

export const BSC_MAINNET_NETWORK: EthereumNetwork = {
	id: BSC_MAINNET_NETWORK_ID,
	env: 'mainnet',
	name: 'BNB Smart Chain',
	chainId: 56n,
	iconLight: bscMainnetIconLight,
	iconDark: bscMainnetIconDark,
	explorerUrl: BSC_EXPLORER_URL,
	providers: {
		infura: 'bnb',
		alchemy: 'bnb',
		alchemyJsonRpcUrl: 'https://bnb-mainnet.g.alchemy.com/v2'
	},
	exchange: { coingeckoId: 'binance-smart-chain' },
	buy: { onramperId: 'bsc' }
};
```

### Create native token object(s)

Location: `src/frontend/src/env/tokens/tokens-evm/`

#### Steps:

- Create a new folder: `tokens-<network>`
- Inside the folder, create a new file: `tokens.<token>.env.ts`
- Copy contents from another EVM network’s token file (e.g., `tokens.pol.env.ts`)

  ```typescript
  const POL_DECIMALS = 18;

  const POL_MAINNET_SYMBOL = 'POL';

  export const POL_MAINNET_TOKEN_ID: TokenId = parseTokenId(POL_MAINNET_SYMBOL);

  export const POL_MAINNET_TOKEN: RequiredToken = {
  	id: POL_MAINNET_TOKEN_ID,
  	network: POLYGON_MAINNET_NETWORK,
  	standard: 'ethereum',
  	category: 'default',
  	name: 'POL (prev. MATIC)',
  	symbol: POL_MAINNET_SYMBOL,
  	decimals: POL_DECIMALS,
  	icon: pol,
  	buy: {
  		onramperId: 'pol_polygon'
  	}
  };
  ```

- Update the following fields:
  - **Decimals** – token precision (e.g., `18`)
  - **Symbol** – short token symbol (e.g., `'POL'`, `'ARB'`)
  - **Network** – reference the network object created in the previous step
  - **Name** – display name of the token
  - **Icon** – SVG format, placed in `src/frontend/src/evm/<network>/assets` folder.
  - **Buy** – Onramper ID if applicable (e.g., `'pol_polygon'`)

- If the network includes testnet tokens, repeat the process for each testnet.

Finally, make sure that the object `SUPPORTED_<network>_TOKENS` exists and is accordingly updated, at the end of the file.

### Add network variant(s) to the Backend

In file `src/shared/src/types/network.ts`, add the network(s) variant to the `NetworkSettingsFor` enum, similar to the existing ones.

Furthermore, in the same file, add the chain ID(s) to the `EthereumNetworkId` enum, similar to the existing ones.

This process will generate new bindings. Once generated, the mapping of user networks must be updated manually:

1. Derived store `userNetworks` needs to map the new variant(s) to the respective network ID(s), similar to the existing ones.
2. Sub-function `networkIdToKey` of util `mapUserNetworks` needs to map the new network ID(s) to the respective network variant(s), similar to the existing ones.

### Include network(s) and token(s) in EVM List

After creating your network and token objects, make sure they are registered in the global EVM lists.

#### 1. Add the Network to `SUPPORTED_EVM_NETWORKS`

Location: `src/frontend/src/env/networks/networks-evm/networks.evm.env.ts`

Action: Add your constant to the `SUPPORTED_EVM_NETWORKS` list:

```ts
export const SUPPORTED_EVM_NETWORKS = [
	...SUPPORTED_BASE_NETWORKS,
	...SUPPORTED_BSC_NETWORKS,
	...SUPPORTED_POLYGON_NETWORKS,
	...(SUPPORTED_ < NETWORK > _NETWORKS)
];
```

#### 2. Add the Token to `SUPPORTED_EVM_TOKENS`

Location: `src/frontend/src/env/tokens/tokens-evm/tokens.evm.env.ts`

Action: Include your network's token list in the main EVM token array:

```ts
export const SUPPORTED_EVM_TOKENS = [
	...SUPPORTED_BASE_TOKENS,
	...SUPPORTED_BSC_TOKENS,
	...SUPPORTED_POLYGON_TOKENS,
	...(SUPPORTED_ < NETWORK > _TOKENS)
];
```

### Create derived store for enabled network(s)

Create file `src/frontend/src/evm/<network>/derived/networks.derived.ts`, by copying an existing one from the other EVM networks.

Then, update the content accordingly. For example:

```typescript
export const enabledPolygonNetworks: Readable<EthereumNetwork[]> = derived(
	[testnetsEnabled, userNetworks],
	([$testnetsEnabled, $userNetworks]) =>
		defineEnabledNetworks({
			$testnetsEnabled,
			$userNetworks,
			mainnetFlag: POLYGON_MAINNET_ENABLED,
			mainnetNetworks: [POLYGON_MAINNET_NETWORK],
			testnetNetworks: [POLYGON_AMOY_NETWORK]
		})
);
```

Finally, include it in derived store `enabledEvmNetworks`, in file `src/frontend/src/evm/derived/networks.derived.ts`:

```typescript
export const enabledEvmNetworks: Readable<EthereumNetwork[]> = derived(
	[enabledBaseNetworks, enabledBscNetworks, enabledPolygonNetworks],
	([$enabledBaseNetworks, $enabledBscNetworks, $enabledPolygonNetworks]) => [
		...$enabledBaseNetworks,
		...$enabledBscNetworks,
		...$enabledPolygonNetworks
	]
);
```

### Create derived store for enabled token(s)

Create file `src/frontend/src/evm/<network>/derived/tokens.derived.ts`, by copying an existing one from the other EVM networks.

Then, update the content accordingly. For example:

```typescript
export const enabledPolygonTokens: Readable<RequiredToken[]> = derived(
	[testnetsEnabled, userNetworks],
	([$testnetsEnabled, $userNetworks]) =>
		defineEnabledTokens({
			$testnetsEnabled,
			$userNetworks,
			mainnetFlag: POLYGON_MAINNET_ENABLED,
			mainnetTokens: [POL_MAINNET_TOKEN],
			testnetTokens: [POL_AMOY_TOKEN]
		})
);
```

Finally, include it in derived store `enabledEvmTokens`, in file `src/frontend/src/evm/derived/tokens.derived.ts`:

```typescript
export const enabledEvmTokens: Readable<RequiredToken[]> = derived(
	[enabledBaseTokens, enabledBscTokens, enabledPolygonTokens],
	([$enabledBaseTokens, $enabledBscTokens, $enabledPolygonTokens]) => [
		...$enabledBaseTokens,
		...$enabledBscTokens,
		...$enabledPolygonTokens
	]
);
```

### Define network default token

Each network should have a default token as fallback. To define one for EVM networks the following is required:

- Util function to check if a Network ID is a valid ID for the new network, in file `src/frontend/src/lib/utils/network.utils.ts`. For example:

```typescript
export const isNetworkIdBase: IsNetworkIdUtil = (id) =>
	nonNullish(id) && SUPPORTED_BASE_NETWORK_IDS.includes(id);
```

- Derived store to verify that the current network is the new network, in file `src/frontend/src/lib/derived/network.derived.ts`. For example:

```typescript
export const networkBase: Readable<boolean> = derived([networkId], ([$networkId]) =>
	isNetworkIdBase($networkId)
);
```

- The default token definition for the new network, in file `src/frontend/src/lib/constants/tokens.constants.ts`. For example:

```typescript
export const [DEFAULT_BASE_TOKEN] = SUPPORTED_BASE_TOKENS;
```

### Add ERC20 tokens to the list of supported tokens

If the new network supports ERC-20 tokens, they can be included among the supported tokens.

> [!TIP]
> Tokens standard that are an extension of the ERC-20 standard can be included too. For example BEP-20 of BNB Smart Chain can be treated the same as ERC-20 by OISY.

To do this, the following steps are required:

- Create a folder in `src/frontend/src/env/tokens/tokens-evm/tokens-<network>/` named `tokens-erc20`
- For each token:
  - Create a file named: `tokens.<token>.env.ts`
  - Copy content from a similar token file in another EVM network.
  - Update the following fields:
    - `name`
    - `symbol`
    - `decimals`
    - `network` (reference the correct network object)
    - `icon` (SVG format, placed in `evm/<network>/assets/`)

- If the token has similar bridged tokens on the other EVM networks or on IC, add the `groupData` property, similar to existing ones (for example USDC, USDT, etc.).

Once all the new ERC20 tokens are created, they need to be added to the list of supported tokens:

- Create a new list <network>\_ERC20_TOKENS in `src/frontend/src/env/tokens/tokens-evm/tokens-<network>/tokens.erc20.env.ts`, similar to the existing ones for other EVM networks.
- Add the list to the `EVM_ERC20_TOKENS` list in `src/frontend/src/env/tokens/tokens-evm/tokens.erc20.env.ts`.

### Adapt exchange rate workers

In the first step, the exchange IDs and required fields should have been already be set. Now, the worker needs to be updated to include the new network.

- In service `syncExchange` of the exchange worker in file `src/frontend/src/lib/workers/exchange.worker.ts`, add the new network in the filter for the ERC-20 price parameters. As example, when this document was written, the filter was:

```typescript
if (
	coingeckoId !== 'ethereum' &&
	coingeckoId !== 'base' &&
	coingeckoId !== 'binance-smart-chain' &&
	coingeckoId !== 'polygon-pos'
) {
	return acc;
}
```

- Set the price for the native token(s) that are not a fork of ETH token:
  - Create a price-fetching function similar to the existing ones in file `src/frontend/src/lib/services/exchange.services.ts`. For example:

```typescript
export const exchangeRateBNBToUsd = (): Promise<CoingeckoSimplePriceResponse | null> =>
	simplePrice({
		ids: 'binancecoin',
		vs_currencies: Currency.USD
	});
```

- Use the function created above in the worker to fetch the price of the new token(s) in service `syncExchange` of the exchange worker in file `src/frontend/src/lib/workers/exchange.worker.ts`. Adapt the types if necessary.
- Map the new token ID(s) to the correct price in the `exchanges` derived store in file `src/frontend/src/lib/derived/exchange.derived.ts`, similar to the existing ones.
- Set the price for the native token(s) that are a fork of ETH token:
  - Just map the new token ID(s) to the ETH price in the `exchanges` derived store in file `src/frontend/src/lib/derived/exchange.derived.ts`, similar to the existing ones.

### Add providers' URLs to Content Security Policy (CSP)

The script that builds the CSP is `scripts/build.csp.mjs`.
It must be updated to include the new network providers' URLs (and any other required URL), similar to the existing ones.

### Optional

- Define a custom Hero color palette for the new network in `src/frontend/src/lib/components/hero/HeroContent.svelte`, similar to the existing ones.
- If provided, please add any additional information that might be useful for the new network. For example, a specific faucet to the list in this same document.

> [!NOTE]
> Remember to adapt all the existing tests and create new ones where needed, including E2E tests.

## Build Frontend Locally with Docker

To test building the frontend locally with Docker and inspect the results, follow these steps:

### 1. Build the Docker image

```bash
docker build . --file Dockerfile.frontend -t oisy-wallet --progress=plain
```

2. Copy the build output to your machine

```bash
docker create --name oisy-wallet oisy-wallet /bin/true
docker cp oisy-wallet:/frontend ./tmp/frontend-output
docker rm oisy-wallet
```

> Notes:
>
> - Our final image uses `FROM scratch`, it has no default command or shell. To work around this, we specify a dummy command (`/bin/true`) when creating the container.
> - Run `mkdir -p ./tmp` to ensure the folder exists before copying files into it.

3. Serve the results locally (optional)

```bash
npx serve ./tmp/frontend-output
```



================================================
FILE: HOW-TO.md
================================================
# How-to

This document provides valuable information regarding OISY Wallet integration and features.

## SNS Token Support

The [SNS aggregator](https://3r4gx-wqaaa-aaaaq-aaaia-cai.icp0.io/) is used to pre-populate the list of available SNSes.
This information is not fetched at runtime because it does not change frequently. Moreover, this approach is best suited
for a smoother UI/UX experience.

> Note: Some SNSes may not be enabled due to their related Index canister version being outdated and therefore not
> compatible with OISY Wallet. If you wish to use these, contact the related project to propose an upgrade to their
> canister.

See script [./script/build.sns.tokens.mjs](./scripts/build.sns.tokens.mjs) for more details.

## Custom ICRC Token Integration

OISY Wallet allows users to add
custom [ICRC](https://internetcomputer.org/docs/current/developer-docs/defi/overview/#icrc-1-ledgers) tokens to their
wallet. However, certain requirements must be met to ensure compatibility and security.

This chapter outlines the necessary steps and considerations for integrating a custom token into OISY Wallet.

### Requirements

To add a custom token to OISY Wallet, users must provide both a Ledger and Index canister ID. The Ledger canister ID is
straightforward, representing the ledger where the token transactions are recorded. However, the Index canister ID is
also required because OISY Wallet does not index transactions and balances. Instead, OISY reads balance and transactions
from an indexer, the Index canister.

### Index Canister

Custom tokens seeking compatibility with OISY Wallet can choose one of the following options for the Index canister:

1. Spin up an Index canister on mainnet using the index-ng WASM.

2. Provide a custom canister that implements specific functions.

### Index-ng

The source code of the Index-ng canister can be found in the Internet Computer
main [repository](https://github.com/dfinity/ic/tree/master/rs/ledger_suite/icrc1/index-ng) and can be downloaded using
the following script:

```bash
#!/bin/bash

IC_COMMIT="43f31c0a1b0d9f9ecbc4e2e5f142c56c7d9b0c7b"

curl -sSL https://download.dfinity.systems/ic/$IC_COMMIT/canisters/ic-icrc1-index-ng.wasm.gz -o "$DIR"/ckbtc_index.wasm.gz
gunzip "$DIR"/ckbtc_index.wasm.gz

curl -sSL https://raw.githubusercontent.com/dfinity/ic/$IC_COMMIT/rs/ledger_suite/icrc1/index-ng/index-ng.did -o "$DIR"/ckbtc_index.did
```

> Tips: You can follow
> this [guide](https://internetcomputer.org/docs/current/developer-docs/defi/icrc-1/icrc1-index-setup) to deploy an ICRC-1
> index canister locally.

### Custom Canister

If opting for a custom canister, it must implement the following two endpoints: one to retrieve the related Ledger
canister ID and one function to effectively provide the balance and transactions.

It's important to note that although both functions are queries, for security reasons, they are called with both query
and update.

> OISY uses the JavaScript
> library [@dfinity/ledger-icrc](https://github.com/dfinity/ic-js/tree/main/packages/ledger-icrc) to interact with the
> canister.

#### Ledger ID

This function is used to verify that the Index canister is indeed linked with the Ledger. It returns the principal of
the Ledger associated with the Index canister.

```
ledger_id : () -> (principal) query;
```

#### Get balance and transactions

This function allows querying of balance and transactions for a specific account. OISY Wallet uses the principal
provided by Internet Identity for the current account without a sub-account.

```
get_account_transactions : (GetAccountTransactionsArgs) -> (GetTransactionsResult) query;
```

Find more information in the
Index-ng [Candid file definition](https://github.com/dfinity/ic/blob/master/rs/ledger_suite/icrc1/index-ng/index-ng.did).



================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS



================================================
FILE: package.json
================================================
{
	"name": "@dfinity/oisy-wallet",
	"version": "1.7.6",
	"private": true,
	"license": "Apache-2.0",
	"repository": {
		"type": "git",
		"url": "git+https://github.com/dfinity/oisy-wallet.git"
	},
	"bugs": {
		"url": "https://github.com/dfinity/oisy-wallet"
	},
	"scripts": {
		"build:compress": "./scripts/build.compress.sh",
		"build:csp": "node scripts/build.csp.mjs",
		"build:metadata": "node scripts/build.metadata.mjs",
		"build:seo": "node scripts/build.seo.mjs",
		"build:style": "node scripts/build.style.mjs",
		"build:ic-domains": "node scripts/build.ic-domains.mjs",
		"build:ii-alternative-origins": "node scripts/build.ii-alternative-origins.mjs",
		"build:post-process": "npm run build:style && npm run build:metadata && npm run build:seo && npm run build:ic-domains && npm run build:ii-alternative-origins && npm run build:csp && npm run build:compress",
		"build:tokens-sns": "vite-node scripts/build.tokens.sns.ts && npm run format:file --file=src/frontend/src/env/tokens/tokens.sns.json",
		"build:tokens-ckerc20": "vite-node scripts/build.tokens.ckerc20.ts && npm run format:file --file=src/frontend/src/env/tokens/tokens.ckerc20.json",
		"build:tokens-icrc": "vite-node scripts/build.tokens.icrc.ts && npm run format:file --file=src/frontend/src/env/tokens/tokens.icrc.json",
		"dev": "vite dev",
		"build": "tsc --noEmit && vite build && npm run build:post-process",
		"prepare": "svelte-kit sync",
		"preview": "vite preview",
		"check": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --fail-on-warnings",
		"check:watch": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --watch",
		"test": "tsc --project tsconfig.spec.json --noEmit && vitest",
		"test:coverage": "tsc --project tsconfig.spec.json --noEmit && vitest run --coverage",
		"test:debug": "ALLOW_LOGGING_FOR_DEBUGGING=true npm run test",
		"test:merge": "tsc --project tsconfig.spec.json --noEmit && vitest run --coverage --merge-reports",
		"cargo:test": "./scripts/test.backend.sh",
		"clippy": "./scripts/lint.rust.sh",
		"lint": "prettier --check --cache ${CI:+--cache-strategy content} './**/*.{ts,js,mjs,json,scss,css,svelte,html,md,yml,did}' && eslint --concurrency=auto --cache ${CI:+--cache-strategy content} .",
		"format:file": "prettier --write \"${npm_config_file}\" && eslint --fix \"${npm_config_file}\"",
		"format": "prettier --write --cache ${CI:+--cache-strategy content} './**/*.{ts,js,mjs,json,scss,css,svelte,html,md,yml,did}' && eslint --fix --concurrency=auto --cache ${CI:+--cache-strategy content} .",
		"format:backend": "./scripts/format.sh",
		"generate": "scripts/generate.sh",
		"deploy": "scripts/deploy.sh",
		"tags": "node_modules/.bin/semver $(git tag)",
		"i18n:types": "node scripts/i18n.generate.types.mjs && prettier --write ./src/frontend/src/lib/types/i18n.d.ts",
		"i18n:keys": "vite-node scripts/i18n.generate.keys.ts && prettier --write ./src/frontend/src/lib/i18n/",
		"i18n": "npm run i18n:types && npm run i18n:keys",
		"playwright:install": "playwright install --with-deps",
		"e2e": "npm run playwright:install && playwright test",
		"e2e:dev": "npm run playwright:install && NODE_ENV=development playwright test",
		"e2e:ci": "npm run playwright:install && playwright test --update-snapshots=changed --reporter=html,list",
		"e2e:snapshots": "npm run playwright:install && npx playwright test --update-snapshots=changed --reporter=list",
		"e2e:snapshots:dev": "npm run playwright:install && NODE_ENV=development npx playwright test --update-snapshots=changed --reporter=list",
		"e2e:report": "npx playwright show-report",
		"erc20:check": "vite-node scripts/check.tokens.erc20.ts",
		"update:agent": "npm rm @dfinity/{agent,auth-client,candid,principal,identity-secp256k1} && npm i @dfinity/{agent,auth-client,candid,principal} && npm i @dfinity/identity-secp256k1 -D",
		"update:ic-js": "npm rm @dfinity/{ckbtc,cketh,ic-management,ledger-icp,ledger-icrc,utils} && npm i @dfinity/{ckbtc,cketh,ledger-icp,ledger-icrc,utils} && npm i @dfinity/ic-management -D",
		"update:ic-js:next": "npm rm @dfinity/{ckbtc,cketh,ic-management,ledger-icp,ledger-icrc,utils} && npm i @dfinity/{ckbtc,cketh,ledger-icp,ledger-icrc,utils}@next && npm i @dfinity/ic-management@next -D",
		"update:signer": "npm rm @dfinity/oisy-wallet-signer && npm i @dfinity/oisy-wallet-signer",
		"update:signer:next": "npm rm @dfinity/oisy-wallet-signer && npm i @dfinity/oisy-wallet-signer@next",
		"update:agent:ic-js": "npm run update:ic-js && npm run update:agent",
		"update:agent:ic-js:next": "npm run update:ic-js:next && npm run update:agent",
		"update:gix-cmp": "npm rm @dfinity/gix-components && npm i @dfinity/gix-components",
		"update:gix-cmp:next": "npm rm @dfinity/gix-components && npm i @dfinity/gix-components@next",
		"update:oisy-eslint": "npm rm @dfinity/eslint-config-oisy-wallet && npm i @dfinity/eslint-config-oisy-wallet -D",
		"update:oisy-eslint:next": "npm rm @dfinity/eslint-config-oisy-wallet && npm i @dfinity/eslint-config-oisy-wallet@next -D"
	},
	"dependencies": {
		"@dfinity/agent": "^3.2.6",
		"@dfinity/auth-client": "^3.2.6",
		"@dfinity/candid": "^3.2.6",
		"@dfinity/ckbtc": "^4.0.4",
		"@dfinity/cketh": "^4.0.4",
		"@dfinity/gix-components": "^9.0.0",
		"@dfinity/ledger-icp": "^6.1.0",
		"@dfinity/ledger-icrc": "^4.1.0",
		"@dfinity/oisy-wallet-signer": "^1.1.0",
		"@dfinity/principal": "^3.2.6",
		"@dfinity/utils": "^3.2.0",
		"@dfinity/verifiable-credentials": "^1.1.0",
		"@dfinity/zod-schemas": "^2.1.0",
		"@metamask/detect-provider": "^2.0.0",
		"@noble/ed25519": "^2.3.0",
		"@noble/hashes": "^1.8.0",
		"@noble/secp256k1": "^2.3.0",
		"@reown/walletkit": "^1.3.0",
		"@solana-program/compute-budget": "^0.9.0",
		"@solana-program/system": "^0.8.1",
		"@solana-program/token": "^0.6.0",
		"@solana-program/token-2022": "^0.5.0",
		"@solana/kit": "^3.0.3",
		"@velora-dex/sdk": "^9.0.0",
		"@walletconnect/auth-client": "^2.1.2",
		"alchemy-sdk": "^3.6.5",
		"bitcoinjs-lib": "^6.1.7",
		"browser-image-compression": "^2.0.2",
		"buffer": "^6.0.3",
		"decimal.js": "^10.6.0",
		"ethers": "^6.15.0",
		"idb-keyval": "^6.2.2",
		"plausible-tracker": "^0.3.9",
		"svelte-confetti": "^2.3.2",
		"zod": "^4.1.12"
	},
	"devDependencies": {
		"@dfinity/eslint-config-oisy-wallet": "^0.2.2",
		"@dfinity/ic-management": "^7.1.1",
		"@dfinity/identity-secp256k1": "^3.2.6",
		"@dfinity/internet-identity-playwright": "^0.0.5",
		"@playwright/test": "^1.56.0",
		"@rollup/plugin-inject": "^5.0.5",
		"@sveltejs/adapter-static": "^3.0.10",
		"@sveltejs/kit": "^2.46.4",
		"@sveltejs/vite-plugin-svelte": "^6.2.1",
		"@tailwindcss/postcss": "4.1.14",
		"@testing-library/jest-dom": "^6.9.1",
		"@testing-library/svelte": "^5.2.8",
		"@types/dom-view-transitions": "^1.0.5",
		"@types/node": "^22.13.4",
		"@vitest/coverage-v8": "^3.2.4",
		"dotenv": "^17.2.3",
		"fake-indexeddb": "^6.2.3",
		"jsdom": "^26.1.0",
		"jsqr": "^1.4.0",
		"pem-file": "^1.0.1",
		"postcss": "^8.5.6",
		"prettier": "^3.5.3",
		"prettier-plugin-motoko": "^0.12.1",
		"prettier-plugin-organize-imports": "^4.3.0",
		"prettier-plugin-svelte": "^3.4.0",
		"prettier-plugin-tailwindcss": "^0.6.14",
		"sass": "^1.93.2",
		"svelte": "^5.39.11",
		"svelte-check": "^4.3.3",
		"tailwindcss": "4.1.14",
		"tslib": "^2.8.1",
		"typescript": "^5.4.5",
		"vite": "^7.1.9",
		"vite-node": "^3.2.4",
		"vitest": "^3.1.1",
		"vitest-mock-extended": "^3.1.0"
	},
	"type": "module",
	"overrides": {
		"@ethersproject/providers": {
			"ws": "^7.5.10"
		},
		"elliptic": "^6.6.1",
		"cookie": "^0.7.0"
	},
	"engines": {
		"npm": ">=10.9.0 <11.0.0",
		"node": "^22"
	}
}



================================================
FILE: playwright.config.ts
================================================
import { notEmptyString } from '@dfinity/utils';
import { defineConfig, devices } from '@playwright/test';
import dotenv, { type DotenvPopulateInput } from 'dotenv';
import { join } from 'node:path';
import { readCanisterIds } from './env.utils';

dotenv.config({
	path: join(process.cwd(), '.env.e2e')
});

dotenv.populate(
	process.env as DotenvPopulateInput,
	readCanisterIds({
		filePath: join(process.cwd(), 'canister_e2e_ids.json'),
		prefix: 'E2E_'
	})
);

const DEV = (process.env.NODE_ENV ?? 'production') === 'development';

const MATRIX_OS = process.env.MATRIX_OS ?? '';
const isMac = notEmptyString(MATRIX_OS)
	? MATRIX_OS.includes('macos')
	: process.platform === 'darwin';

const appleProjects = [
	{
		name: 'Safari',
		use: devices['Desktop Safari']
	},
	{
		name: 'Google Chrome',
		use: devices['Desktop Chrome']
	},
	{
		name: 'iPhone SE',
		use: {
			...devices['iPhone SE'],
			screen: { width: 375, height: 667 },
			viewport: { width: 375, height: 667 }
		}
	},
	{
		name: 'iPad Pro 11',
		use: {
			...devices['iPad Pro 11'],
			screen: { width: 633, height: 1194 },
			viewport: { width: 633, height: 1194 }
		}
	}
];

const nonAppleProjects = [
	{
		name: 'Google Chrome',
		use: devices['Desktop Chrome']
	},
	{
		name: 'Firefox',
		use: devices['Desktop Firefox']
	},
	{
		name: 'Pixel 7',
		use: {
			...devices['Pixel 7'],
			screen: { width: 412, height: 915 },
			viewport: { width: 412, height: 915 }
		}
	}
];

const TIMEOUT = 5 * 60 * 1000;

export default defineConfig({
	retries: 3,
	timeout: TIMEOUT,
	workers: 5,
	expect: {
		toHaveScreenshot: {
			threshold: 0.3,
			// disable any animations caught by playwright for better screenshots and less flaky tests
			animations: 'disabled',
			// hide caret for cleaner snapshots
			caret: 'hide',
			// apply masks to hide flaky elements
			stylePath: 'e2e/styles/masks.css'
		}
	},
	webServer: {
		command: DEV ? 'npm run dev' : 'npm run build && npm run preview',
		reuseExistingServer: true,
		port: DEV ? 5173 : 4173,
		timeout: TIMEOUT
	},
	testDir: 'e2e',
	testMatch: ['**/*.e2e.ts', '**/*.spec.ts'],
	snapshotDir: 'e2e/snapshots',
	use: {
		testIdAttribute: 'data-tid',
		trace: 'on',
		actionTimeout: TIMEOUT,
		navigationTimeout: TIMEOUT,
		...(DEV && { headless: false })
	},
	projects: isMac ? appleProjects : nonAppleProjects
});



================================================
FILE: postcss.config.mjs
================================================
import tailwindcss from '@tailwindcss/postcss';

export default {
	plugins: [tailwindcss]
};



================================================
FILE: rust-toolchain.toml
================================================
[toolchain]
channel = "1.90.0"
targets = ["wasm32-unknown-unknown"]



================================================
FILE: rustfmt.toml
================================================
edition = "2021"
wrap_comments = true
comment_width = 120
imports_granularity = "Crate"
group_imports = "StdExternalCrate"
reorder_impl_items = true


================================================
FILE: SECURITY.md
================================================
# Security Policy

DFINITY takes the security of our software products seriously, which includes all source code repositories under the [DFINITY](https://github.com/dfinity) GitHub organization.

<!-- prettier-ignore-start -->
> [!IMPORTANT]  
> [DFINITY Foundation](https://dfinity.org) has a [Internet Computer (ICP) Bug Bounty program](https://dfinity.org/bug-bounty/) that rewards researchers for finding and reporting vulnerabilities in the Internet Computer. Please check the scope and eligibility criteria outlined in the policy to see if the vulnerability you found qualifies for a reward.
<!-- prettier-ignore-end -->

## How to report a vulnerability

We appreciate your help in keeping our projects secure.
If you believe you have found a security vulnerability in any of our repositories, please report it resonsibly to us as described below:

1. **Do not disclose the vulnerability publicly.** Public disclosure could be exploited by attackers before it can be fixed.
2. **Send an email to securitybugs@dfinity.org.** Please include the following information in your email:
   - A description of the vulnerability
   - Steps to reproduce the vulnerability
   - Risk rating of the vulnerability
   - Any other relevant information

We will respond to your report within 72 hours and work with you to fix the vulnerability as soon as possible.

### Security Updates

We are committed to fixing security vulnerabilities in a timely manner. Once a security vulnerability is reported, we will:

- Investigate the report and confirm the vulnerability.
- Develop a fix for the vulnerability.
- Release a new version of the project that includes the fix.
- Announce the security fix in the project's release notes.

## Preferred Language

We prefer all communications to be in English.

## Disclaimer

This security policy is subject to change at any time.



================================================
FILE: svelte.config.js
================================================
import adapter from '@sveltejs/adapter-static';
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte';
import { readFileSync } from 'node:fs';
import { fileURLToPath } from 'node:url';

const file = fileURLToPath(new URL('package.json', import.meta.url));
const json = readFileSync(file, 'utf8');
const { version } = JSON.parse(json);

const filesPath = (/** @type {string} */ path) => `src/frontend/${path}`;

/** @type {import('@sveltejs/kit').Config} */
const config = {
	preprocess: vitePreprocess(),

	kit: {
		adapter: adapter({
			fallback: 'index.html',
			precompress: false
		}),
		files: {
			assets: filesPath('static'),
			lib: filesPath('src/lib'),
			routes: filesPath('src/routes'),
			appTemplate: filesPath('src/app.html')
		},
		alias: {
			$declarations: './src/declarations',
			$btc: './src/frontend/src/btc',
			$eth: './src/frontend/src/eth',
			$evm: './src/frontend/src/evm',
			$icp: './src/frontend/src/icp',
			$sol: './src/frontend/src/sol',
			'$icp-eth': './src/frontend/src/icp-eth',
			$env: './src/frontend/src/env',
			$routes: './src/frontend/src/routes'
		},

		serviceWorker: {
			register: false
		},

		version: {
			name: version
		}
	}
};

export default config;



================================================
FILE: tailwind.config.ts
================================================
import type { Config } from 'tailwindcss';
import defaultTheme from 'tailwindcss/defaultTheme';
import { themeVariables } from './src/frontend/src/lib/styles/tailwind/theme-variables';

export default {
	content: ['./src/**/*.{html,js,svelte,ts}'],
	theme: {
		fontFamily: {
			sans: ['CircularXX', 'sans-serif', ...defaultTheme.fontFamily.sans]
		},
		screens: {
			...defaultTheme.screens,
			...themeVariables.screens
		},
		colors: {
			// base colors, can be left in
			inherit: 'inherit',
			transparent: 'transparent',
			current: 'currentColor',
			black: 'rgb(0, 0, 0)',
			white: 'rgb(255 255 255)',

			// keeping off-white since there's currently no matching color var in figma even though its used
			'off-white': '#fcfaf6',

			// custom hero gradient colors
			...themeVariables.gradient
		},
		extend: {
			backgroundColor: themeVariables.background,
			gradientColorStops: themeVariables.background,
			borderColor: themeVariables.border,
			ringColor: themeVariables.border,
			textColor: themeVariables.foreground,
			backgroundImage: {
				'trump-token-hero-image':
					'url(/images/trump-token-hero-image.webp), linear-gradient(to bottom, #232bcc, #000797)',
				'vchf-token-hero-image':
					'url(/images/vchf-token-hero-image.webp), radial-gradient(#DA291C, #AD1207)',
				'veur-token-hero-image':
					'url(/images/veur-token-hero-image.webp), linear-gradient(180deg, #00319E, #00319E)'
			},
			backgroundSize: {
				'size-200': '200% 200%'
			},
			backgroundPosition: {
				'pos-0': '0% 0%',
				'pos-100': '100% 100%'
			},
			width: {
				sm: '576px',
				md: '768px'
			}
		}
	},
	plugins: []
} satisfies Config;



================================================
FILE: tsconfig.e2e.json
================================================
{
	"extends": "./tsconfig.spec.json",
	"include": [
		"ambient.d.ts",
		"./types/**/$types.d.ts",
		"./vite.config.ts",
		"./src/**/*.js",
		"./src/**/*.ts",
		"./src/**/*.svelte",
		"./tests/**/*.js",
		"./tests/**/*.ts",
		"./tests/**/*.svelte",
		"./vitest.config.ts",
		"./vitest.setup.ts",
		"./e2e/**/*.ts"
	]
}



================================================
FILE: tsconfig.eslint.json
================================================
{
	"extends": "./tsconfig.json",
	"include": [
		"ambient.d.ts",
		"non-ambient.d.ts",
		"./types/**/$types.d.ts",
		"./vite.config.js",
		"./vite.config.ts",
		"./src/**/*.js",
		"./src/**/*.ts",
		"./src/**/*.svelte",
		"./env.utils.ts",
		"./vitest.setup.ts",
		"./vitest.config.ts",
		"./tailwind.config.ts",
		"./svelte.config.js",
		"./postcss.config.mjs",
		"./playwright.config.ts",
		"./e2e/**/*.js",
		"./e2e/**/*.ts",
		"./scripts/*.mjs",
		"./scripts/*.ts",
		"./eslint.config.mjs",
		"./eslint-local-rules.cjs"
	],
	"exclude": [
		"./node_modules/**",
		"./src/frontend/service-worker.js",
		"./src/frontend/service-worker.ts",
		"./src/frontend/service-worker.d.ts"
	]
}



================================================
FILE: tsconfig.json
================================================
{
	"extends": "./.svelte-kit/tsconfig.json",
	"compilerOptions": {
		"allowJs": true,
		"checkJs": true,
		"esModuleInterop": true,
		"forceConsistentCasingInFileNames": true,
		"resolveJsonModule": true,
		"skipLibCheck": true,
		"sourceMap": true,
		"strict": true,
		"types": ["node", "@types/dom-view-transitions"]
	},
	"exclude": ["src/frontend/src/tests/**/*"]
}



================================================
FILE: tsconfig.spec.json
================================================
{
	"extends": "./tsconfig.json",
	"compilerOptions": {
		"paths": {
			"$declarations": ["./src/declarations"],
			"$declarations/*": ["./src/declarations/*"],
			"$btc": ["./src/frontend/src/btc"],
			"$btc/*": ["./src/frontend/src/btc/*"],
			"$eth": ["./src/frontend/src/eth"],
			"$eth/*": ["./src/frontend/src/eth/*"],
			"$evm": ["./src/frontend/src/evm"],
			"$evm/*": ["./src/frontend/src/evm/*"],
			"$icp": ["./src/frontend/src/icp"],
			"$icp/*": ["./src/frontend/src/icp/*"],
			"$sol": ["./src/frontend/src/sol"],
			"$sol/*": ["./src/frontend/src/sol/*"],
			"$icp-eth": ["./src/frontend/src/icp-eth"],
			"$icp-eth/*": ["./src/frontend/src/icp-eth/*"],
			"$env": ["./src/frontend/src/env"],
			"$env/*": ["./src/frontend/src/env/*"],
			"$lib": ["./src/frontend/src/lib"],
			"$lib/*": ["./src/frontend/src/lib/*"],
			"$tests": ["./src/frontend/src/tests"],
			"$tests/*": ["./src/frontend/src/tests/*"],
			"$routes": ["./src/frontend/src/routes"],
			"$routes/*": ["./src/frontend/src/routes/*"]
		},
		"types": ["vitest/globals", "@testing-library/jest-dom"]
	},
	"exclude": [],
	"include": [
		"ambient.d.ts",
		"./types/**/$types.d.ts",
		"./vite.config.ts",
		"./src/**/*.js",
		"./src/**/*.ts",
		"./src/**/*.svelte",
		"./tests/**/*.js",
		"./tests/**/*.ts",
		"./tests/**/*.svelte",
		"./vitest.config.ts",
		"./vitest.setup.ts",
		"./scripts/*.ts"
	]
}



================================================
FILE: vite.config.ts
================================================
import inject from '@rollup/plugin-inject';
import { sveltekit } from '@sveltejs/kit/vite';
import { basename, dirname, resolve } from 'node:path';
import { defineConfig, loadEnv, type UserConfig } from 'vite';
import { defineViteReplacements, readCanisterIds } from './vite.utils';

// npm run dev = local
// npm run build = local
// dfx deploy = local
// dfx deploy --network ic = ic
// dfx deploy --network beta = beta
// dfx deploy --network staging = staging
const network = process.env.DFX_NETWORK ?? 'local';

const config: UserConfig = {
	plugins: [sveltekit()],
	resolve: {
		alias: {
			$declarations: resolve('./src/declarations')
		}
	},
	build: {
		target: 'es2020',
		rollupOptions: {
			output: {
				manualChunks: (id) => {
					const folder = dirname(id);

					const lazy = ['@dfinity/nns', '@dfinity/nns-proto', 'html5-qrcode', 'qr-creator'];

					if (
						['@sveltejs', 'svelte', '@dfinity/gix-components', ...lazy].find((lib) =>
							folder.includes(lib)
						) === undefined &&
						folder.includes('node_modules')
					) {
						return 'vendor';
					}

					if (
						lazy.find((lib) => folder.includes(lib)) !== undefined &&
						folder.includes('node_modules')
					) {
						return 'lazy';
					}

					return 'index';
				}
			},
			// Polyfill Buffer for production build
			plugins: [
				inject({
					modules: { Buffer: ['buffer', 'Buffer'] }
				})
			],
			external: (id) => {
				// A list of file to exclude because we parse those manually with custom scripts.
				const filename = basename(id);
				return ['+oisy.page.css'].includes(filename);
			}
		}
	},
	// proxy /api to port 4943 during development
	server: {
		proxy: {
			'/api': 'http://localhost:4943'
		}
	},
	optimizeDeps: {
		esbuildOptions: {
			define: {
				global: 'globalThis'
			},
			plugins: [
				{
					name: 'fix-node-globals-polyfill',
					setup: (build) => {
						build.onResolve({ filter: /_virtual-process-polyfill_\.js/ }, ({ path }) => ({ path }));
					}
				}
			]
		}
	},
	worker: {
		format: 'es'
	}
};

export default defineConfig((): UserConfig => {
	// Expand environment - .env files - with canister IDs
	process.env = {
		...process.env,
		...loadEnv(
			network === 'ic'
				? 'production'
				: ['beta', 'staging'].includes(network)
					? network
					: 'development',
			process.cwd()
		),
		...readCanisterIds({ prefix: 'VITE_' })
	};

	return {
		...config,
		// Backwards compatibility for auto generated types of dfx that are meant for webpack and process.env
		define: {
			'process.env': {
				...readCanisterIds({}),
				DFX_NETWORK: network
			},
			...defineViteReplacements()
		}
	};
});



================================================
FILE: vite.utils.ts
================================================
import { execSync } from 'node:child_process';
import { existsSync, readFileSync } from 'node:fs';
import { join } from 'node:path';
import { fileURLToPath } from 'node:url';
import { readCanisterIds as readIds } from './env.utils';
import OISY_DOMAINS from './scripts/domains.json' with { type: 'json' };

/**
 * Get the domain URL for a given DFX network
 * @param dfx_network - The DFX network name (e.g., 'ic', 'staging', 'beta', etc.)
 * @returns The domain URL for the network, or a default URL if not found
 */
const domain_for_dfx_network = (dfx_network: string): string => {
	if (dfx_network === 'local') {
		return 'http://localhost:4943';
	}
	const map = OISY_DOMAINS.frontend as Record<string, string>;
	return map[dfx_network] ?? `https://${dfx_network}.oisy.com`;
};

/**
 * Read all the locally deployed canister IDs. For example Oisy backend, ckBTC|ETH, ICP etc.
 * @param prefix
 */
const readLocalCanisterIds = ({ prefix }: { prefix?: string }): Record<string, string> => {
	const dfxCanisterIdsJsonFile = join(process.cwd(), '.dfx', 'local', 'canister_ids.json');
	const e2eCanisterIdsJsonFile = join(process.cwd(), 'canister_e2e_ids.json');
	return readIds({
		filePath: existsSync(dfxCanisterIdsJsonFile) ? dfxCanisterIdsJsonFile : e2eCanisterIdsJsonFile,
		prefix
	});
};

/**
 * Read Oisy staging and production canister IDs
 * @param prefix
 */
const readOisyCanisterIds = ({ prefix }: { prefix?: string }): Record<string, string> => {
	const canisterIdsJsonFile = join(process.cwd(), 'canister_ids.json');
	return readIds({ filePath: canisterIdsJsonFile, prefix });
};

/**
 * Read IC staging and production canister IDs. For example ckBTC staging and production but, also ICP ledger production
 * @param prefix
 */
const readRemoteCanisterIds = ({ prefix }: { prefix?: string }): Record<string, string> => {
	const dfxJsonFile = join(process.cwd(), 'dfx.json');

	try {
		interface DetailsId {
			ic: string;
			beta?: string;
			staging?: string;
		}

		interface Details {
			remote?: {
				id: DetailsId;
			};
		}

		interface DfxJson {
			canisters: Record<string, Details>;
		}

		const { canisters }: DfxJson = JSON.parse(readFileSync(dfxJsonFile, 'utf8'));

		return Object.entries(canisters).reduce((acc, current: [string, Details]) => {
			const [canisterName, canisterDetails] = current;

			if (canisterDetails.remote !== undefined) {
				const ids = Object.entries(canisterDetails.remote.id).reduce(
					(acc, [network, id]) => ({
						...acc,
						[`${prefix ?? ''}${network.toUpperCase().replaceAll('-', '_')}_${canisterName
							.replaceAll('-', '_')
							.replaceAll("'", '')
							.toUpperCase()}_CANISTER_ID`]: id
					}),
					{}
				);

				return {
					...acc,
					...ids
				};
			}

			return acc;
		}, {});
	} catch (e) {
		console.warn(`Could not get canisters ID from ${dfxJsonFile}: ${e}`);
		return {};
	}
};

export const readCanisterIds = (params: { prefix?: string }): Record<string, string> => ({
	...readLocalCanisterIds(params),
	...readOisyCanisterIds(params),
	...readRemoteCanisterIds(params)
});

export const defineViteReplacements = (): {
	VITE_OISY_DOMAIN: string;
	VITE_APP_VERSION: string;
	VITE_DFX_NETWORK: string;
	VITE_GIT_COMMIT_HASH: string;
	VITE_GIT_BRANCH_NAME: string;
} => {
	const file = fileURLToPath(new URL('package.json', import.meta.url));
	const json = readFileSync(file, 'utf8');
	const { version } = JSON.parse(json);

	// npm run dev = local
	// npm run build = local
	// npm run test = local
	// dfx deploy = local
	// dfx deploy --network ic = ic
	// dfx deploy --network staging = staging
	const network = process.env.DFX_NETWORK ?? 'local';

	const isTestFe = network.startsWith('test_fe_');

	const commitHash = isTestFe ? execSync('git rev-parse --short HEAD').toString().trim() : '';
	const branchName = isTestFe ? execSync('git rev-parse --abbrev-ref HEAD').toString().trim() : '';

	return {
		VITE_OISY_DOMAIN: JSON.stringify(domain_for_dfx_network(network)),
		VITE_APP_VERSION: JSON.stringify(version),
		VITE_DFX_NETWORK: JSON.stringify(network),
		VITE_GIT_COMMIT_HASH: JSON.stringify(commitHash),
		VITE_GIT_BRANCH_NAME: JSON.stringify(branchName)
	};
};



================================================
FILE: vitest.config.ts
================================================
import { sveltekit } from '@sveltejs/kit/vite';
import { svelteTesting } from '@testing-library/svelte/vite';
import { resolve } from 'path';
import type { UserConfig } from 'vite';
import { defineConfig } from 'vitest/config';
import { defineViteReplacements, readCanisterIds } from './vite.utils';

process.env = {
	...process.env,
	...readCanisterIds({ prefix: 'VITE_' })
};

export default defineConfig(
	(): UserConfig => ({
		plugins: [sveltekit(), svelteTesting()],
		resolve: {
			alias: [
				{
					find: '$lib',
					replacement: resolve(__dirname, 'src/frontend/src/lib')
				},
				{
					find: '$routes',
					replacement: resolve(__dirname, 'src/frontend/src/routes')
				},
				{
					find: '$btc',
					replacement: resolve(__dirname, 'src/frontend/src/btc')
				},
				{
					find: '$eth',
					replacement: resolve(__dirname, 'src/frontend/src/eth')
				},
				{
					find: '$evm',
					replacement: resolve(__dirname, 'src/frontend/src/evm')
				},
				{
					find: '$icp',
					replacement: resolve(__dirname, 'src/frontend/src/icp')
				},
				{
					find: '$sol',
					replacement: resolve(__dirname, 'src/frontend/src/sol')
				},
				{
					find: '$icp-eth',
					replacement: resolve(__dirname, 'src/frontend/src/icp-eth')
				},
				{
					find: '$tests',
					replacement: resolve(__dirname, 'src/frontend/src/tests')
				},
				{
					find: '$env',
					replacement: resolve(__dirname, 'src/frontend/src/env')
				},
				{
					find: '$declarations',
					replacement: resolve(__dirname, 'src/declarations')
				}
			]
		},
		define: {
			...defineViteReplacements()
		},
		test: {
			environment: 'jsdom',
			globals: true,
			watch: false,
			silent: false,
			setupFiles: ['./vitest.setup.ts'],
			include: ['src/frontend/src/**/*.{test,spec}.?(c|m)[jt]s?(x)'],
			coverage: {
				include: ['src/frontend/src'],
				exclude: ['src/frontend/src/routes/**/+page.ts', 'src/frontend/src/tests/**/*'],
				// TODO: increase the thresholds slowly up to an acceptable 90% at least
				thresholds: {
					autoUpdate: true,
					statements: 80.15,
					branches: 86.4,
					functions: 74.78,
					lines: 80.15
				}
			}
		}
	})
);



================================================
FILE: vitest.setup.ts
================================================
import { parseBoolEnvVar } from '$lib/utils/env.utils';
import { mockPage } from '$tests/mocks/page.store.mock';
import {
	allowLoggingForDebugging,
	disableConsoleLog,
	failTestsThatLogToConsole
} from '$tests/utils/console.test-utils';
import type { HttpAgent } from '@dfinity/agent';
import '@testing-library/jest-dom';
import { configure } from '@testing-library/svelte';
import 'fake-indexeddb/auto';
import { mock } from 'vitest-mock-extended';

// We mock ResizeObserver and element.animate because neither JSDOM nor Happy DOM supports them, while Svelte v5 requires them.
// Interesting related thread: https://github.com/testing-library/svelte-testing-library/issues/284
global.ResizeObserver = class ResizeObserver {
	observe() {
		// do nothing
	}
	unobserve() {
		// do nothing
	}
	disconnect() {
		// do nothing
	}
};

// eslint-disable-next-line local-rules/prefer-object-params
Element.prototype.animate = (
	_keyframes: Keyframe[] | PropertyIndexedKeyframes,
	options?: number | KeyframeAnimationOptions
): Animation => {
	const animation = {
		abort: vi.fn(),
		cancel: vi.fn(),
		finished: Promise.resolve()
		// Svelte v5 register onfinish
		// Source: https://github.com/sveltejs/svelte/blob/75f81991c27e9602d4bb3eb44aec8775de0713af/packages/svelte/src/internal/client/dom/elements/transitions.js#L386
		// onfinish: () => undefined
	} as unknown as Animation;

	setTimeout(
		// @ts-expect-error We are omitting the parameter of onfinish for simplicity reason and because Svelte v5 do not use those.
		() => animation.onfinish(),
		typeof options === 'number' ? options : Number(options?.duration ?? 0)
	);

	return animation;
};

Element.prototype.scrollTo = vi.fn();

vi.mock('$app/stores', () => ({
	page: mockPage
}));

vi.mock('$app/state', () => ({
	page: {}
}));

vi.mock(import('$lib/actors/agents.ic'), async (importOriginal) => {
	const actual = await importOriginal();
	return {
		...actual,
		// eslint-disable-next-line require-await
		getAgent: async () => mock<HttpAgent>()
	};
});

vi.mock('ethers/providers', () => {
	const provider = vi.fn();

	const plugin = vi.fn();

	const network = vi.fn();
	network.prototype.attachPlugin = vi.fn();

	return {
		EtherscanProvider: provider,
		InfuraProvider: provider,
		JsonRpcProvider: provider,
		EtherscanPlugin: plugin,
		Network: network
	};
});

vi.mock('idb-keyval', () => ({
	createStore: vi.fn(() => ({})),
	set: vi.fn(),
	get: vi.fn(),
	del: vi.fn(),
	clear: vi.fn(),
	delMany: vi.fn(),
	keys: vi.fn(() => []),
	update: vi.fn()
}));

failTestsThatLogToConsole();

const ALLOW_LOGGING_FOR_DEBUGGING = parseBoolEnvVar(
	process.env.ALLOW_LOGGING_FOR_DEBUGGING ?? import.meta.env.VITE_ALLOW_LOGGING_FOR_DEBUGGING
);

if (ALLOW_LOGGING_FOR_DEBUGGING) {
	allowLoggingForDebugging();
}

disableConsoleLog();

configure({
	testIdAttribute: 'data-tid'
});

window.matchMedia = vi.fn().mockImplementation((query) => ({
	matches: false,
	media: query,
	onchange: null,
	addListener: vi.fn(), // Deprecated
	removeListener: vi.fn(), // Deprecated
	addEventListener: vi.fn(),
	removeEventListener: vi.fn(),
	dispatchEvent: vi.fn()
}));



================================================
FILE: zizmor.yml
================================================
rules:
  cache-poisoning:
    ignore:
      # Staging is deployed with every commit to main, so needs to be fast, hence the use of caching.
      #
      # Similarly, deployments to test environments need to be fast, to make developers productive.
      #
      # Production builds are verified independently, so bad builds, due to cache poisoning
      # or any other reason, would be detected.
      - deploy-to-environment.yml



================================================
FILE: .dockerignore
================================================
# Various IDEs and Editors
.vscode/
.idea/
**/*~

# Mac OSX temporary files
.DS_Store
**/.DS_Store

# dfx temporary files
.dfx/

# rust and downloaded wasm|did files
target/

# frontend code
node_modules/
build/
.svelte-kit/
package/


vite.config.js.timestamp-*
vite.config.ts.timestamp-*

internet_identity.wasm
internet_identity.did

codes.txt

backend-v*.wasm.gz
scripts/build.ic-domains.test.actual.*

# Version control files
# Note: This can be either a file or a directory, depending on how git is configured.
.git
.git/



================================================
FILE: .env.e2e
================================================
VITE_EXCHANGE_DISABLED=true
VITE_PLAUSIBLE_ENABLED=false



================================================
FILE: .env.example
================================================
VITE_BITCOIN_MAINNET_DISABLED=true
VITE_ETHEREUM_MAINNET_DISABLED=true
VITE_SOLANA_MAINNET_DISABLED=true
VITE_ETHERSCAN_API_KEY=
VITE_INFURA_API_KEY=
VITE_ALCHEMY_API_KEY=
VITE_QUICKNODE_API_KEY=
VITE_WALLET_CONNECT_PROJECT_ID=
VITE_COINGECKO_API_KEY=
VITE_EXCHANGE_DISABLED=true
VITE_POUH_ENABLED=false
VITE_AUTH_ALTERNATIVE_ORIGINS=
VITE_ONRAMPER_API_KEY_DEV=pk_test_
VITE_ONRAMPER_API_KEY_PROD=pk_prod_
VITE_AI_ASSISTANT_CONSOLE_ENABLED=



================================================
FILE: .env.test
================================================
VITE_ETHERSCAN_API_KEY=
VITE_INFURA_API_KEY=
VITE_ALCHEMY_API_KEY=
VITE_QUICKNODE_API_KEY=
VITE_WALLET_CONNECT_PROJECT_ID=
VITE_LOCAL_POUH_ISSUER_CANISTER_ID=qbw6f-caaaa-aaaah-qdcwa-cai



================================================
FILE: .ls-lint.yml
================================================
ls:
  .js: kebab-case
  .ts: kebab-case
  .svelte: PascalCase

  src/frontend/src:
    .dir: kebab-case
    .js: kebab-case
    .ts: kebab-case
    .svelte: PascalCase

ignore:
  - .dfx
  - .git
  - .idea
  - .svelte-kit
  - build
  - node_modules
  - target
  - src/frontend/src/lib/ic-pub-key
  - src/frontend/src/routes
  - src/frontend/src/tests/fixtures



================================================
FILE: .node-version
================================================
22.14.0



================================================
FILE: .npmrc
================================================
engine-strict=true



================================================
FILE: .prettierignore
================================================
.DS_Store
node_modules
/build
/.svelte-kit
/package
.env
.env.*
!.env.example

# Ignore files for PNPM, NPM and YARN
pnpm-lock.yaml
package-lock.json
yarn.lock

/target

.dfx



================================================
FILE: .prettierrc
================================================
{
  "useTabs": true,
  "singleQuote": true,
  "trailingComma": "none",
  "printWidth": 100,
  "plugins": [
    "prettier-plugin-svelte",
    "prettier-plugin-organize-imports"
  ],
  "overrides": [
    {
      "files": "*.svelte",
      "options": {
        "plugins": [
          "prettier-plugin-svelte",
          "prettier-plugin-organize-imports",
          "prettier-plugin-tailwindcss"
        ],
        "tailwindStylesheet": "./src/frontend/src/lib/styles/global.scss",
        "parser": "svelte",
        "htmlWhitespaceSensitivity": "strict"
      }
    },
    {
      "files": "*.did",
      "options": {
        "plugins": [
          "prettier-plugin-svelte",
          "prettier-plugin-organize-imports",
          "prettier-plugin-motoko"
        ],
        "semi": false
      }
    }
  ]
}



================================================
FILE: docker/deploy
================================================
#!/usr/bin/env bash

source /home/apprunner/.bashrc

dfx start --background --quiet

./docker/wait-port "$DFX_PORT"

npm run deploy

dfx stop



================================================
FILE: docker/replica
================================================
#!/usr/bin/env bash

source /home/apprunner/.bashrc

# https://docs.docker.com/config/containers/multi-service_container/
# turn on bash's job control
set -m

# The default bind address of dfx is 127.0.0.1:4943. We have to use 0.0.0.0:4943 otherwise Docker cannot expose the port.
dfx start --host 0.0.0.0:"$DFX_PORT" --quiet &

./docker/wait-port "$DFX_PORT"

REPLICA_PORT="$(dfx info replica-port)"
./docker/wait-port "$REPLICA_PORT"

# In case we ever want to re-deploy or configure anything when the image is running. This can be implemented here.

# now we bring the primary process back into the foreground
# and leave it there
fg %1



================================================
FILE: docker/wait-port
================================================
#!/bin/bash

#source https://stackoverflow.com/a/70181222/5404186

for _ in $(seq 1 20); do
  echo -n .
  if nc -z localhost "$1"; then
    echo "✅ Connection to port $1 succeeded."
    exit 0
  fi
  sleep 0.5
done

echo "❌ Connection to port $1 failed!"

exit 1



================================================
FILE: e2e/about-why-oisy-modal.spec.ts
================================================
import { ABOUT_WHY_OISY_BUTTON, ABOUT_WHY_OISY_MODAL } from '$lib/constants/test-ids.constants';
import { test } from '@playwright/test';
import { MODALS_VIEWPORT_WIDTH } from './utils/constants/e2e.constants';
import { HomepageLoggedOut } from './utils/pages/homepage.page';

const ABOUT_WHY_OISY_MODAL_VIEWPORT_HEIGHT = 1600;

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
test.skip('should display about-why-oisy modal', async ({ page, isMobile }) => {
	const homepageLoggedOut = new HomepageLoggedOut({
		page,
		viewportSize: !isMobile
			? {
					width: MODALS_VIEWPORT_WIDTH,
					height: ABOUT_WHY_OISY_MODAL_VIEWPORT_HEIGHT
				}
			: undefined
	});

	await homepageLoggedOut.waitForReady();

	await homepageLoggedOut.testModalSnapshot({
		modalOpenButtonTestId: ABOUT_WHY_OISY_BUTTON,
		modalTestId: ABOUT_WHY_OISY_MODAL
	});
});



================================================
FILE: e2e/activity-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { ActivityPage } from './utils/pages/activity.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display activity page', async ({ page, iiPage, isMobile }) => {
	const activityPage = new ActivityPage({ page, iiPage, isMobile });

	await activityPage.waitForReady();

	await activityPage.takeScreenshot();
});



================================================
FILE: e2e/authentication.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { HomepageLoggedIn } from './utils/pages/homepage.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should sign-in', async ({ page, iiPage }) => {
	const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage });

	await homepageLoggedIn.waitForAuthentication();

	await homepageLoggedIn.waitForLoggedInIndicator();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should stay signed in after an interval', async ({ page, iiPage }) => {
	const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage });

	await homepageLoggedIn.waitForAuthentication();

	await homepageLoggedIn.checkIfStillLoggedIn();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should sign-out', async ({ page, iiPage }) => {
	const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage });

	await homepageLoggedIn.waitForAuthentication();
	await homepageLoggedIn.waitForLogout();
});



================================================
FILE: e2e/enable-testnets.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { TestnetCases, TestnetsPage } from './utils/pages/testnets.page';

TestnetCases.forEach(({ networkSymbol, tokenSymbol }) => {
	testWithII.beforeEach(async ({ page }) => {
		await page.clock.install();
	});

	// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
	testWithII.skip(`should enable ${networkSymbol} network`, async ({ page, iiPage, isMobile }) => {
		const testnetsPage = new TestnetsPage({ page, iiPage, isMobile });
		await testnetsPage.waitForReady();
		await testnetsPage.enableTestnets({ networkSymbol, tokenSymbol });
		const tokenCardTestId = testnetsPage.getTokenCardTestId({ tokenSymbol, networkSymbol });
		await testnetsPage.takeScreenshot({
			freezeCarousel: true,
			centeredElementTestId: tokenCardTestId
		});
	});
});



================================================
FILE: e2e/explorer-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { ExplorerPage } from './utils/pages/explorer.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display explorer page', async ({ page, iiPage, isMobile }) => {
	const explorerPage = new ExplorerPage({ page, iiPage, isMobile });

	await explorerPage.waitForReady();

	await explorerPage.takeScreenshot();
});



================================================
FILE: e2e/guards-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { TRANSACTIONS_URL } from './utils/constants/e2e.constants';
import { HomepageLoggedIn } from './utils/pages/homepage.page';
import { TransactionsPage } from './utils/pages/transactions.page';

testWithII.beforeEach(async ({ page }) => {
	await page.clock.install();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip(
	'should be redirected to home if no network is provided to access transactions',
	async ({ page, iiPage }) => {
		// We load the transaction page for ICP. This way we know ICP is supported.
		const transactionsPage = new TransactionsPage({
			page,
			iiPage
		});

		await transactionsPage.waitForReady();

		// We go to transactions without network
		await page.goto(`${TRANSACTIONS_URL}?token=Internet%20Computer`);

		// We should be redirected to the home screen.
		const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage });

		await homepageLoggedIn.waitForContentReady();

		await homepageLoggedIn.takeScreenshot({ freezeCarousel: true });
	}
);



================================================
FILE: e2e/homepage.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { test } from '@playwright/test';
import { HomepageLoggedIn, HomepageLoggedOut } from './utils/pages/homepage.page';

test('should display homepage in logged out state', async ({ page }) => {
	const homepageLoggedOut = new HomepageLoggedOut({ page });

	await homepageLoggedOut.waitForReady();

	await homepageLoggedOut.takeScreenshot();
});

testWithII.beforeEach(async ({ page }) => {
	await page.clock.install();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip(
	'should display homepage in logged in state',
	async ({ page, iiPage, isMobile }) => {
		const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage, isMobile });

		await homepageLoggedIn.waitForReady();

		await homepageLoggedIn.takeScreenshot({ freezeCarousel: true });
	}
);



================================================
FILE: e2e/manage-tokens.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { MODALS_VIEWPORT_WIDTH, MODAL_VIEWPORT_HEIGHT } from './utils/constants/e2e.constants';
import { ManageTokensCases, ManageTokensPage } from './utils/pages/manage-tokens.page';

ManageTokensCases.forEach(({ type, tokenSymbol, networkSymbol }) => {
	testWithII.beforeEach(async ({ page }) => {
		await page.clock.install();
	});

	// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
	testWithII.skip(`should enable and disable ${type} token`, async ({ page, iiPage, isMobile }) => {
		const manageTokensPage = new ManageTokensPage({
			page,
			iiPage,
			isMobile,
			// TODO: check a better way to make the select network visible in the network switcher dropdown, otherwise the test will fail, since the network cannot be clicked
			viewportSize: !isMobile
				? {
						width: MODALS_VIEWPORT_WIDTH,
						height: MODAL_VIEWPORT_HEIGHT
					}
				: undefined
		});
		await manageTokensPage.waitForReady();
		await manageTokensPage.enableAndDisableToken({ tokenSymbol, networkSymbol });
	});
});



================================================
FILE: e2e/privacy-mode.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { HomepageLoggedIn } from './utils/pages/homepage.page';
import { FlowPage } from './utils/pages/send-and-receive-flow.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display privacy mode on homepage', async ({ page, iiPage, isMobile }) => {
	const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage, isMobile });

	await homepageLoggedIn.waitForReady();

	await homepageLoggedIn.activatePrivacyMode();

	await homepageLoggedIn.clickTokenGroupCard('ETH');

	await homepageLoggedIn.takeScreenshot({ freezeCarousel: true });
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip(
	'should display privacy mode on network selector',
	async ({ page, iiPage, isMobile }) => {
		const homepageLoggedIn = new HomepageLoggedIn({ page, iiPage, isMobile });

		await homepageLoggedIn.waitForReady();

		await homepageLoggedIn.activatePrivacyMode();

		await homepageLoggedIn.openNetworkSelector();

		await homepageLoggedIn.takeScreenshot({ freezeCarousel: true });
	}
);

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip(
	'should display privacy mode on transactions page',
	async ({ page, iiPage, isMobile }) => {
		const flowPage = new FlowPage({ page, iiPage, isMobile });

		await flowPage.waitForReady();

		await flowPage.receiveTokens();

		await flowPage.sendTokens();

		await flowPage.navigateToAssets();

		await flowPage.activatePrivacyMode();

		await flowPage.navigateToTransactionsPage({ tokenSymbol: 'ICP', networkSymbol: 'ICP' });

		await flowPage.takeScreenshot();
	}
);

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip(
	'should display privacy mode on activity page',
	async ({ page, iiPage, isMobile }) => {
		const flowPage = new FlowPage({ page, iiPage, isMobile });

		await flowPage.waitForReady();

		await flowPage.receiveTokens();

		await flowPage.sendTokens();

		await flowPage.navigateToActivity();

		await flowPage.activatePrivacyMode();

		await flowPage.takeScreenshot();
	}
);



================================================
FILE: e2e/receive-tokens-modal.spec.ts
================================================
import {
	RECEIVE_TOKENS_MODAL,
	RECEIVE_TOKENS_MODAL_BTC_MAINNET_SECTION,
	RECEIVE_TOKENS_MODAL_BTC_REGTEST_SECTION,
	RECEIVE_TOKENS_MODAL_BTC_TESTNET_SECTION,
	RECEIVE_TOKENS_MODAL_ETH_SECTION,
	RECEIVE_TOKENS_MODAL_ICP_SECTION,
	RECEIVE_TOKENS_MODAL_ICRC_SECTION,
	RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
	RECEIVE_TOKENS_MODAL_SOL_DEVNET_SECTION,
	RECEIVE_TOKENS_MODAL_SOL_MAINNET_SECTION
} from '$lib/constants/test-ids.constants';
import { testWithII } from '@dfinity/internet-identity-playwright';
import { MODALS_VIEWPORT_WIDTH } from './utils/constants/e2e.constants';
import { HomepageLoggedIn } from './utils/pages/homepage.page';
import { getReceiveTokensModalAddressLabelSelectors } from './utils/selectors.utils';

const RECEIVE_TOKENS_MODAL_VIEWPORT_HEIGHT = 900;
let homepageLoggedIn: HomepageLoggedIn;

testWithII.beforeEach(async ({ page, iiPage, isMobile }) => {
	await page.clock.install();

	homepageLoggedIn = new HomepageLoggedIn({
		page,
		iiPage,
		viewportSize: !isMobile
			? {
					width: MODALS_VIEWPORT_WIDTH,
					height: RECEIVE_TOKENS_MODAL_VIEWPORT_HEIGHT
				}
			: undefined
	});
	await homepageLoggedIn.waitForReady();
	await homepageLoggedIn.activateTestnetSettings();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display receive-tokens modal', async () => {
	await homepageLoggedIn.testModalSnapshot({
		modalOpenButtonTestId: RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
		modalTestId: RECEIVE_TOKENS_MODAL,
		selectorsToMock: getReceiveTokensModalAddressLabelSelectors([
			RECEIVE_TOKENS_MODAL_ICRC_SECTION,
			RECEIVE_TOKENS_MODAL_ICP_SECTION,
			RECEIVE_TOKENS_MODAL_ETH_SECTION,
			RECEIVE_TOKENS_MODAL_BTC_MAINNET_SECTION,
			RECEIVE_TOKENS_MODAL_BTC_TESTNET_SECTION,
			RECEIVE_TOKENS_MODAL_BTC_REGTEST_SECTION,
			RECEIVE_TOKENS_MODAL_SOL_MAINNET_SECTION,
			RECEIVE_TOKENS_MODAL_SOL_DEVNET_SECTION
		])
	});
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display correct QR codes for receiving ICP tokens', async () => {
	await homepageLoggedIn.testReceiveModalQrCode({
		receiveModalSectionSelector: RECEIVE_TOKENS_MODAL_ICP_SECTION
	});
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display correct QR codes for receiving ICRC tokens', async () => {
	await homepageLoggedIn.testReceiveModalQrCode({
		receiveModalSectionSelector: RECEIVE_TOKENS_MODAL_ICRC_SECTION
	});
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display correct QR codes for receiving ETH tokens', async () => {
	await homepageLoggedIn.testReceiveModalQrCode({
		receiveModalSectionSelector: RECEIVE_TOKENS_MODAL_ETH_SECTION
	});
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display correct QR codes for receiving SOL mainnet tokens', async () => {
	await homepageLoggedIn.testReceiveModalQrCode({
		receiveModalSectionSelector: RECEIVE_TOKENS_MODAL_SOL_MAINNET_SECTION
	});
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display correct QR codes for receiving SOL devnet tokens', async () => {
	await homepageLoggedIn.testReceiveModalQrCode({
		receiveModalSectionSelector: RECEIVE_TOKENS_MODAL_SOL_DEVNET_SECTION
	});
});



================================================
FILE: e2e/rewards-modal.spec.ts
================================================
import {
	REWARDS_MODAL,
	REWARDS_MODAL_DATE_BADGE,
	REWARDS_STATUS_BUTTON
} from '$lib/constants/test-ids.constants';
import { testWithII } from '@dfinity/internet-identity-playwright';
import { MODALS_VIEWPORT_WIDTH } from './utils/constants/e2e.constants';
import { RewardsPage } from './utils/pages/rewards-page';
import { getNestedSelector } from './utils/selectors.utils';

const REWARDS_MODAL_VIEWPORT_HEIGHT = 900;

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
// TODO: improve the test to mock the campaign in case there is none
testWithII.skip('should display rewards modal', async ({ page, iiPage, isMobile }) => {
	const rewardsPage = new RewardsPage({
		page,
		iiPage,
		viewportSize: !isMobile
			? {
					width: MODALS_VIEWPORT_WIDTH,
					height: REWARDS_MODAL_VIEWPORT_HEIGHT
				}
			: undefined
	});

	await rewardsPage.waitForReady();

	await rewardsPage.testModalSnapshot({
		modalOpenButtonTestId: REWARDS_STATUS_BUTTON,
		modalTestId: REWARDS_MODAL,
		selectorsToMock: [
			getNestedSelector({
				parentSelector: REWARDS_MODAL,
				innerSelector: REWARDS_MODAL_DATE_BADGE
			})
		]
	});
});



================================================
FILE: e2e/rewards-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { RewardsPage } from './utils/pages/rewards-page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
// TODO: Adjust test to new earn page instead of rewards page, when the feature is ready
testWithII.skip('should display rewards page', async ({ page, iiPage }) => {
	const rewardsPage = new RewardsPage({ page, iiPage });

	await rewardsPage.waitForReady();

	await rewardsPage.takeScreenshot();
});



================================================
FILE: e2e/send-and-receive-flow.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { FlowPage } from './utils/pages/send-and-receive-flow.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should receive and send ICP', async ({ page, iiPage, isMobile }) => {
	const flowPage = new FlowPage({ page, iiPage, isMobile });

	await flowPage.waitForReady();
	await flowPage.receiveTokens();
	await flowPage.sendTokens();
	await flowPage.takeScreenshot();
});



================================================
FILE: e2e/settings-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { SettingsPage } from './utils/pages/settings.page';

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display settings page', async ({ page, iiPage, isMobile }) => {
	const settingsPage = new SettingsPage({ page, iiPage, isMobile });

	await settingsPage.waitForReady();

	await settingsPage.takeScreenshot();
});



================================================
FILE: e2e/swap-modal.spec.ts
================================================
import {
	SWAP_TOKENS_MODAL,
	SWAP_TOKENS_MODAL_OPEN_BUTTON
} from '$lib/constants/test-ids.constants';
import { testWithII } from '@dfinity/internet-identity-playwright';
import { MODALS_VIEWPORT_WIDTH } from './utils/constants/e2e.constants';
import { HomepageLoggedIn } from './utils/pages/homepage.page';

const SWAP_TOKENS_MODAL_VIEWPORT_HEIGHT = 900;
let homepageLoggedIn: HomepageLoggedIn;

testWithII.beforeEach(async ({ page, iiPage, isMobile }) => {
	homepageLoggedIn = new HomepageLoggedIn({
		page,
		iiPage,
		viewportSize: !isMobile
			? {
					width: MODALS_VIEWPORT_WIDTH,
					height: SWAP_TOKENS_MODAL_VIEWPORT_HEIGHT
				}
			: undefined
	});
	await homepageLoggedIn.waitForReady();
});

// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
testWithII.skip('should display swap-tokens modal', async () => {
	await homepageLoggedIn.testModalSnapshot({
		modalOpenButtonTestId: SWAP_TOKENS_MODAL_OPEN_BUTTON,
		modalTestId: SWAP_TOKENS_MODAL
	});
});



================================================
FILE: e2e/transactions-page.spec.ts
================================================
import { testWithII } from '@dfinity/internet-identity-playwright';
import { TransactionCases, TransactionsPage } from './utils/pages/transactions.page';

TransactionCases.forEach(({ tokenSymbol, networkId, ...rest }) => {
	// TODO: E2E tests are failing and/or take too much time, we need to fix them slowly, so we skip them for now
	testWithII.skip(
		`should display ${tokenSymbol} transactions page for network ${networkId}`,
		async ({ page, iiPage }) => {
			const transactionsPage = new TransactionsPage({
				page,
				iiPage
			});
			await transactionsPage.waitForReady();
			await transactionsPage.showTransactions({ tokenSymbol, networkId, ...rest });
		}
	);
});



================================================
FILE: e2e/tsconfig.json
================================================
{
	"extends": "../tsconfig.e2e.json"
}



================================================
FILE: e2e/styles/masks.css
================================================
/* TODO: the carousel is too flaky for the E2E tests, so we need completely mask it and work on freezing it in a permanent state in another PR.*/
.carousel-container {
	visibility: hidden;
}



================================================
FILE: e2e/utils/qr-code.utils.ts
================================================
// TODO: uncomment and replace Jimp with native functions, unless the library bumps its dependency to zod to v4
export const getQRCodeValueFromDataURL = async ({
	dataUrl: _
}: {
	dataUrl: string;
	// eslint-disable-next-line arrow-body-style,require-await
}): Promise<string | undefined> => {
	return Promise.reject(new Error('Function `getQRCodeValueFromDataURL` not implemented'));

	// const qrBuffer = Buffer.from(dataUrl.replace(/^data:image\/[a-z]+;base64,/, ''), 'base64');
	// const image = await Jimp.read(qrBuffer);
	//
	// const imageData = {
	// 	data: new Uint8ClampedArray(image.bitmap.data),
	// 	width: image.bitmap.width,
	// 	height: image.bitmap.height
	// };
	//
	// const decodedQR = jsQR(imageData.data, imageData.width, imageData.height);
	//
	// if (nonNullish(decodedQR)) {
	// 	return decodedQR.data;
	// }
};



================================================
FILE: e2e/utils/selectors.utils.ts
================================================
import {
	RECEIVE_TOKENS_MODAL_ADDRESS_LABEL,
	RECEIVE_TOKENS_MODAL_QR_CODE_BUTTON
} from '$lib/constants/test-ids.constants';

/**
 * Generates a selector that can be used to query an inner element by specifying its parent
 */
export const getNestedSelector = ({
	parentSelector,
	innerSelector
}: {
	parentSelector: string;
	innerSelector: string;
}): string => `[data-tid="${parentSelector}"] >> [data-tid="${innerSelector}"]`;

export const getReceiveTokensModalAddressLabelSelector = ({
	sectionSelector
}: {
	sectionSelector: string;
}): string =>
	getNestedSelector({
		parentSelector: sectionSelector,
		innerSelector: RECEIVE_TOKENS_MODAL_ADDRESS_LABEL
	});

export const getReceiveTokensModalAddressLabelSelectors = (sectionSelectors: string[]): string[] =>
	sectionSelectors.map((sectionSelector) =>
		getReceiveTokensModalAddressLabelSelector({ sectionSelector })
	);

export const getReceiveTokensModalQrCodeButtonSelector = ({
	sectionSelector
}: {
	sectionSelector: string;
}): string =>
	getNestedSelector({
		parentSelector: sectionSelector,
		innerSelector: RECEIVE_TOKENS_MODAL_QR_CODE_BUTTON
	});



================================================
FILE: e2e/utils/commands/ledger-transfer.command.ts
================================================
import type { Command } from './runner';

interface LedgerTransferCommandParams {
	amount: string;
	recipient: string | undefined;
	memo?: number;
}

export class LedgerTransferCommand implements Command {
	readonly #amount: string;
	readonly #recipient: string | undefined;
	readonly #memo: number;

	constructor({ amount, recipient, memo = 0 }: LedgerTransferCommandParams) {
		this.#amount = amount;
		this.#recipient = recipient;
		this.#memo = memo;
	}

	toString(): string {
		return `dfx ledger transfer --memo ${this.#memo} --amount ${this.#amount} ${this.#recipient}`;
	}
}



================================================
FILE: e2e/utils/commands/runner.ts
================================================
import { exec, type ExecException } from 'child_process';
import { promisify } from 'util';

// Example Command + CommandRunner types
export interface Command {
	toString(): string;
}

export interface CommandRunner {
	exec(args: { command: Command }): Promise<string>;
}

const execAsync = promisify(exec);

// 1) Wrap 'exec' in a promise using promisify
const execPromise = ({
	command
}: {
	command: string;
}): Promise<{ stdout: string; stderr: string }> =>
	execAsync(command).catch((err: ExecException & { stdout: string; stderr: string }) => {
		// Mimic the original error handling: reject with new Error(stderr)
		throw new Error(err.stderr);
	});

// 2) LocalCommandRunner
export class LocalCommandRunner implements CommandRunner {
	async exec({ command }: { command: Command }): Promise<string> {
		try {
			const { stdout } = await execPromise({ command: command.toString() });
			return stdout;
		} catch (err: unknown) {
			if (err instanceof Error) {
				throw new Error(`Error executing command: ${err.message}`);
			}
			throw new Error(`Error executing command: ${JSON.stringify(err)}`);
		}
	}
}

// 3) createCommandRunner: always returns LocalCommandRunner
export const createCommandRunner = (): CommandRunner => new LocalCommandRunner();



================================================
FILE: e2e/utils/components/promotion-carousel.component.ts
================================================
import { CAROUSEL_CONTAINER, CAROUSEL_SLIDE_NAVIGATION } from '$lib/constants/test-ids.constants';
import type { Locator, Page } from '@playwright/test';

export class PromotionCarousel {
	#page: Page;

	constructor(page: Page) {
		this.#page = page;
	}

	public getCarouselSelector(): Locator {
		return this.#page.getByTestId(CAROUSEL_CONTAINER).filter({ visible: true });
	}

	public async freezeCarouselToSlide(slideNumber: number): Promise<void> {
		// TODO: the carousel is too flaky for the E2E tests, so we need completely mask it and work on freezing it in a permanent state in another PR.
		const navigationSelector1 = `[data-tid="${CAROUSEL_SLIDE_NAVIGATION}${slideNumber}"]:visible`;
		await this.#page.click(navigationSelector1);
		await this.#page.evaluate(() => {
			const slide = document.querySelector(`div[data-tid="carousel-slide"]`);
			if (slide) {
				slide.setAttribute(
					'style',
					// 'width: 1584px; ' +
					'transform: translate3d(-264px, 0px, 0px) !important; ' +
						'transition: none !important; ' +
						'animation: none !important;'
				);
			}
		});
	}
}



================================================
FILE: e2e/utils/constants/e2e.constants.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';

export const HOMEPAGE_URL = '/';
export const TRANSACTIONS_URL = AppPath.Transactions;

export const LOCAL_REPLICA_URL = 'http://127.0.0.1:4943';

export const MODALS_VIEWPORT_WIDTH = 800;
export const MODAL_VIEWPORT_HEIGHT = 900;



================================================
FILE: e2e/utils/pages/activity.page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	ACTIVITY_TRANSACTION_SKELETON_PREFIX,
	CAROUSEL_SLIDE_NAVIGATION,
	NAVIGATION_ITEM_ACTIVITY,
	NO_TRANSACTIONS_PLACEHOLDER
} from '$lib/constants/test-ids.constants';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

export type ActivityPageParams = HomepageLoggedInParams;

export class ActivityPage extends HomepageLoggedIn {
	constructor(params: ActivityPageParams) {
		super(params);
	}

	override async extendWaitForReady(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_ACTIVITY, expectedPath: AppPath.Activity });
		await this.getLocatorByTestId({ testId: CAROUSEL_SLIDE_NAVIGATION }).waitFor({
			state: 'hidden'
		});
		await this.waitForLoadState();

		await Promise.all(
			Array.from(
				{ length: 5 },
				async (_, i) =>
					await this.waitForByTestId({
						testId: `${ACTIVITY_TRANSACTION_SKELETON_PREFIX}-${i}`,
						options: { state: 'hidden', timeout: 60000 }
					})
			)
		);

		await this.waitForByTestId({
			testId: NO_TRANSACTIONS_PLACEHOLDER,
			options: { state: 'visible', timeout: 60000 }
		});
	}
}



================================================
FILE: e2e/utils/pages/explorer.page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	CAROUSEL_SLIDE_NAVIGATION,
	NAVIGATION_ITEM_EXPLORER
} from '$lib/constants/test-ids.constants';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

export type ExplorerPageParams = HomepageLoggedInParams;

export class ExplorerPage extends HomepageLoggedIn {
	constructor(params: ExplorerPageParams) {
		super(params);
	}

	override async extendWaitForReady(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_EXPLORER, expectedPath: AppPath.Explore });
		await this.getLocatorByTestId({ testId: CAROUSEL_SLIDE_NAVIGATION }).waitFor({
			state: 'hidden'
		});
		await this.waitForLoadState();
	}
}



================================================
FILE: e2e/utils/pages/homepage.page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	AMOUNT_DATA,
	LOADER_MODAL,
	LOGIN_BUTTON,
	LOGOUT_BUTTON,
	MANAGE_TOKENS_MODAL,
	MANAGE_TOKENS_MODAL_BUTTON,
	MANAGE_TOKENS_MODAL_SAVE,
	MANAGE_TOKENS_MODAL_TOKEN_TOGGLE,
	MOBILE_NAVIGATION_MENU,
	NAVIGATION_ITEM_HOMEPAGE,
	NAVIGATION_ITEM_SETTINGS,
	NAVIGATION_MENU,
	NAVIGATION_MENU_BUTTON,
	NAVIGATION_MENU_PRIVACY_MODE_BUTTON,
	NETWORKS_SWITCHER_DROPDOWN,
	NETWORKS_SWITCHER_SELECTOR,
	RECEIVE_TOKENS_MODAL,
	RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
	RECEIVE_TOKENS_MODAL_QR_CODE_OUTPUT,
	SETTINGS_ACTIVE_NETWORKS_EDIT_BUTTON,
	SETTINGS_NETWORKS_MODAL,
	SETTINGS_NETWORKS_MODAL_SAVE_BUTTON,
	SETTINGS_NETWORKS_MODAL_TESTNETS_CONTAINER,
	SETTINGS_NETWORKS_MODAL_TESTNET_CHECKBOX,
	SETTINGS_NETWORKS_MODAL_TESTNET_TOGGLE,
	SIDEBAR_NAVIGATION_MENU,
	TOKEN_BALANCE,
	TOKEN_CARD,
	TOKEN_GROUP
} from '$lib/constants/test-ids.constants';
import type { InternetIdentityPage } from '@dfinity/internet-identity-playwright';
import { isNullish, nonNullish } from '@dfinity/utils';
import { expect, type Locator, type Page, type ViewportSize } from '@playwright/test';
import { PromotionCarousel } from '../components/promotion-carousel.component';
import { HOMEPAGE_URL, LOCAL_REPLICA_URL } from '../constants/e2e.constants';
import { getQRCodeValueFromDataURL } from '../qr-code.utils';
import {
	getReceiveTokensModalAddressLabelSelector,
	getReceiveTokensModalQrCodeButtonSelector
} from '../selectors.utils';

interface HomepageParams {
	page: Page;
	viewportSize?: ViewportSize;
	isMobile?: boolean;
}

export type HomepageLoggedInParams = {
	iiPage: InternetIdentityPage;
} & HomepageParams;

interface SelectorOperationParams {
	selector: string;
}

interface TestIdOperationParams {
	testId: string;
}

interface WaitForModalParams {
	modalOpenButtonTestId: string;
	modalTestId: string;
	state?: 'detached';
}

interface TakeScreenshotParams {
	freezeCarousel?: boolean;
	centeredElementTestId?: string;
	screenshotTarget?: Locator;
}

type TestModalSnapshotParams = {
	selectorsToMock?: string[];
} & WaitForModalParams;

interface ClickMenuItemParams {
	menuItemTestId: string;
}

interface WaitForLocatorOptions {
	state: 'attached' | 'detached' | 'visible' | 'hidden';
	timeout?: number;
}

interface ShowSelectorParams {
	display?: 'block' | 'flex';
}

abstract class Homepage {
	readonly #page: Page;
	readonly #viewportSize?: ViewportSize;
	readonly #isMobile?: boolean;

	private promotionCarousel?: PromotionCarousel;

	protected constructor({ page, viewportSize, isMobile }: HomepageParams) {
		this.#page = page;
		this.#viewportSize = viewportSize;
		this.#isMobile = isMobile;
	}

	protected async clickByTestId({
		testId,
		scrollIntoView = true
	}: {
		testId: string;
		scrollIntoView?: boolean;
	}): Promise<void> {
		const locator = this.#page.getByTestId(testId).filter({ visible: true });

		if (scrollIntoView) {
			// Method `click` auto-scrolls into view if needed.
			await locator.click();
			return;
		}

		// Since the method `click` auto-scrolls into view, we could prefer to avoid it.
		// That is because it could potentially have different screenshot outputs if it takes more time to load and scrolls more.
		await locator.dispatchEvent('click');
	}

	protected async waitForByTestId({
		testId,
		options
	}: TestIdOperationParams & { options?: WaitForLocatorOptions }): Promise<void> {
		await this.#page.getByTestId(testId).waitFor(options);
	}

	protected async isVisibleByTestId(testId: string): Promise<boolean> {
		const element = this.#page.locator(`[data-tid="${testId}"]`);
		return await element.isVisible();
	}

	private async isSelectorVisible({ selector }: SelectorOperationParams): Promise<boolean> {
		return await this.#page.isVisible(selector);
	}

	private async isSelectorNotVisible({ selector }: SelectorOperationParams): Promise<boolean> {
		const isVisible = await this.isSelectorVisible({ selector });

		return !isVisible;
	}

	private async hideSelector({ selector }: SelectorOperationParams): Promise<void> {
		if (await this.isSelectorVisible({ selector })) {
			await this.#page.locator(selector).evaluate((element) => (element.style.display = 'none'));
		}
	}

	private async showSelector({
		selector,
		display = 'block'
	}: SelectorOperationParams & ShowSelectorParams): Promise<void> {
		if (await this.isSelectorNotVisible({ selector })) {
			const locator = this.#page.locator(selector);

			if (display === 'flex') {
				await locator.evaluate((element) => (element.style.display = 'flex'));
				return;
			}

			await locator.evaluate((element) => (element.style.display = 'block'));
		}
	}

	protected async mockSelector({ selector }: SelectorOperationParams): Promise<void> {
		await this.#page.locator(selector).innerHTML();

		if (await this.isSelectorVisible({ selector })) {
			const elementsLocator = this.#page.locator(selector);
			await elementsLocator.evaluate((element) => (element.innerHTML = 'placeholder'));
			await elementsLocator.locator('text=placeholder').first().waitFor();
		}
	}

	protected async mockSelectorAll({ selector }: SelectorOperationParams): Promise<void> {
		const elementsLocator = this.#page.locator(selector);
		await elementsLocator.evaluateAll((elements) => {
			for (const element of elements) {
				(element as HTMLElement).innerHTML = 'placeholder';
			}
		});

		await elementsLocator.locator('text=placeholder').first().waitFor();
	}

	private async goto(): Promise<void> {
		await this.#page.goto(HOMEPAGE_URL);
	}

	private async setViewportSize(viewportSize: ViewportSize) {
		await this.#page.setViewportSize(viewportSize);
	}

	private async waitForNavigationMenu(options?: WaitForLocatorOptions): Promise<void> {
		await this.waitForByTestId({ testId: NAVIGATION_MENU, options });
	}

	protected async waitForLoginButton(options?: WaitForLocatorOptions): Promise<void> {
		await this.waitForByTestId({ testId: LOGIN_BUTTON, options });
	}

	private async getCanvasAsDataURL({
		selector
	}: SelectorOperationParams): Promise<string | undefined> {
		return await this.#page.evaluate<string | undefined, { selector: string }>(
			({ selector }) => {
				const canvas = document.querySelector<HTMLCanvasElement>(selector);
				return canvas?.toDataURL();
			},
			{
				selector
			}
		);
	}

	protected async readQRCode({ selector }: SelectorOperationParams): Promise<string | undefined> {
		await this.#page.locator(selector).waitFor();

		const dataUrl = await this.getCanvasAsDataURL({ selector });

		if (nonNullish(dataUrl)) {
			return getQRCodeValueFromDataURL({ dataUrl });
		}
	}

	protected async waitForModal({
		modalOpenButtonTestId,
		modalTestId,
		state
	}: WaitForModalParams): Promise<Locator> {
		const modal = this.#page.getByTestId(modalTestId);
		if (state === 'detached') {
			await modal.waitFor({ state });
			return modal;
		}
		await this.clickByTestId({ testId: modalOpenButtonTestId, scrollIntoView: false });
		await modal.waitFor();
		return modal;
	}

	protected async waitForHomepageReady(): Promise<void> {
		if (nonNullish(this.#viewportSize)) {
			await this.setViewportSize(this.#viewportSize);
		}

		await this.goto();
		await this.waitForLoggedOutIndicator();
	}

	protected async waitForLoaderModal(options?: WaitForLocatorOptions): Promise<void> {
		await this.waitForByTestId({ testId: LOADER_MODAL, options });
	}

	protected async waitForTokensInitialization(options?: WaitForLocatorOptions): Promise<void> {
		await this.waitForByTestId({ testId: `${TOKEN_CARD}-ICP-ICP`, options });
		await this.waitForByTestId({ testId: `${TOKEN_GROUP}-ETH`, options });

		await this.waitForByTestId({ testId: `${TOKEN_BALANCE}-ICP-ICP`, options });
		await this.waitForByTestId({ testId: `${TOKEN_BALANCE}-ETH`, options });
	}

	protected async clickMenuItem({ menuItemTestId }: ClickMenuItemParams): Promise<void> {
		await this.clickByTestId({ testId: NAVIGATION_MENU_BUTTON });
		await this.waitForNavigationMenu();

		await this.clickByTestId({ testId: menuItemTestId });
	}

	protected async clickSelector({ selector }: SelectorOperationParams): Promise<void> {
		await this.#page.locator(selector).click();
	}

	protected getLocatorByTestId({ testId }: TestIdOperationParams): Locator {
		return this.#page.getByTestId(testId);
	}

	async waitForTimeout(timeout: number): Promise<void> {
		await this.#page.waitForTimeout(timeout);
	}

	async waitForLoggedOutIndicator(): Promise<void> {
		await this.waitForLoginButton();
	}

	async waitForLoggedInIndicator(): Promise<void> {
		await this.waitForByTestId({ testId: NAVIGATION_MENU_BUTTON });
	}

	protected async elementExistsByTestId(testId: string): Promise<boolean> {
		return await this.#page
			.getByTestId(testId)
			.isVisible()
			.catch(() => false);
	}

	getBalanceLocator(): Locator {
		return this.#page.getByTestId(AMOUNT_DATA);
	}

	async setInputValueByTestId({
		testId,
		value
	}: TestIdOperationParams & { value: string }): Promise<void> {
		await this.#page.getByTestId(testId).fill(value);
	}

	async getAccountIdByTestId(testId: string): Promise<string> {
		const addressLocator = getReceiveTokensModalAddressLabelSelector({
			sectionSelector: testId
		});
		const addressText = await this.#page.locator(addressLocator).innerHTML();
		if (!addressText) {
			throw new Error('No address text found in container icp-account-id');
		}
		return addressText.trim();
	}

	async testModalSnapshot({
		modalOpenButtonTestId,
		modalTestId,
		selectorsToMock
	}: TestModalSnapshotParams): Promise<void> {
		const modal = await this.waitForModal({
			modalOpenButtonTestId,
			modalTestId
		});

		if (nonNullish(selectorsToMock)) {
			await Promise.all(
				selectorsToMock.map(async (selector) => await this.mockSelector({ selector }))
			);
		}

		await this.takeScreenshot({ screenshotTarget: modal });
	}

	// TODO: the carousel is too flaky for the E2E tests, so we need completely mask it and work on freezing it in a permanent state in another PR.
	async setCarouselFirstSlide(): Promise<void> {
		if (isNullish(this.promotionCarousel)) {
			this.promotionCarousel = new PromotionCarousel(this.#page);
		}
		await this.promotionCarousel.freezeCarouselToSlide(1);
		await this.waitForLoadState();
	}

	async waitForLoadState() {
		await this.#page.waitForLoadState('networkidle');
	}

	async navigateTo({
		testId,
		expectedPath
	}: {
		testId: string;
		expectedPath: AppPath;
	}): Promise<void> {
		if (await this.isVisibleByTestId(testId)) {
			await this.clickByTestId({ testId });
		} else if (await this.isVisibleByTestId(`mobile-${testId}`)) {
			await this.clickByTestId({ testId: `mobile-${testId}` });
		} else {
			throw new Error('Cannot reach navigation menu!');
		}

		const urlRegex = new RegExp(`${expectedPath}(\\?.*|#.*|$)`);
		await this.#page.waitForURL(urlRegex);
	}

	private async toggleAllTestnets(): Promise<void> {
		const toggles = this.#page.locator(`[data-tid^="${SETTINGS_NETWORKS_MODAL_TESTNET_TOGGLE}-"]`);
		const countToggles = await toggles.count();
		const testIds = await Promise.all(
			Array.from({ length: countToggles }, (_, i) => toggles.nth(i).getAttribute('data-tid'))
		);
		for (const testId of testIds) {
			if (nonNullish(testId)) {
				await this.clickByTestId({ testId });
			}
		}
	}

	async activateTestnetSettings(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_SETTINGS, expectedPath: AppPath.Settings });
		await this.clickByTestId({ testId: SETTINGS_ACTIVE_NETWORKS_EDIT_BUTTON });
		await this.clickByTestId({ testId: SETTINGS_NETWORKS_MODAL_TESTNET_CHECKBOX });
		await this.waitForByTestId({ testId: SETTINGS_NETWORKS_MODAL_TESTNETS_CONTAINER });
		await this.toggleAllTestnets();
		await this.clickByTestId({ testId: SETTINGS_NETWORKS_MODAL_SAVE_BUTTON });
		await this.waitForByTestId({
			testId: SETTINGS_NETWORKS_MODAL,
			options: { state: 'hidden', timeout: 60000 }
		});
		await this.clickByTestId({ testId: NAVIGATION_ITEM_HOMEPAGE });
	}

	private async scrollToTop(testId: string): Promise<void> {
		if (await this.isVisibleByTestId(testId)) {
			const selector = `[data-tid="${testId}"]`;
			const locator = this.#page.locator(selector);
			await locator.evaluate((element) => {
				element.scrollTo(0, 0);
			});
		}
	}

	private async scrollIntoViewCentered(testId: string): Promise<void> {
		const selector = `[data-tid="${testId}"]`;
		const locator = this.#page.locator(selector);
		await locator.evaluate((el) => el.scrollIntoView({ block: 'center', inline: 'center' }));
	}

	private async hideMobileNavigationMenu(): Promise<void> {
		await this.hideSelector({ selector: `[data-tid="${MOBILE_NAVIGATION_MENU}"]` });
	}

	private async showMobileNavigationMenu(): Promise<void> {
		await this.showSelector({
			selector: `[data-tid="${MOBILE_NAVIGATION_MENU}"]`,
			display: 'flex'
		});
	}

	protected async waitForManageTokensModal(options?: WaitForLocatorOptions): Promise<void> {
		await this.waitForByTestId({ testId: MANAGE_TOKENS_MODAL, options });
	}

	async openNetworkSelector(): Promise<void> {
		await this.scrollIntoViewCentered(NETWORKS_SWITCHER_DROPDOWN);
		await this.clickByTestId({ testId: NETWORKS_SWITCHER_DROPDOWN });
	}

	async toggleNetworkSelector({ networkSymbol }: { networkSymbol: string }): Promise<void> {
		await this.openNetworkSelector();
		await this.clickByTestId({ testId: `${NETWORKS_SWITCHER_SELECTOR}-${networkSymbol}` });
	}

	async toggleTokenInList({
		tokenSymbol,
		networkSymbol
	}: {
		tokenSymbol: string;
		networkSymbol: string;
	}): Promise<void> {
		await this.toggleNetworkSelector({ networkSymbol });
		await this.clickByTestId({ testId: MANAGE_TOKENS_MODAL_BUTTON });
		await this.waitForManageTokensModal();
		await this.clickByTestId({
			testId: `${MANAGE_TOKENS_MODAL_TOKEN_TOGGLE}-${tokenSymbol}-${networkSymbol}`
		});
		await this.clickByTestId({ testId: MANAGE_TOKENS_MODAL_SAVE });
		await this.waitForManageTokensModal({ state: 'hidden', timeout: 60000 });
	}

	getTokenCardTestId({
		tokenSymbol,
		networkSymbol
	}: {
		tokenSymbol: string;
		networkSymbol: string;
	}): string {
		return `${TOKEN_CARD}-${tokenSymbol}-${networkSymbol}`;
	}

	getTokenCardLocator(params: { tokenSymbol: string; networkSymbol: string }): Locator {
		return this.#page.locator(`[data-tid="${this.getTokenCardTestId(params)}"]`);
	}

	async getStableViewportHeight(): Promise<number> {
		let previousHeight: number;
		let currentHeight: number = await this.#page.evaluate(
			() => document.documentElement.scrollHeight
		);

		do {
			previousHeight = currentHeight;
			await this.#page.waitForTimeout(1000);
			currentHeight = await this.#page.evaluate(() => document.documentElement.scrollHeight);
		} while (currentHeight !== previousHeight);

		return currentHeight;
	}

	private async viewportAdjuster(): Promise<void> {
		await this.waitForLoadState();
		const stablePageHeight = await this.getStableViewportHeight();

		const currentViewport = this.#page.viewportSize();
		const width = currentViewport?.width ?? (await this.#page.evaluate(() => window.innerWidth));

		await this.#page.setViewportSize({ height: stablePageHeight, width });
	}

	async takeScreenshot(
		{ freezeCarousel: _ = false, centeredElementTestId, screenshotTarget }: TakeScreenshotParams = {
			freezeCarousel: false
		}
	): Promise<void> {
		if (isNullish(screenshotTarget) && !this.#isMobile) {
			// Creates a snapshot as a fullPage and not just certain parts (if not a mobile).
			await this.viewportAdjuster();
		}

		const element = screenshotTarget ?? this.#page;

		// TODO: the carousel is too flaky for the E2E tests, so we need completely mask it and work on freezing it in a permanent state in another PR.
		// if (freezeCarousel) {
		// 	// Freezing the time because the carousel has a timer that resets the animations and the transitions.
		// 	await this.#page.clock.pauseAt(Date.now());
		// 	await this.setCarouselFirstSlide();
		// 	await this.#page.clock.pauseAt(Date.now());
		// }

		if (!this.#isMobile) {
			await this.scrollToTop(SIDEBAR_NAVIGATION_MENU);
		}

		if (nonNullish(centeredElementTestId)) {
			await this.scrollIntoViewCentered(centeredElementTestId);
		}

		await this.#page.mouse.move(0, 0);

		const colorSchemes = ['light', 'dark'] as const;
		for (const scheme of colorSchemes) {
			await this.#page.emulateMedia({ colorScheme: scheme });
			await this.#page.waitForTimeout(1000);

			// There is a race condition with playwright: it can happen that there is a bad error about
			// screenshot existence, even if the screenshot is created/overwritten.
			// Issue: https://github.com/microsoft/playwright/issues/36228
			// TODO: remove the try-catch block (and the pause) when the issue is fixed in playwright
			try {
				await this.#page.waitForTimeout(5000);

				await expect(element).toHaveScreenshot();
			} catch (error: unknown) {
				console.warn(error);
			}

			// If it's mobile, we want a full page screenshot too, but without the navigation bar.
			if (this.#isMobile) {
				await this.hideMobileNavigationMenu();

				// There is a race condition with playwright: it can happen that there is an error about
				// screenshot existence, even if the screenshot is created/overwritten.
				// Issue: https://github.com/microsoft/playwright/issues/36228
				// TODO: remove the try-catch block (and the pause) when the issue is fixed in playwright
				try {
					await this.#page.waitForTimeout(5000);

					await expect(element).toHaveScreenshot({ fullPage: true });
				} catch (error: unknown) {
					console.warn(error);
				}

				await this.showMobileNavigationMenu();
			}
		}
		await this.#page.emulateMedia({ colorScheme: null });

		// TODO: the carousel is too flaky for the E2E tests, so we need completely mask it and work on freezing it in a permanent state in another PR.
		// if (freezeCarousel) {
		// 	// Resuming the time that we froze because of the carousel animations.
		// 	await this.#page.clock.resume();
		// }
	}

	abstract extendWaitForReady(): Promise<void>;

	abstract waitForReady(): Promise<void>;
}

export class HomepageLoggedOut extends Homepage {
	constructor(params: HomepageParams) {
		super(params);
	}

	override async extendWaitForReady(): Promise<void> {}

	/**
	 * @override
	 */
	async waitForReady(): Promise<void> {
		await this.waitForHomepageReady();
		await this.waitForLoadState();
	}
}

export class HomepageLoggedIn extends Homepage {
	readonly #iiPage: InternetIdentityPage;

	constructor({ iiPage, ...rest }: HomepageLoggedInParams) {
		super(rest);

		this.#iiPage = iiPage;
	}

	async waitForAuthentication(): Promise<void> {
		await this.#iiPage.waitReady({
			url: LOCAL_REPLICA_URL,
			canisterId: process.env.E2E_LOCAL_INTERNET_IDENTITY_CANISTER_ID
		});

		await this.waitForHomepageReady();

		await this.#iiPage.signInWithNewIdentity();
	}

	async checkIfStillLoggedIn(timeout = 10000): Promise<void> {
		await this.waitForLoggedInIndicator();

		await this.waitForTimeout(timeout);

		await this.waitForLoggedInIndicator();
	}

	async waitForLogout(): Promise<void> {
		await this.clickMenuItem({ menuItemTestId: LOGOUT_BUTTON });

		await this.waitForLoggedOutIndicator();
	}

	async activatePrivacyMode(): Promise<void> {
		await this.clickMenuItem({ menuItemTestId: NAVIGATION_MENU_PRIVACY_MODE_BUTTON });
	}

	async clickTokenGroupCard(tokenSymbol: string): Promise<void> {
		await this.clickByTestId({ testId: `${TOKEN_GROUP}-${tokenSymbol}` });
	}

	async testReceiveModalQrCode({
		receiveModalSectionSelector
	}: {
		receiveModalSectionSelector: string;
	}): Promise<void> {
		await this.waitForModal({
			modalOpenButtonTestId: RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
			modalTestId: RECEIVE_TOKENS_MODAL
		});

		await this.clickSelector({
			selector: getReceiveTokensModalQrCodeButtonSelector({
				sectionSelector: receiveModalSectionSelector
			})
		});

		const qrCodeOutputLocator = this.getLocatorByTestId({
			testId: RECEIVE_TOKENS_MODAL_QR_CODE_OUTPUT
		});
		await qrCodeOutputLocator.waitFor();

		const qrCode = await this.readQRCode({
			selector: `[data-tid="${RECEIVE_TOKENS_MODAL}"] canvas`
		});

		await expect(qrCodeOutputLocator).toHaveText(qrCode ?? '');
	}

	override async extendWaitForReady(): Promise<void> {
		// Extend the waitForReady method in a subclass
	}

	/**
	 * @override
	 */
	async waitForReady(): Promise<void> {
		await this.waitForAuthentication();

		await this.waitForLoaderModal();

		await this.waitForLoaderModal({ state: 'hidden', timeout: 60000 });

		await this.waitForContentReady();
	}

	async waitForContentReady(): Promise<void> {
		await this.waitForTokensInitialization();

		await this.waitForLoadState();

		await this.extendWaitForReady();
	}
}



================================================
FILE: e2e/utils/pages/manage-tokens.page.ts
================================================
import { TOKEN_BALANCE, TOKEN_CARD, TOKEN_SKELETON_TEXT } from '$lib/constants/test-ids.constants';
import { expect } from '@playwright/test';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

type ManageTokensPageParams = HomepageLoggedInParams;

interface ManageTokensConfig {
	type: string;
	tokenSymbol: string;
	networkSymbol: string;
}

export const ManageTokensCases: ManageTokensConfig[] = [
	{
		type: 'ICRC',
		tokenSymbol: 'ckSepoliaETH',
		networkSymbol: 'ICP'
	},
	{
		type: 'ERC20',
		tokenSymbol: 'SHIB',
		networkSymbol: 'ETH'
	},
	{
		type: 'SepoliaERC20',
		tokenSymbol: 'USDC',
		networkSymbol: 'SepoliaETH'
	},
	{
		type: 'SPL',
		tokenSymbol: 'EURC',
		networkSymbol: 'SOL'
	},
	{
		type: 'DevnetSPL',
		tokenSymbol: 'DevnetUSDC',
		networkSymbol: 'SOL (Devnet)'
	}
];

export class ManageTokensPage extends HomepageLoggedIn {
	constructor(params: ManageTokensPageParams) {
		super(params);
	}

	enableAndDisableToken = async ({
		tokenSymbol,
		networkSymbol
	}: {
		tokenSymbol: string;
		networkSymbol: string;
	}) => {
		await this.activateTestnetSettings();
		await this.toggleTokenInList({
			tokenSymbol,
			networkSymbol
		});

		await expect(
			this.getTokenCardLocator({
				tokenSymbol,
				networkSymbol
			})
		).toBeVisible();

		await this.waitForLoadState();

		const skeletons = this.getLocatorByTestId({ testId: TOKEN_SKELETON_TEXT });
		const countSkeletons = await skeletons.count();
		await Promise.all(
			Array.from({ length: countSkeletons }, (_, i) =>
				skeletons.nth(i).waitFor({ state: 'hidden', timeout: 60000 })
			)
		);

		const balances = this.getLocatorByTestId({ testId: `[data-tid^="${TOKEN_BALANCE}-"]` });
		const countBalances = await balances.count();
		await Promise.all(
			Array.from({ length: countBalances }, (_, i) =>
				skeletons.nth(i).waitFor({ state: 'visible', timeout: 60000 })
			)
		);

		await this.takeScreenshot({
			freezeCarousel: true,
			centeredElementTestId: `${TOKEN_CARD}-${tokenSymbol}-${networkSymbol}`
		});
		await this.toggleTokenInList({
			tokenSymbol,
			networkSymbol
		});

		await expect(
			this.getTokenCardLocator({
				tokenSymbol,
				networkSymbol
			})
		).not.toBeVisible();
	};
}



================================================
FILE: e2e/utils/pages/rewards-page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	NAVIGATION_ITEM_REWARDS,
	REWARDS_ACTIVE_CAMPAIGNS_CONTAINER
} from '$lib/constants/test-ids.constants';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

export type RewardsPageParams = HomepageLoggedInParams;

export class RewardsPage extends HomepageLoggedIn {
	constructor(params: RewardsPageParams) {
		super(params);
	}

	override async extendWaitForReady(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_REWARDS, expectedPath: AppPath.Rewards });
		await this.mockSelector({
			selector: `[data-tid^="${REWARDS_ACTIVE_CAMPAIGNS_CONTAINER}-"][data-tid$="-badge"]`
		});
		await this.waitForLoadState();
	}
}



================================================
FILE: e2e/utils/pages/send-and-receive-flow.page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	AMOUNT_DATA,
	DESTINATION_INPUT,
	IN_PROGRESS_MODAL,
	MAX_BUTTON,
	NAVIGATION_ITEM_ACTIVITY,
	NAVIGATION_ITEM_TOKENS,
	RECEIVE_TOKENS_MODAL,
	RECEIVE_TOKENS_MODAL_DONE_BUTTON,
	RECEIVE_TOKENS_MODAL_ICP_SECTION,
	RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
	REVIEW_FORM_SEND_BUTTON,
	SEND_FORM_DESTINATION_NEXT_BUTTON,
	SEND_FORM_NEXT_BUTTON,
	SEND_TOKENS_MODAL,
	SEND_TOKENS_MODAL_OPEN_BUTTON,
	TOKEN_CARD,
	TOKEN_INPUT_CURRENCY_TOKEN
} from '$lib/constants/test-ids.constants';
import { expect } from '@playwright/test';
import { LedgerTransferCommand } from '../commands/ledger-transfer.command';
import { createCommandRunner } from '../commands/runner';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

const commandRunner = createCommandRunner();

export type FlowPageParams = HomepageLoggedInParams;

export class FlowPage extends HomepageLoggedIn {
	constructor(params: FlowPageParams) {
		super(params);
	}

	async receiveTokens(): Promise<void> {
		await this.clickByTestId({ testId: `${TOKEN_CARD}-ICP-ICP` });
		await this.waitForByTestId({ testId: AMOUNT_DATA });

		await expect(this.getBalanceLocator()).toHaveText('0 ICP');

		await this.waitForModal({
			modalOpenButtonTestId: RECEIVE_TOKENS_MODAL_OPEN_BUTTON,
			modalTestId: RECEIVE_TOKENS_MODAL
		});
		const accountId = await this.getAccountIdByTestId(RECEIVE_TOKENS_MODAL_ICP_SECTION);

		expect(accountId).toBeTruthy();

		await commandRunner.exec({
			command: new LedgerTransferCommand({ amount: '10', recipient: accountId })
		});
		await this.clickByTestId({ testId: RECEIVE_TOKENS_MODAL_DONE_BUTTON });

		await expect(this.getBalanceLocator()).toHaveText('10 ICP', { timeout: 30_000 });
	}

	async sendTokens(): Promise<void> {
		await this.clickByTestId({ testId: SEND_TOKENS_MODAL_OPEN_BUTTON });
		await this.waitForModal({
			modalOpenButtonTestId: SEND_TOKENS_MODAL_OPEN_BUTTON,
			modalTestId: SEND_TOKENS_MODAL
		});
		await this.setInputValueByTestId({
			testId: DESTINATION_INPUT,
			value: 'tjgkf-baw6u-7lmw2-cbwoi-omgia-jk4kg-yvfcw-jni6g-k7spl-552th-jae'
		});
		await this.clickByTestId({ testId: SEND_FORM_DESTINATION_NEXT_BUTTON });
		await this.clickByTestId({ testId: MAX_BUTTON });
		await this.setInputValueByTestId({
			testId: TOKEN_INPUT_CURRENCY_TOKEN,
			value: '1'
		});
		await this.clickByTestId({ testId: SEND_FORM_NEXT_BUTTON });
		await this.clickByTestId({ testId: REVIEW_FORM_SEND_BUTTON });
		const progressModalExists = await this.isVisibleByTestId(IN_PROGRESS_MODAL);

		expect(progressModalExists).toBeTruthy();

		await this.waitForByTestId({
			testId: IN_PROGRESS_MODAL,
			options: { state: 'detached' }
		});
		const progressModalDoesNotExists = await this.isVisibleByTestId(IN_PROGRESS_MODAL);

		expect(progressModalDoesNotExists).toBeFalsy();

		await this.mockSelectorAll({
			selector: '[data-tid="receive-tokens-modal-transaction-timestamp"]'
		});
	}

	async navigateToActivity(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_ACTIVITY, expectedPath: AppPath.Activity });

		await new Promise((resolve) => setTimeout(resolve, 5000));

		await this.mockSelectorAll({
			selector: '[data-tid="receive-tokens-modal-transaction-timestamp"]'
		});
	}

	async navigateToAssets(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_TOKENS, expectedPath: AppPath.Tokens });

		await this.waitForContentReady();
	}

	async navigateToTransactionsPage({
		tokenSymbol,
		networkSymbol
	}: {
		tokenSymbol: string;
		networkSymbol: string;
	}): Promise<void> {
		await this.navigateTo({
			testId: this.getTokenCardTestId({ tokenSymbol, networkSymbol }),
			expectedPath: AppPath.Transactions
		});

		await new Promise((resolve) => setTimeout(resolve, 1000));

		await this.mockSelectorAll({
			selector: '[data-tid="receive-tokens-modal-transaction-timestamp"]'
		});
	}
}



================================================
FILE: e2e/utils/pages/settings.page.ts
================================================
import { AppPath } from '$lib/constants/routes.constants';
import {
	CAROUSEL_SLIDE_NAVIGATION,
	NAVIGATION_ITEM_SETTINGS,
	SETTINGS_ADDRESS_LABEL
} from '$lib/constants/test-ids.constants';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

export type SettingsPageParams = HomepageLoggedInParams;

export class SettingsPage extends HomepageLoggedIn {
	constructor(params: SettingsPageParams) {
		super(params);
	}

	override async extendWaitForReady(): Promise<void> {
		await this.navigateTo({ testId: NAVIGATION_ITEM_SETTINGS, expectedPath: AppPath.Settings });

		await this.mockSelector({ selector: `[data-tid="${SETTINGS_ADDRESS_LABEL}"]` });

		await this.getLocatorByTestId({ testId: CAROUSEL_SLIDE_NAVIGATION }).waitFor({
			state: 'hidden'
		});

		await this.waitForLoadState();
	}
}



================================================
FILE: e2e/utils/pages/testnets.page.ts
================================================
import { TOKEN_BALANCE, TOKEN_SKELETON_TEXT } from '$lib/constants/test-ids.constants';
import { expect } from '@playwright/test';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

type TestnetsPageParams = HomepageLoggedInParams;

interface TestnetConfig {
	networkSymbol: string;
	tokenSymbol: string;
}

export const TestnetCases: TestnetConfig[] = [
	{
		networkSymbol: 'BTC (Testnet)',
		tokenSymbol: 'BTC (Testnet)'
	},
	{
		networkSymbol: 'BTC (Regtest)',
		tokenSymbol: 'BTC (Regtest)'
	},
	{
		networkSymbol: 'SepoliaETH',
		tokenSymbol: 'SepoliaETH'
	},
	{
		networkSymbol: 'SOL (Devnet)',
		tokenSymbol: 'SOL (Devnet)'
	},
	{
		networkSymbol: 'SOL (Local)',
		tokenSymbol: 'SOL (Local)'
	},
	{
		networkSymbol: 'SepoliaBASE',
		tokenSymbol: 'SepoliaETH'
	},
	{
		networkSymbol: 'BSC (Testnet)',
		tokenSymbol: 'BNB (Testnet)'
	},
	{
		networkSymbol: 'POL (Amoy Testnet)',
		tokenSymbol: 'POL (Amoy Testnet)'
	}
];

export class TestnetsPage extends HomepageLoggedIn {
	constructor(params: TestnetsPageParams) {
		super(params);
	}

	async enableTestnets({
		networkSymbol,
		tokenSymbol
	}: {
		networkSymbol: string;
		tokenSymbol: string;
	}): Promise<void> {
		await this.activateTestnetSettings();
		await this.toggleNetworkSelector({ networkSymbol });

		await expect(
			this.getTokenCardLocator({
				tokenSymbol,
				networkSymbol
			})
		).toBeVisible();

		await this.waitForLoadState();

		if (tokenSymbol !== 'BTC (Testnet)') {
			const skeletons = this.getLocatorByTestId({ testId: TOKEN_SKELETON_TEXT });
			const countSkeletons = await skeletons.count();
			await Promise.all(
				Array.from({ length: countSkeletons }, (_, i) =>
					skeletons.nth(i).waitFor({ state: 'hidden', timeout: 60000 })
				)
			);

			const balances = this.getLocatorByTestId({ testId: `[data-tid^="${TOKEN_BALANCE}-"]` });
			const countBalances = await balances.count();
			await Promise.all(
				Array.from({ length: countBalances }, (_, i) =>
					skeletons.nth(i).waitFor({ state: 'visible', timeout: 60000 })
				)
			);
		}
	}
}



================================================
FILE: e2e/utils/pages/transactions.page.ts
================================================
import {
	CAROUSEL_SLIDE_NAVIGATION,
	NO_TRANSACTIONS_PLACEHOLDER,
	TOKEN_CARD
} from '$lib/constants/test-ids.constants';
import { HomepageLoggedIn, type HomepageLoggedInParams } from './homepage.page';

type TransactionsPageParams = HomepageLoggedInParams;

interface TransactionsConfig {
	tokenSymbol: string;
	networkId: string;
	waitForPlaceholder?: boolean;
}

export const TransactionCases: TransactionsConfig[] = [
	{
		tokenSymbol: 'BTC',
		networkId: 'BTC',
		waitForPlaceholder: false
	},
	{
		tokenSymbol: 'ETH',
		networkId: 'ETH'
	},
	{
		tokenSymbol: 'ICP',
		networkId: 'ICP'
	},
	{
		tokenSymbol: 'SOL',
		networkId: 'SOL'
	},
	{
		tokenSymbol: 'ETH',
		networkId: 'BASE'
	},
	{
		tokenSymbol: 'BNB',
		networkId: 'BSC'
	},
	{
		tokenSymbol: 'POL',
		networkId: 'POL'
	}
];

export class TransactionsPage extends HomepageLoggedIn {
	constructor(params: TransactionsPageParams) {
		super(params);
	}

	showTransactions = async ({
		tokenSymbol,
		networkId,
		waitForPlaceholder = true
	}: TransactionsConfig) => {
		await this.toggleNetworkSelector({ networkSymbol: networkId });
		const testId = `${TOKEN_CARD}-${tokenSymbol}-${networkId}`;
		await this.clickByTestId({ testId });
		await this.getLocatorByTestId({ testId: CAROUSEL_SLIDE_NAVIGATION }).waitFor({
			state: 'hidden'
		});
		if (waitForPlaceholder) {
			await this.waitForByTestId({ testId: NO_TRANSACTIONS_PLACEHOLDER });
		}
		await this.waitForLoadState();
		await this.takeScreenshot();
	};
}



================================================
FILE: licenses/LUCIDE_LICENSE
================================================
Lucide License

ISC License

Copyright (c) for portions of Lucide are held by Cole Bemis 2013-2022 as part of Feather (MIT).
All other copyright (c) for Lucide are held by Lucide Contributors 2022.

Permission to use, copy, modify, and/or distribute this software for any purpose with or
without fee is hereby granted, provided that the above copyright notice and this permissionnotice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.


================================================
FILE: scripts/add.tokens.bitcoin.sh
================================================
#!/bin/bash

print_help() {
  cat <<-EOF

	Mines blocks to a given address.

Arguments:
--amount <amount>  Amount of BTC to mine.
--address <address>  Address to mine to.

If no amount and no address are provided, it will mine a block to a random address.
	EOF
  # TODO: Consider using clap for argument parsing.  If not, describe the flags here.
}

BITCOIN_DIR="bitcoin-core"

# Initialize variables for the parameters
amount=""
address=""

# Loop through the parameters
while [[ "$#" -gt 0 ]]; do
  case $1 in
  --help) print_help && exit 0 ;;
  --amount)
    amount="$2"
    shift 2
    ;; # Assign the next argument to amount and shift
  --address)
    address="$2"
    shift 2
    ;; # Assign the next argument to address and shift
  *)
    echo "Unknown parameter passed: $1"
    exit 1
    ;;
  esac
done

if [ -n "$amount" ] && [ -n "$address" ]; then
  # Reference: https://internetcomputer.org/docs/current/developer-docs/multi-chain/bitcoin/using-btc/local-development
  ./$BITCOIN_DIR/bin/bitcoin-cli -conf="$(pwd)/$BITCOIN_DIR/bitcoin.conf" generatetoaddress "$amount" "$address"
  # One caveat of the previous block rewards is that they are subject to the Coinbase maturity rule
  # which states that, in order for you to spend them, you will first need to mine 100 additional blocks.
  # Therefore, we will generate 100 blocks to a random address.
  ./$BITCOIN_DIR/bin/bitcoin-cli -conf="$(pwd)/$BITCOIN_DIR/bitcoin.conf" generatetoaddress 100 mtbZzVBwLnDmhH4pE9QynWAgh6H3aC1E6M
else
  # Step necessary after making a transaction so that it becomes part of the blockchain
  ./$BITCOIN_DIR/bin/bitcoin-cli -conf="$(pwd)/$BITCOIN_DIR/bitcoin.conf" generatetoaddress 1 mtbZzVBwLnDmhH4pE9QynWAgh6H3aC1E6M
fi



================================================
FILE: scripts/add.tokens.erc20.mjs
================================================
import { isNullish, nonNullish } from '@dfinity/utils';
import dotenv from 'dotenv';
import { Contract } from 'ethers/contract';
import { EtherscanProvider } from 'ethers/providers';
import { execSync } from 'node:child_process';
import { readFileSync, writeFileSync } from 'node:fs';
import { resolve } from 'node:path';
import path from 'path';
import { ENV } from './build.utils.mjs';
import { CK_ERC20_JSON_FILE } from './constants.mjs';

dotenv.config({ path: `.env.${ENV}` });

const getArgValue = (argName) => {
	const argIndex = process.argv.indexOf(argName);
	return argIndex > -1 ? process.argv[argIndex + 1] : null;
};

const ETHERSCAN_API_KEY = getArgValue('--etherscan-api-key') ?? process.env.VITE_ETHERSCAN_API_KEY;

if (isNullish(ETHERSCAN_API_KEY)) {
	console.error(
		`Missing VITE_ETHERSCAN_API_KEY. Please provide it in .env.${ENV} or via --etherscan-api-key argument.`
	);
	process.exit(1);
}

const DATA_DIR = 'src/frontend/src/env/tokens';
const DATA_DIR_PATH = resolve(process.cwd(), DATA_DIR);

const ERC20_DATA_DIR = `${DATA_DIR}/tokens-erc20`;
const ERC20_DATA_DIR_PATH = resolve(process.cwd(), ERC20_DATA_DIR);

const SVG_DIR = 'src/frontend/src/icp-eth/assets';
const SVG_DIR_PATH = resolve(process.cwd(), SVG_DIR);

const escapeRegExp = (string) => string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');

const unescapeRegExp = (string) => string.replace(/\\([.*+?^${}()|/[\]\\])/g, '$1');

const addElementListInContent = ({ content, regex, element, addAtStartIfNotFound = false }) => {
	const match = content.match(regex);
	if (match) {
		const list = match[1].trim();
		if (!list.includes(element)) {
			const updatedList = list ? `${list}, ${element}` : element;
			return {
				content: content.replace(regex, match[0].replace(match[1], updatedList)),
				hasChanged: true
			};
		}
		return { content, hasChanged: false };
	}
	const newLine = unescapeRegExp(regex.source.replace('([\\s\\S]*?)', element));
	return {
		content: addAtStartIfNotFound ? `${newLine}\n${content}` : `${content}\n${newLine}`,
		hasChanged: true
	};
};

const updateListInContent = ({ content, regex, elements, addAtStartIfNotFound = false }) =>
	elements.reduce(
		(acc, element) => {
			const { content: newContent, hasChanged } = addElementListInContent({
				content: acc.content,
				regex,
				element,
				addAtStartIfNotFound
			});
			return {
				content: newContent,
				hasChanged: acc.hasChanged ?? hasChanged
			};
		},
		{ content, hasChanged: false }
	);

const updateImportsInContent = ({ content, imports, module }) =>
	updateListInContent({
		content,
		regex: new RegExp(`import \\{([\\s\\S]*?)} from '${escapeRegExp(module)}';`),
		elements: imports,
		addAtStartIfNotFound: true
	});

const fetchTokenDetails = async ({ contractAddress, isTestnet }) => {
	const provider = new EtherscanProvider(isTestnet ? 'sepolia' : 'homestead', ETHERSCAN_API_KEY);
	const contract = new Contract(
		contractAddress,
		[
			'function name() view returns (string)',
			'function decimals() view returns (uint8)',
			'function symbol() public view returns (string)'
		],
		provider
	);

	const [name, decimals, symbol] = await Promise.all([
		contract.name(),
		contract.decimals(),
		contract.symbol()
	]).catch((err) => {
		console.error(`Error fetching token details:\n${err}`);
		process.exit(1);
	});

	return { name, decimals, symbol };
};

const loadFileContentOrEmpty = (filePath) => {
	try {
		return readFileSync(filePath, 'utf8');
	} catch (_err) {
		console.log(`File ${filePath} does not exist, it will be created.`);
		return '';
	}
};

let filesCreatedOrModified = false;
const manageEnvFile = async ({ mainSymbol: symbol, contractAddress, testnetContractAddress }) => {
	const fileName = `tokens.${symbol.toLowerCase()}.env.ts`;
	const filePath = path.join(ERC20_DATA_DIR_PATH, fileName);

	const existingFileContent = loadFileContentOrEmpty(filePath);

	const mainnetToken = nonNullish(contractAddress) ? `${symbol}_TOKEN` : undefined;
	const testnetToken = nonNullish(testnetContractAddress) ? `SEPOLIA_${symbol}_TOKEN` : undefined;

	const mainnetTokenCreated = existingFileContent.split(/\W+/).includes(mainnetToken ?? '');
	const testnetTokenCreated = existingFileContent.split(/\W+/).includes(testnetToken ?? '');

	if (mainnetTokenCreated && testnetTokenCreated) {
		console.log(`Variables for token ${symbol} already exists in the environment file ${fileName}`);
		return { fileName, mainnetToken: undefined, testnetToken: undefined };
	}

	const {
		name: mainnetName,
		decimals: mainnetDecimals,
		symbol: mainnetSymbol
	} = nonNullish(contractAddress)
		? await fetchTokenDetails({ contractAddress, isTestnet: false })
		: {};
	const {
		name: testnetName,
		decimals: testnetDecimals,
		symbol: testnetSymbol
	} = nonNullish(testnetContractAddress)
		? await fetchTokenDetails({
				contractAddress: testnetContractAddress,
				isTestnet: true
			})
		: {};

	const icon = symbol.toLowerCase();

	const fileContentFirstPart =
		existingFileContent !== ''
			? existingFileContent
			: `import type { RequiredErc20Token } from '$eth/types/erc20';
import ${icon} from '$icp-eth/assets/${icon}.svg';
import type { TokenId } from '$lib/types/token';
import { parseTokenId } from '$lib/utils/zod.utils';
`;

	const { content: fileContentFirstPartWithImports } = updateImportsInContent({
		content: fileContentFirstPart,
		imports: [
			...(!mainnetTokenCreated ? ['ETHEREUM_NETWORK'] : []),
			...(!testnetTokenCreated ? ['SEPOLIA_NETWORK'] : [])
		],
		module: '$env/networks.env'
	});

	const decimalsConst = `export const ${symbol}_DECIMALS = ${mainnetDecimals ?? testnetDecimals};`;
	const fileContentDecimalsConst = !existingFileContent.includes(decimalsConst)
		? `\n${decimalsConst}\n`
		: '';

	const newFileContentMainnet =
		nonNullish(mainnetToken) && !mainnetTokenCreated
			? `
export const ${symbol}_SYMBOL = '${mainnetSymbol}';

export const ${symbol}_TOKEN_ID: TokenId = parseTokenId(${symbol}_SYMBOL);

export const ${mainnetToken}: RequiredErc20Token = {
	id: ${symbol}_TOKEN_ID,
	network: ETHEREUM_NETWORK,
	standard: 'erc20',
	category: 'default',
	name: '${mainnetName}',
	symbol: ${symbol}_SYMBOL,
	decimals: ${symbol}_DECIMALS,
	icon: ${icon},
	address: '${contractAddress}',
	exchange: 'erc20',
	twinTokenSymbol: 'ck${symbol}'
};
`
			: '';

	const newFileContentTestnet =
		nonNullish(testnetToken) && !testnetTokenCreated
			? `
export const SEPOLIA_${symbol}_SYMBOL = 'Sepolia${testnetSymbol}';

export const SEPOLIA_${symbol}_TOKEN_ID: TokenId = parseTokenId(SEPOLIA_${symbol}_SYMBOL);

export const ${testnetToken}: RequiredErc20Token = {
	id: SEPOLIA_${symbol}_TOKEN_ID,
	network: SEPOLIA_NETWORK,
	standard: 'erc20',
	category: 'default',
	name: '${testnetName}',
	symbol: '${testnetSymbol}',
	decimals: ${symbol}_DECIMALS,
	icon: ${icon},
	address: '${testnetContractAddress}',
	exchange: 'erc20',
	twinTokenSymbol: 'ckSepolia${symbol}'
};
`
			: '';

	if (newFileContentMainnet + newFileContentTestnet === '') {
		console.log(`No new variables to create for token ${symbol}`);
		return { fileName, mainnetToken: undefined, testnetToken: undefined };
	}

	const newFileContent =
		fileContentFirstPartWithImports +
		fileContentDecimalsConst +
		newFileContentMainnet +
		newFileContentTestnet;
	writeFileSync(filePath, newFileContent);
	filesCreatedOrModified = true;

	if (newFileContentMainnet !== '') {
		console.log(`Created new mainnet variables for token ${symbol} in file ${filePath}`);
	}

	if (newFileContentTestnet !== '') {
		console.log(`Created new testnet variables for token ${symbol} in file ${filePath}`);
	}

	return {
		fileName,
		mainnetToken: newFileContentMainnet !== '' ? mainnetToken : undefined,
		testnetToken: newFileContentTestnet !== '' ? testnetToken : undefined
	};
};

const updateTokensErc20Env = ({ fileName, mainnetToken, testnetToken }) => {
	const filePath = path.join(DATA_DIR_PATH, 'tokens.erc20.env.ts');
	let content = readFileSync(filePath, 'utf8');

	const regexList = [
		{
			regex: /const ERC20_TWIN_TOKENS_MAINNET: RequiredErc20Token\[] = \[([\s\S]*?)];/,
			token: mainnetToken
		},
		{
			regex: /const ERC20_TWIN_TOKENS_SEPOLIA: RequiredErc20Token\[] = \[([\s\S]*?)];/,
			token: testnetToken
		}
	];

	regexList
		.filter(({ token }) => nonNullish(token))
		.forEach(({ regex, token }) => {
			const { content: newContent, hasChanged } = addElementListInContent({
				content,
				regex,
				element: token
			});
			if (hasChanged) {
				content = newContent;
				console.log(`Included ${token} in token list in ${filePath}`);
			}
		});

	if (nonNullish(mainnetToken) || nonNullish(testnetToken)) {
		const imports = [mainnetToken, testnetToken].filter(Boolean);
		const { content: newContent, hasChanged } = updateImportsInContent({
			content,
			imports,
			module: `$env/tokens-erc20/${fileName.replace('.ts', '')}`
		});
		if (hasChanged) {
			content = newContent;
			console.log(`Added import statement for ${imports.join(', ')} in ${filePath}`);
		}
	}

	writeFileSync(filePath, content);
};

const flattenData = (data) =>
	Object.keys(data).map((symbol) => ({
		symbol,
		...data[symbol]
	}));

const flattenEnvironmentData = (data) =>
	Object.entries(data).reduce(
		(acc, [environment, values]) => ({
			...acc,
			[environment]: flattenData(values)
		}),
		{}
	);

const readSupportedTokens = () => {
	const jsonPath = resolve(CK_ERC20_JSON_FILE);
	return JSON.parse(readFileSync(jsonPath, 'utf-8'));
};

const parseTokens = (tokens) => {
	const { production: prodTokens, staging: testnetTokens } = flattenEnvironmentData(tokens);

	const acc = {};

	prodTokens.forEach(({ symbol, erc20ContractAddress }) => {
		const mainSymbol = symbol.slice(2);
		acc[mainSymbol] = {
			mainSymbol,
			contractAddress: erc20ContractAddress,
			testnetContractAddress: acc[mainSymbol]?.testnetContractAddress
		};
	});

	testnetTokens.forEach(({ symbol, erc20ContractAddress }) => {
		const mainSymbol = symbol.replace('Sepolia', '').slice(2);
		acc[mainSymbol] ??= { mainSymbol };
		acc[mainSymbol].testnetContractAddress = erc20ContractAddress;
	});

	return Object.values(acc);
};

const main = async () => {
	const tokens = readSupportedTokens();

	const tokensToProcess = parseTokens(tokens);

	if (tokensToProcess.length === 0) {
		console.log('No new token found to process.');
		return;
	}

	console.log(
		`Found ${tokensToProcess.length} tokens to check: ${tokensToProcess.map(({ mainSymbol }) => mainSymbol).join(', ')}`
	);

	const newTokens = [];

	for (const token of tokensToProcess) {
		const { mainSymbol } = token;

		console.log('--------------------------------');
		console.log(`Checking if token ${mainSymbol} already exists in the environment files.`);

		const { fileName, mainnetToken, testnetToken } = await manageEnvFile(token);

		updateTokensErc20Env({ fileName, mainnetToken, testnetToken });

		if (nonNullish(mainnetToken) || nonNullish(testnetToken)) {
			newTokens.push(token);
		}
	}

	if (filesCreatedOrModified) {
		console.log('--------------------------------');
		console.log('Running npm run format && npm run lint');
		execSync('npm run format && npm run lint', { stdio: 'inherit' });
	}

	if (newTokens.length > 0) {
		console.log('--------------------------------');
		console.log(
			'Final Step: To complete the integration of the new tokens, you need to create SVG icon files for each token and place them in the correct directory.'
		);
		console.log(`Navigate to the following directory: ${path.join(SVG_DIR_PATH)}`);

		newTokens.forEach(({ mainSymbol }) => {
			console.log(
				`- For token ${mainSymbol}, create an SVG file named '${mainSymbol.toLowerCase()}.svg'`
			);
		});

		console.log(
			'Ensure that the SVG files are valid SVG format and represent the tokens, typically the logo or symbol of each token.'
		);

		newTokens.forEach(({ mainSymbol }) => {
			console.log(
				`Example: For token ${mainSymbol}, the SVG file should be: ${SVG_DIR_PATH}/${mainSymbol.toLowerCase()}.svg`
			);
		});
	}
};

try {
	await main();
} catch (err) {
	console.error(`Error in main function:\n${err}`);
	process.exit(1);
}



================================================
FILE: scripts/add.tokens.erc20.sh
================================================
#!/bin/sh

if [ -n "$1" ]; then
  ETHERSCAN_API_KEY=$1
  node ./scripts/add.tokens.erc20.mjs --etherscan-api-key "$ETHERSCAN_API_KEY"
else
  node ./scripts/add.tokens.erc20.mjs
fi



================================================
FILE: scripts/build.backend.args.ic.did
================================================
(
	variant {
		Init = record {
			ecdsa_key_name = "key_1";
			allowed_callers = vec { principal "nynz6-haaaa-aaaan-qzqda-cai" };
			cfs_canister_id = opt principal "grghe-syaaa-aaaar-qabyq-cai";
			derivation_origin = opt "https://oisy.com";
			supported_credentials = opt vec {
				record {
					credential_type = variant { ProofOfUniqueness };
					ii_origin = "https://identity.internetcomputer.org";
					ii_canister_id = principal "rdmx6-jaaaa-aaaaa-aaadq-cai";
					issuer_origin = "https://id.decideai.xyz/";
					issuer_canister_id = principal "qgxyr-pyaaa-aaaah-qdcwq-cai"
				}
			};
			ic_root_key_der = null
		}
	}
)



================================================
FILE: scripts/build.backend.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Generates the backend arguments.

  # Prerequisites
  Canisters IDs must already be known to dfx.

	This is intended to be run as part of a dfx command, so the dfx environment variables are assumed to be available:
	  https://internetcomputer.org/docs/current/developer-docs/developer-tools/cli-tools/cli-reference/dfx-envars
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

# We write the output to a file including the network name, then we symlink it to the generic name specified in dfx.json.
CANISTER_ARG_PATH_BACKEND="$(jq -re .canisters.backend.init_arg_file dfx.json)"
CANISTER_ARG_PATH_BACKEND_FOR_NETWORK="${CANISTER_ARG_PATH_BACKEND%.did}.$DFX_NETWORK.did"
mkdir -p "$(dirname "$CANISTER_ARG_PATH_BACKEND")"
ln -s -f "$(basename "$CANISTER_ARG_PATH_BACKEND_FOR_NETWORK")" "$CANISTER_ARG_PATH_BACKEND"

case "$DFX_NETWORK" in
"staging")
  ECDSA_KEY_NAME="test_key_1"
  # For security reasons, mainnet root key will be hardcoded in the backend canister.
  ic_root_key_der="null"
  # URL used by issuer in the issued verifiable credentials (typically hard-coded)
  # Represents more an ID than a URL
  POUH_ISSUER_VC_URL="https://${CANISTER_ID_POUH_ISSUER}.icp0.io/"
  DERIVATION_ORIGIN="https://tewsx-xaaaa-aaaad-aadia-cai.icp0.io"
  ;;
"ic")
  ECDSA_KEY_NAME="key_1"
  # For security reasons, mainnet root key will be hardcoded in the backend canister.
  ic_root_key_der="null"
  # URL used by issuer in the issued verifiable credentials (tipically hard-coded)
  # Represents more an ID than a URL
  POUH_ISSUER_VC_URL="https://id.decideai.xyz/"
  DERIVATION_ORIGIN="https://oisy.com"
  ;;
*)
  ECDSA_KEY_NAME="dfx_test_key"
  # In order to read the root key we grab the array from the '"root_key": [...]' bit, the brackets
  # to match what candid expects ({}), replace the commas between array entries to match
  # what candid expects (semicolon) and annotate the numbers with their type (otherwise dfx assumes 'nat'
  # instead of 'nat8').
  rootkey_did=$(dfx ping "${DFX_NETWORK:-local}" |
    jq -r '.root_key | reduce .[] as $item ("{ "; "\(.) \($item):nat8;") + " }"')
  echo "Parsed rootkey: ${rootkey_did:0:20}..." >&2
  ic_root_key_der="opt vec $rootkey_did"
  # URL used by issuer in the issued verifiable credentials (tipically hard-coded)
  # We use the dummy issuer canister for local development
  POUH_ISSUER_VC_URL="https://dummy-issuer.vc/"
  DERIVATION_ORIGIN="http://${CANISTER_ID_BACKEND}.localhost:4943"
  ;;
esac

# If the rewards canister is known, it may perform privileged actions such as find which users are eligible for rewards.
if [[ "${CANISTER_ID_REWARDS:-}" == "" ]]; then
  ALLOWED_CALLERS="vec {}"
else
  ALLOWED_CALLERS="vec{ principal \"$CANISTER_ID_REWARDS\" }"
fi

# URL used by II-issuer in the id_alias-verifiable credentials (hard-coded in II)
# Represents more an ID than a URL
II_VC_URL="https://identity.internetcomputer.org"

echo "Deploying backend with the following arguments: ${POUH_ISSUER_VC_URL}"

echo "(variant {
    Init = record {
         ecdsa_key_name = \"$ECDSA_KEY_NAME\";
         allowed_callers = $ALLOWED_CALLERS;
         cfs_canister_id = opt principal \"$CANISTER_ID_SIGNER\";
         derivation_origin = opt \"$DERIVATION_ORIGIN\";
         supported_credentials = opt vec {
            record {
              credential_type = variant { ProofOfUniqueness };
              ii_origin = \"$II_VC_URL\";
              ii_canister_id = principal \"$CANISTER_ID_INTERNET_IDENTITY\";
              issuer_origin = \"$POUH_ISSUER_VC_URL\";
              issuer_canister_id = principal \"$CANISTER_ID_POUH_ISSUER\";
            }
         };
         ic_root_key_der = $ic_root_key_der;
     }
  })" >"$CANISTER_ARG_PATH_BACKEND_FOR_NETWORK"



================================================
FILE: scripts/build.backend.metadata.sh
================================================
#!/usr/bin/env bash
set -euxo pipefail

CANISTER="backend"
export CANISTER

# Get the input variables
CANDID_FILE="$(jq -r ".canisters.$CANISTER.candid" dfx.json)"
ARGS_FILE="$(jq -r ".canisters.$CANISTER.init_arg_file" dfx.json)"
WASM_FILE="$(jq -r ".canisters.$CANISTER.wasm" dfx.json)"
BUILD_DIR="target/wasm32-unknown-unknown/release"
COMMIT_FILE="in/commit"
TAGS_FILE="in/tags"

####
# Gets commit and tag information, if available.
mkdir -p in
if test -d .git; then
  scripts/commit-metadata
else
  touch "$COMMIT_FILE" "$TAGS_FILE"
fi
# Keep just the tags with semantic versions
grep -E '^v[0-9]' "$TAGS_FILE" >"${TAGS_FILE}.semver" || true # No match is fine.

####
# Builds the candid file
mkdir -p "$(dirname "$CANDID_FILE")"
candid-extractor "$BUILD_DIR/$CANISTER.wasm" >"$CANDID_FILE"

####
# Optimize Wasm and set metadata
ic-wasm \
  "$BUILD_DIR/$CANISTER.wasm" \
  -o "$BUILD_DIR/$CANISTER.optimized.wasm" \
  shrink

# adds the content of $canister.did to the `icp:public candid:service` custom section of the public metadata in the wasm
ic-wasm "$BUILD_DIR/$CANISTER.optimized.wasm" -o "$BUILD_DIR/$CANISTER.service.wasm" metadata candid:service -f "$CANDID_FILE" -v public
ic-wasm "$BUILD_DIR/$CANISTER.service.wasm" -o "$BUILD_DIR/$CANISTER.args.wasm" metadata candid:args -f "$ARGS_FILE" -v public
ic-wasm "$BUILD_DIR/$CANISTER.args.wasm" -o "$BUILD_DIR/$CANISTER.commit.wasm" metadata git:commit -f "$COMMIT_FILE" -v public
ic-wasm "$BUILD_DIR/$CANISTER.commit.wasm" -o "$BUILD_DIR/$CANISTER.metadata.wasm" metadata git:tags -f "${TAGS_FILE}.semver" -v public

gzip -fn "$BUILD_DIR/$CANISTER.metadata.wasm"

mkdir -p "$(dirname "$WASM_FILE")"
mv "$BUILD_DIR/$CANISTER.metadata.wasm.gz" "$WASM_FILE"

####
# Success
scripts/build.report.sh "$CANISTER"



================================================
FILE: scripts/build.backend.sh
================================================
#!/usr/bin/env bash
set -euxo pipefail

case "${BACKEND_BUILD_STRATEGY:-}" in
none | prebuilt)
  echo "In this mode, existing args and Wasm are used."
  BACKEND_WASM_FILE="$(jq -r .canisters.backend.wasm dfx.json)"
  BACKEND_ARGUMENT_FILE="$(jq -r .canisters.backend.init_arg_file dfx.json)"
  test -e "$BACKEND_WASM_FILE" || {
    echo "ERROR with 'prebuilt' strategy: Wasm file not found at: '$BACKEND_WASM_FILE'"
    echo "      Please run 'dfx build backend' first."
    exit 1
  } >&2
  test -e "$BACKEND_ARGUMENT_FILE" || {
    echo "ERROR with 'prebuilt' strategy: Argument file not found at: '$BACKEND_WASM_FILE'"
    echo "      Please run 'dfx build backend' first."
    exit 1
  } >&2
  ;;
args)
  echo "In this mode, only the arguments are recreated. An existing Wasm is used."
  BACKEND_WASM_FILE="$(jq -r .canisters.backend.wasm dfx.json)"
  test -e "$BACKEND_WASM_FILE" || {
    echo "ERROR with 'prebuilt' strategy: Wasm file not found at: '$BACKEND_WASM_FILE'"
    echo "      Please run 'dfx build backend' first."
    exit 1
  } >&2
  scripts/build.backend.args.sh
  ;;
*)
  scripts/build.backend.wasm.sh
  scripts/build.backend.args.sh
  scripts/commit-metadata
  scripts/build.backend.metadata.sh
  ;;
esac



================================================
FILE: scripts/build.backend.test
================================================
#!/usr/bin/env bash
set -euo pipefail
EXIT=0

(
  : The backend Wasm should include metadata
  set -euo pipefail
  rm -fr in out
  TOY_TAG="v000.000.$RANDOM"
  git tag -f "$TOY_TAG"
  #  dfx build backend --ic
  ./scripts/docker-build
  git tag -d "$TOY_TAG"

  (
    echo "Tag metadata should include the tag we just created"
    tag_metadata="$(ic-wasm <(gunzip <./out/backend.wasm.gz) metadata git:tags)"
    if echo "$tag_metadata" | grep -q --line-regexp "$TOY_TAG"; then
      echo OK: Found tag
    else
      echo "ERROR: Incorrect tag metadata"
      echo "Expected a line consisting of '$TOY_TAG'"
      echo "Found: '$tag_metadata'"
      exit 1
    fi
  ) || EXIT=1

  (
    echo "Commit metadata should be the current commit"
    COMMIT="$(git rev-parse HEAD)"
    commit_metadata="$(ic-wasm <(gunzip <./out/backend.wasm.gz) metadata git:commit)"
    if [[ "${commit_metadata:-}" == "$COMMIT" ]]; then
      echo OK: Commit
    else
      echo "ERROR: Incorrect git:commit metadata"
      echo "Expected: '$COMMIT'"
      echo "Found:    '$commit_metadata'"
      exit 1
    fi
  ) || EXIT=1

  (
    echo "Service metadata should be the did file"
    CANDID_SERVICE_FILE="$(mktemp ,candid-service.XXXXXX)"
    EXPECTED_SERVICE_FILE="src/backend/backend.did"
    ic-wasm <(gunzip <./out/backend.wasm.gz) metadata candid:service >"$CANDID_SERVICE_FILE"
    if diff --ignore-all-space --ignore-blank-lines "$EXPECTED_SERVICE_FILE" "$CANDID_SERVICE_FILE"; then
      echo OK: Service
      rm "$CANDID_SERVICE_FILE"
    else
      echo "ERROR: Incorrect candid:service metadata"
      echo "Expected: EXPECTED_SERVICE_FILE"
      echo "Found:    $CANDID_SERVICE_FILE"
      exit 1
    fi
  ) || EXIT=1
  (
    echo "Argument metadata should be the generated args"
    CANDID_ARGS_FILE="$(mktemp ,candid-args.XXXXXX)"
    EXPECTED_ARGS_FILE="out/backend.args.did"
    ic-wasm <(gunzip <./out/backend.wasm.gz) metadata candid:args >"$CANDID_ARGS_FILE"
    if diff --ignore-all-space --ignore-blank-lines "$EXPECTED_ARGS_FILE" "$CANDID_ARGS_FILE"; then
      echo OK: Args
      rm "$CANDID_ARGS_FILE"
    else
      echo "ERROR: Incorrect candid:args metadata"
      echo "Expected: $EXPECTED_ARGS_FILE"
      echo "Found:    $CANDID_ARGS_FILE"
      exit 1
    fi
  ) || EXIT=1

) || EXIT=1

(
  echo "Change detector test for production"
  EXPECTED="scripts/build.backend.args.ic.did"
  ACTUAL="out/backend.args.ic.did"
  if diff --ignore-all-space --ignore-blank-lines "$EXPECTED" "$ACTUAL"; then
    echo "OK: Mainnet arguments are unchanged"
  else
    echo "WARNING: Mainnet arguments have changed.  If this is intentional, please run:"
    echo "  cp '$ACTUAL' '$EXPECTED'"
  fi

)

if ((EXIT == 0)); then
  echo "SUCCESS: Wasm metadata checks pass."
else
  echo "ERROR: One or more Wasm metadata checks failed"
fi
exit "$EXIT"



================================================
FILE: scripts/build.backend.wasm.sh
================================================
#!/usr/bin/env bash
set -euxo pipefail

CANISTER="backend"
export CANISTER

####
# Builds the Wasm without metadata
cargo build --locked --target wasm32-unknown-unknown --release -p $CANISTER



================================================
FILE: scripts/build.ckbtc_index.args.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Populates the ckbtc_index init args file.

	# Prerequisites
	This is expected to be run via dfx, and in particular that
	environment variables provided by dfx are set.

	EOF
  exit 0
}
set -euxo pipefail

: START populating the ckbtc_index install args file...
ARGS_FILE="$(jq -re .canisters.ckbtc_index.init_arg_file dfx.json)"
mkdir -p "$(dirname "$ARGS_FILE")"

cat <<EOF >"$ARGS_FILE"
(opt variant {
  Init = record {
    ledger_id = principal "$CANISTER_ID_CKBTC_LEDGER";
   }
})
EOF
: FINISH populating the ckbtc_index install args file.



================================================
FILE: scripts/build.ckbtc_index.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Assembles the ckbtc_index canister deploy artefacts.

	# Prerequisites
	This is expected to be run by dfx.  In particular,
	the code that creates the arguments uses environment
	variables set by dfx.

	EOF
  exit 0
}

set -euo pipefail

scripts/download.ckbtc.sh
scripts/build.ckbtc_index.args.sh



================================================
FILE: scripts/build.ckbtc_kyt.args.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Populates the ckbtc_kyt init args file.

	# Prerequisites
	This is expected to be run via dfx, and in particular that
	environment variables provided by dfx are set.

	EOF
  exit 0
}
set -euxo pipefail

: START populating the ckbtc_kyt install args file...
ARGS_FILE="$(jq -re .canisters.ckbtc_kyt.init_arg_file dfx.json)"
mkdir -p "$(dirname "$ARGS_FILE")"

cat <<EOF >"$ARGS_FILE"
(variant {
  InitArg = record {
    minter_id = principal "$CANISTER_ID_CKBTC_MINTER";
    maintainers = vec {};
    mode = variant { AcceptAll };
   }
})
EOF
: FINISH populating the ckbtc_kyt install args file.



================================================
FILE: scripts/build.ckbtc_kyt.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Assembles the ckbtc_kyt canister deploy artefacts.

	# Prerequisites
	This is expected to be run by dfx.  In particular,
	the code that creates the arguments uses environment
	variables set by dfx.

	EOF
  exit 0
}

set -euo pipefail

scripts/download.ckbtc.sh
scripts/build.ckbtc_kyt.args.sh



================================================
FILE: scripts/build.ckbtc_minter.args.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Populates the ckbtc_minter init args file.

	# Prerequisites
	This is expected to be run via dfx, and in particular that
	environment variables provided by dfx are set.

	EOF
  exit 0
}
set -euxo pipefail

: START populating the ckbtc_minter install args file...
ARGS_FILE="$(jq -re .canisters.ckbtc_minter.init_arg_file dfx.json)"
mkdir -p "$(dirname "$ARGS_FILE")"

cat <<EOF >"$ARGS_FILE"
(variant {
  Init = record {
       btc_network = variant { Regtest };
       ledger_id = principal "$CANISTER_ID_CKBTC_LEDGER";
       ecdsa_key_name = "dfx_test_key";
       retrieve_btc_min_amount = 10_000;
       max_time_in_queue_nanos = 420_000_000_000;
       min_confirmations = opt 12;
       mode = variant { GeneralAvailability };
       kyt_fee = opt 1_333;
       kyt_principal = opt principal "$CANISTER_ID_CKBTC_KYT";
   }
})
EOF
: FINISH populating the ckbtc_minter install args file.



================================================
FILE: scripts/build.ckbtc_minter.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Assembles the ckbtc_minter canister deploy artefacts.

	# Prerequisites
	This is expected to be run by dfx.  In particular,
	the code that creates the arguments uses environment
	variables set by dfx.

	EOF
  exit 0
}

set -euo pipefail

# Install ICP index locally as documented in:
# https://internetcomputer.org/docs/current/developer-docs/integrations/ledger/ledger-local-setup

scripts/download.ckbtc.sh
scripts/build.ckbtc_minter.args.sh



================================================
FILE: scripts/build.cketh_index.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

ARG_FILE="$(jq -re .canisters.cketh_index.init_arg_file dfx.json)"

mkdir -p "$(dirname "$ARG_FILE")"

cat <<-EOF >"$ARG_FILE"
(opt variant {
  Init = record {
    ledger_id = principal "$CANISTER_ID_CKETH_LEDGER";
   }
})
EOF



================================================
FILE: scripts/build.cketh_index.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
scripts/download.cketh.sh
scripts/build.cketh_index.args.sh



================================================
FILE: scripts/build.cketh_ledger.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

PRINCIPAL="$(dfx identity get-principal)"
ARG_FILE="$(jq -re .canisters.cketh_ledger.init_arg_file dfx.json)"

mkdir -p "$(dirname "$ARG_FILE")"

cat <<-EOF >"$ARG_FILE"
(variant {
  Init = record {
     token_symbol = "ckSepoliaETH";
     token_name = "Chain key local Sepolia Ethereum";
     decimals = opt 18;
     max_memo_length = opt 80;
     minting_account = record { owner = principal "$CANISTER_ID_CKETH_MINTER" };
     transfer_fee = 9_500;
     metadata = vec {};
     initial_balances = vec {
        record { record { owner = principal "$PRINCIPAL"; }; 100_000_000_000_000_000_000; };
        record { record { owner = principal "x4w27-so7wg-cudsa-yy7fh-wcpy5-njul4-q54tv-euzzi-tdnzz-ill46-zqe"; }; 500_000_000_000_000_000; }
     };
     archive_options = record {
         num_blocks_to_archive = 10_000;
         trigger_threshold = 20_000;
         controller_id = principal "$PRINCIPAL";
         cycles_for_archive_creation = opt 1_000_000_000_000;
         max_message_size_bytes = null;
         node_max_memory_size_bytes = opt 3_221_225_472;
     };
     feature_flags  = opt record { icrc2 = true };
 }
})
EOF



================================================
FILE: scripts/build.cketh_ledger.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
scripts/download.cketh.sh
scripts/build.cketh_ledger.args.sh



================================================
FILE: scripts/build.cketh_minter.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

ARG_FILE="$(jq -re .canisters.cketh_minter.init_arg_file dfx.json)"

mkdir -p "$(dirname "$ARG_FILE")"

[[ "${CANISTER_ID_CKETH_LEDGER:-}" != "" ]] || {
  echo "ERROR: cketh_ledger canister ID is not known."
  echo "       Please create the cketh_ledger canister before deploying the minter:"
  echo
  echo "       dfx canister create cketh_ledger --network $DFX_NETWORK"
  echo
  echo "NOTE: There is an (expected) circular dependency between the ledger and minter."
  echo "      To resolve this, both canister IDs need to be known before deploying either."
  exit 1
} >&2

cat <<EOF >"$ARG_FILE"
(variant {
  InitArg = record {
       ethereum_network = variant {Sepolia};
       ecdsa_key_name = "dfx_test_key";
       ethereum_contract_address = opt "0xb44B5e756A894775FC32EDdf3314Bb1B1944dC34";
       ledger_id = principal "$CANISTER_ID_CKETH_LEDGER";
       ethereum_block_height = variant {Finalized};
       minimum_withdrawal_amount = 10_000_000_000_000_000;
       next_transaction_nonce = 209;
       last_scraped_block_number = 5371702;
   }
})
EOF



================================================
FILE: scripts/build.cketh_minter.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
scripts/download.cketh.sh
scripts/build.cketh_minter.args.sh



================================================
FILE: scripts/build.ckusdc_index.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

ARG_FILE="$(jq -re .canisters.ckusdc_index.init_arg_file dfx.json)"

mkdir -p "$(dirname "$ARG_FILE")"

cat <<-EOF >"$ARG_FILE"
(opt variant {
  Init = record {
    ledger_id = principal "$CANISTER_ID_CKUSDC_LEDGER";
   }
})
EOF



================================================
FILE: scripts/build.ckusdc_index.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
scripts/download.cketh.sh # Uses the same Wasms as cketh.
scripts/build.ckusdc_index.args.sh



================================================
FILE: scripts/build.ckusdc_ledger.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

PRINCIPAL="$(dfx identity get-principal)"
ARG_FILE="$(jq -re .canisters.ckusdc_ledger.init_arg_file dfx.json)"

mkdir -p "$(dirname "$ARG_FILE")"

cat <<-EOF >"$ARG_FILE"
(variant {
	Init = record {
		 token_symbol = "ckSepoliaUSDC";
		 token_name = "Chain key Sepolia USDC";
		 decimals = opt 6;
		 max_memo_length = opt 80;
		 minting_account = record { owner = principal "$CANISTER_ID_CKETH_MINTER" };
		 transfer_fee = 9_500;
		 metadata = vec {};
		 initial_balances = vec {
		   record { record { owner = principal "$PRINCIPAL"; }; 100_000_000_000_000_000_000; };
		   record { record { owner = principal "x4w27-so7wg-cudsa-yy7fh-wcpy5-njul4-q54tv-euzzi-tdnzz-ill46-zqe"; }; 500_000_000_000_000_000; };
		 };
		 archive_options = record {
		     num_blocks_to_archive = 10_000;
		     trigger_threshold = 20_000;
		     controller_id = principal "$PRINCIPAL";
		     cycles_for_archive_creation = opt 1_000_000_000_000;
		     max_message_size_bytes = null;
		     node_max_memory_size_bytes = opt 3_221_225_472;
		 };
		 feature_flags  = opt record { icrc2 = true };
	}
})
EOF



================================================
FILE: scripts/build.ckusdc_ledger.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
scripts/download.cketh.sh # Uses the same Wasm as cketh.
scripts/build.ckusdc_ledger.args.sh



================================================
FILE: scripts/build.compress.sh
================================================
#!/usr/bin/env bash

find build/ -type f -print0 | xargs -0 -I{} gzip -fnk "{}"



================================================
FILE: scripts/build.csp.mjs
================================================
#!/usr/bin/env node

import { config } from 'dotenv';
import { createHash } from 'node:crypto';
import { readFileSync, writeFileSync } from 'node:fs';
import { dirname, join, relative } from 'node:path';
import { ENV, findHtmlFiles } from './build.utils.mjs';

config({ path: `.env.${ENV}` });

const buildCsp = (htmlFile) => {
	// 1. We extract the start script parsed by SvelteKit into the HTML file
	const indexHTMLWithoutStartScript = extractStartScript(htmlFile);
	// 2. We add our custom script loader - we inject it at build time because it would throw an error when developing locally if missing
	const indexHTMLWithScriptLoader = injectScriptLoader({
		content: indexHTMLWithoutStartScript,
		filePath: htmlFile
	});
	// 3. Replace preloaders
	const indexHTMLWithPreloaders = injectLinkPreloader(indexHTMLWithScriptLoader);
	// 4. remove the content-security-policy tag injected by SvelteKit
	const indexHTMLNoCSP = removeDefaultCspTag(indexHTMLWithPreloaders);
	// 5. We calculate the sha256 values for these scripts and update the CSP
	const indexHTMLWithCSP = updateCSP(indexHTMLNoCSP);

	writeFileSync(htmlFile, indexHTMLWithCSP);
};

const removeDefaultCspTag = (indexHtml) =>
	indexHtml.replace('<meta http-equiv="content-security-policy" content="">', '');

/**
 * We need a script loader to implement a proper Content Security Policy. See the `updateCSP` doc for more information.
 */
const injectScriptLoader = ({ content, filePath }) => {
	// We need to provide the relative path to the script; otherwise, it will be resolved from the root at runtime.
	// This isn't an issue if all loaders are consistent and use the same name,
	// but it could become a problem if Svelte changes its approach, or we start hashing the script names.
	const buildDir = join(process.cwd(), 'build');
	const scriptName = 'main.js';

	const parentFolders = relative(buildDir, dirname(filePath));
	const loaderSrc = `${parentFolders !== '' ? `/${parentFolders}/` : ''}${scriptName}`;

	return content.replace(
		'<!-- SCRIPT_LOADER -->',
		`<script sveltekit-loader>
      const loader = document.createElement("script");
      loader.type = "module";
      loader.src = "${loaderSrc}";
      document.head.appendChild(loader);
    </script>`
	);
};

/**
 * Calculating the sh256 value for the preloaded link and whitelisting these seem not to be supported by the Content-Security-Policy.
 * Instead, we transform these in dynamic scripts and add the sha256 value of the script to the script-src policy of the CSP.
 */
const injectLinkPreloader = (indexHtml) => {
	const preload = /<link rel="preload"[\s\S]*?href="([\s\S]*?)">/gm;

	const links = [];

	let p;
	while ((p = preload.exec(indexHtml))) {
		const [linkTag, src] = p;

		links.push({
			linkTag,
			src
		});
	}

	// 1. Inject pre-loaders dynamically after loading
	const loader = `<script sveltekit-preloader>
      const links = [${links.map(({ src }) => `'${src}'`)}];
      for (const link of links) {
          const preloadLink = document.createElement("link");
          preloadLink.href = link;
          preloadLink.rel = "preload";
          preloadLink.as = "script";
          document.head.appendChild(preloadLink);
      }
    </script>`;

	let updateIndex = indexHtml.replace('<!-- LINKS_PRELOADER -->', loader);

	// 2. Remove original <link rel="preload" as="script" />
	for (const url of links) {
		const { linkTag } = url;
		updateIndex = updateIndex.replace(linkTag, '');
	}

	return updateIndex;
};

/**
 * Using a CSP with 'strict-dynamic' with SvelteKit breaks in Firefox.
 * Issue: https://github.com/sveltejs/kit/issues/3558
 *
 * As a workaround:
 * 1. we extract the start script injected by SvelteKit in index.html into a separate main.js
 * 2. we remove the script content from index.html but let the script tag as anchor
 * 3. we use our custom script loader to load the main.js script
 */
const extractStartScript = (htmlFile) => {
	const indexHtml = readFileSync(htmlFile, 'utf8');

	const svelteKitStartScript = /(<script>)([\s\S]*?)(<\/script>)/gim;

	// 1. extract SvelteKit start script to a separate main.js file
	const [_script, _scriptStartTag, content, _scriptEndTag] = svelteKitStartScript.exec(indexHtml);
	const inlineScript = content.replace(/^\s*/gm, '');

	// Each file needs its own main.js because the script that calls the SvelteKit start function contains information dedicated to the route
	// i.e., the routeId and a particular id for the querySelector use to attach the content
	const folderPath = dirname(htmlFile);

	// 2. Extract the SvelteKit script into a separate file

	// We need to replace the document.currentScript.parentElement because the script is added to the head. SvelteKit except the <body /> element as an initial parameter.
	// We also need to attach explicitly to the `window` the __sveltekit_ variables because they are not defined in the global scope but are used as global.
	const moduleScript = inlineScript
		.replaceAll('document.currentScript.parentElement', "document.querySelector('body')")
		.replaceAll(/__sveltekit_(.*)\s=/g, 'window.$&');

	writeFileSync(join(folderPath, 'main.js'), moduleScript, 'utf8');

	// 3. Replace original SvelteKit script tag content with empty
	return indexHtml.replace(svelteKitStartScript, '$1$3');
};

/**
 * Inject "Content Security Policy" (CSP) into index.html for a production build
 *
 * Note about script-src and 'strict-dynamic':
 * Chrome 40+ / Firefox 31+ / Safari 15.4+ / Edge 15+ supports 'strict-dynamic'.
 * Safari 15.4 has been released recently - March 15, 2022 - that's why we add 'unsafe-inline' to the rules for backwards compatibility.
 * Browsers that support the 'strict-dynamic' rule will ignore these backwards directives (CSP 3).
 */
const updateCSP = (indexHtml) => {
	const sw = /<script[\s\S]*?>([\s\S]*?)<\/script[^\S\r\n]*[^>]*?>/gim;

	const indexHashes = [];

	let m;
	while ((m = sw.exec(indexHtml))) {
		const [_, content] = m;

		indexHashes.push(`'sha256-${createHash('sha256').update(content).digest('base64')}'`);
	}

	const ethMainnetConnectSrc =
		'https://api.etherscan.io wss://eth-mainnet.g.alchemy.com https://eth-mainnet.g.alchemy.com https://mainnet.infura.io';
	const ethSepoliaConnectSrc =
		'https://api-sepolia.etherscan.io https://sepolia.infura.io wss://eth-sepolia.g.alchemy.com https://eth-sepolia.g.alchemy.com';

	const baseMainnetConnectSrc =
		'wss://base-mainnet.g.alchemy.com https://base-mainnet.g.alchemy.com https://base-mainnet.infura.io';
	const baseSepoliaConnectSrc =
		'wss://base-sepolia.g.alchemy.com https://base-sepolia.g.alchemy.com https://base-sepolia.infura.io';
	const arbitrumMainnetConnectSrc =
		'wss://arb-mainnet.g.alchemy.com https://arb-mainnet.g.alchemy.com https://arbitrum-mainnet.infura.io';
	const arbitrumSepoliaConnectSrc =
		'wss://arb-sepolia.g.alchemy.com https://arb-sepolia.g.alchemy.com https://arbitrum-sepolia.infura.io';
	const bnbMainnetConnectSrc =
		'wss://bnb-mainnet.g.alchemy.com https://bnb-mainnet.g.alchemy.com https://bsc-mainnet.infura.io';
	const bnbTestnetConnectSrc =
		'wss://bnb-testnet.g.alchemy.com https://bnb-testnet.g.alchemy.com https://bsc-testnet.infura.io';
	const polygonMainnetConnectSrc =
		'wss://polygon-mainnet.g.alchemy.com https://polygon-mainnet.g.alchemy.com https://polygon-mainnet.infura.io https://gasstation.polygon.technology';
	const polygonAmoyConnectSrc =
		'wss://polygon-amoy.g.alchemy.com https://polygon-amoy.g.alchemy.com https://polygon-amoy.infura.io';
	const evmConnectSrc = `${baseMainnetConnectSrc} ${baseSepoliaConnectSrc} ${arbitrumMainnetConnectSrc} ${arbitrumSepoliaConnectSrc} ${bnbMainnetConnectSrc} ${bnbTestnetConnectSrc} ${polygonMainnetConnectSrc} ${polygonAmoyConnectSrc}`;

	const infuraConnectSrc = 'https://gas.api.infura.io';

	const blockstreamApiConnectSrc = 'https://blockstream.info';
	const blockchainApiConnectSrc = 'https://blockchain.info';

	const coingeckoApiConnectSrc = 'https://pro-api.coingecko.com';

	const paraswapApiConnectSrc = 'https://api.paraswap.io';

	const kongSwapApiConnectSrc = 'https://api.kongswap.io';

	const plausibleApiConnectSrc = 'https://plausible.io/api/event';

	const walletConnectSrc =
		'wss://relay.walletconnect.com wss://relay.walletconnect.org https://verify.walletconnect.com https://verify.walletconnect.org https://pulse.walletconnect.org';
	const walletConnectFrameSrc = 'https://verify.walletconnect.com https://verify.walletconnect.org';

	const onramperConnectFrameSrc = 'https://buy.onramper.dev https://buy.onramper.com';

	const solanaRpcApiConnectSrc =
		'https://api.mainnet-beta.solana.com wss://api.mainnet-beta.solana.com https://api.testnet.solana.com wss://api.testnet.solana.com https://api.devnet.solana.com wss://api.devnet.solana.com';
	const solanaAlchemyApiConnectSrc =
		'https://solana-mainnet.g.alchemy.com wss://solana-mainnet.g.alchemy.com https://solana-testnet.g.alchemy.com wss://solana-testnet.g.alchemy.com https://solana-devnet.g.alchemy.com wss://solana-devnet.g.alchemy.com';
	const solanaQuicknodeApiConnectSrc =
		'https://burned-little-dinghy.solana-mainnet.quiknode.pro wss://burned-little-dinghy.solana-mainnet.quiknode.pro wss://burned-little-dinghy.solana-testnet.quiknode.pro wss://burned-little-dinghy.solana-devnet.quiknode.pro';
	const solanaApiConnectSrc = `${solanaRpcApiConnectSrc} ${solanaAlchemyApiConnectSrc} ${solanaQuicknodeApiConnectSrc}`;

	const allConnectSrc =
		'https://ic0.app https://icp0.io https://icp-api.io' +
		` ${ethMainnetConnectSrc} ${ethSepoliaConnectSrc} ${evmConnectSrc} ${infuraConnectSrc} ${walletConnectSrc} ${onramperConnectFrameSrc} ${blockstreamApiConnectSrc} ${blockchainApiConnectSrc} ${coingeckoApiConnectSrc} ${solanaApiConnectSrc} ${plausibleApiConnectSrc} ${kongSwapApiConnectSrc} ${paraswapApiConnectSrc}`;

	// TODO: remove once the feature has been completed
	const NFTS_ENABLED = process.env.VITE_NFTS_ENABLED;

	const csp = `<meta
        http-equiv="Content-Security-Policy"
        content="default-src 'none';
        connect-src 'self' ${NFTS_ENABLED ? 'https: wss:' : allConnectSrc};
        img-src 'self' https: ipfs: data:;
        frame-src 'self' ${walletConnectFrameSrc} ${onramperConnectFrameSrc};
        manifest-src 'self';
        script-src 'unsafe-inline' 'strict-dynamic' ${indexHashes.join(' ')};
        base-uri 'self';
        form-action 'none';
        style-src 'self' 'unsafe-inline';
        font-src 'self';
        upgrade-insecure-requests;"
    />`;

	return indexHtml.replace('<!-- CONTENT_SECURITY_POLICY -->', csp);
};

const htmlFiles = findHtmlFiles();
htmlFiles.forEach((htmlFile) => buildCsp(htmlFile));



================================================
FILE: scripts/build.cycles_depositor.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the cycles_depositor installation arguments.

	The file is installed at the location defined for 'cycles_depositor' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"
ARG_FILE="$(jq -r .canisters.cycles_depositor.init_arg_file dfx.json)"

####
# Computes the install args, overwriting any existing args file.

CANISTER_ID_CYCLES_LEDGER="${CANISTER_ID_CYCLES_LEDGER:-$(dfx canister id cycles_ledger --network "$DFX_NETWORK")}"

# .. Creates the init args file
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"
cat <<EOF >"$ARG_FILE"
(record { ledger_id = principal "$CANISTER_ID_CYCLES_LEDGER" })
EOF

####
# Success
cat <<EOF
SUCCESS: The cycles_depositor argument file has been created:
cycles_depositor install args: $(sha256sum "$ARG_FILE")
EOF



================================================
FILE: scripts/build.cycles_depositor.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
		Creates the cycles_depositor installation files:

		- The Wasm and Candid files are downloaded.
		- The installation args are computed based on the target network,
		      determined by the DFX_NETWORK environment variable.

		The files are installed at at the locations defined for 'cycles_depositor' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"

LEDGER_RELEASE="v1.0.1"
CANDID_URL="https://github.com/dfinity/cycles-ledger/releases/download/cycles-ledger-${LEDGER_RELEASE}/depositor.did"
WASM_URL="https://github.com/dfinity/cycles-ledger/releases/download/cycles-ledger-${LEDGER_RELEASE}/depositor.wasm.gz"

CANDID_FILE="$(jq -r .canisters.cycles_depositor.candid dfx.json)"
WASM_FILE="$(jq -r .canisters.cycles_depositor.wasm dfx.json)"
ARG_FILE="$(jq -r .canisters.cycles_depositor.init_arg_file dfx.json)"

####
# Downloads the candid file
scripts/download-immutable.sh "$CANDID_URL" "$CANDID_FILE"

####
# Downloads the Wasm file
scripts/download-immutable.sh "$WASM_URL" "$WASM_FILE"

####
# Computes the install args, overwriting any existing args file.
scripts/build.cycles_depositor.args.sh

# Success
cat <<EOF
SUCCESS: The cycles_depositor installation files have been created:
cycles_depositor candid:       $CANDID_FILE
cycles_depositor Wasm:         $WASM_FILE
cycles_depositor install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.frontend-report.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

{
  # Hash the env file.
  # Note: Whitespace is removed from end of lines and the end of file.
  # TODO: Support other environments as well.
  ENV_FILE=".env.production"
  perl -pe 'eof&&chomp;s/\s+$//g' "$ENV_FILE" | sha256sum | awk -v e="$ENV_FILE" '{ $2=e; print}'
}



================================================
FILE: scripts/build.gldt_stake.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
Creates the GLDT stake installation files:

- The Wasm and Candid files are downloaded.

The files are installed at the locations defined for 'gldt_stake' in 'dfx.json'.
EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"
export GLDT_STAKE_BUILDENV="$DFX_NETWORK"

GLDT_STAKE_REPO_URL="https://raw.githubusercontent.com/GoldDAO/gold-dao/refs/heads/develop/"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${GLDT_STAKE_REPO_URL}/backend/canisters/gldt_stake/api/can.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
# TODO: replace with the gldt-stake repo WASM URL
WASM_URL="https://github.com/dfinity/oisy-wallet/raw/refs/heads/gldt-stake-wasm/wasms/gldt_stake_canister.wasm.gz"

CANDID_FILE="$(jq -r .canisters.gldt_stake.candid dfx.json)"
WASM_FILE_GZ="$(jq -r .canisters.gldt_stake.wasm dfx.json)"
WASM_FILE="${WASM_FILE_GZ%.gz}"
ARG_FILE="$(jq -r .canisters.gldt_stake.init_arg_file dfx.json)"

download() {
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

# Download candid and wasm
download candid
download wasm

# Compress Wasm
echo "Compressing Wasm: $WASM_FILE_GZ"
gzip -c "$WASM_FILE" >"$WASM_FILE_GZ"

# Generate init args
echo "Generating init args..."
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"

# Set default principals (can be overridden via env if needed)
INFO_CID="aaaaa-aa"
TRUSTED_CANISTER_MANAGER_CID="aaaaa-aa"
GOVERNANCE_CID="aaaaa-aa"
PASSCODE_MANAGER_CID="aaaaa-aa"
BACKUP_CID="aaaaa-aa"
FEE_RECEIVER_CID="aaaaa-aa"

cat <<EOF >"$ARG_FILE"
(
  principal "$INFO_CID",
  principal "$TRUSTED_CANISTER_MANAGER_CID",
  principal "$GOVERNANCE_CID",
  principal "$PASSCODE_MANAGER_CID",
  principal "$BACKUP_CID",
  opt principal "$FEE_RECEIVER_CID"
)
EOF

cat <<EOF
SUCCESS: The gldt_stake installation files have been created:
gldt_stake candid:       $CANDID_FILE
gldt_stake Wasm:         $WASM_FILE_GZ
gldt_stake install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.ic-domains.mjs
================================================
import { readFileSync, writeFileSync } from 'node:fs';
import { join } from 'node:path';
import { OISY_IC_DOMAIN, replaceEnv } from './build.utils.mjs';

const generateDomain = (targetFile) => {
	let content = readFileSync(targetFile, 'utf8');

	const domain = OISY_IC_DOMAIN;

	// For information such as custom domains, only the domain without protocol is required
	const { host: value } = new URL(domain);
	content = replaceEnv({
		content,
		pattern: `{{VITE_OISY_DOMAIN}}`,
		value
	});

	writeFileSync(targetFile, content);
};

generateDomain(join(process.cwd(), 'build', '.well-known', 'ic-domains'));



================================================
FILE: scripts/build.ic-domains.test
================================================
#!/usr/bin/env bash
set -euxo pipefail

print_help() {
  cat <<-"EOF"

  Usage: $0 [--help] [<actual-domains-file>]

	EOF
}

if [[ "${1:-}" == "--help" ]]; then
  print_help
  exit 0
fi

# Prints the Oisy domain name for every network.
# - The URL is the one in .well-known/ic-domains, used by the Internet Computer.
dfx_network_domains() {
  scripts/build.ic-domains.test.list | while read -r i; do
    if [[ -d build ]]; then
      rm -rf build
    fi
    dfx build frontend --network "$i" >/dev/null 2>/dev/null && cat build/.well-known/ic-domains && echo " $i"
  done
}

(
  echo Checking domains for all known networks...
  EXPECTED_DOMAINS="$0.expected"
  if [[ -n "${1:-}" ]]; then
    ACTUAL_DOMAINS="$1"
  else
    ACTUAL_DOMAINS="$(mktemp "$0.actual.XXXXXXXXXX")"
    dfx_network_domains >"$ACTUAL_DOMAINS"
  fi
  if diff --ignore-all-space --ignore-blank-lines <(sort <"$EXPECTED_DOMAINS") <(sort <"$ACTUAL_DOMAINS"); then
    echo OK: ic-domains
    rm "$ACTUAL_DOMAINS"
  else
    echo "ERROR: Incorrect .well-known/ic-domains"
    echo "Expected: $EXPECTED_DOMAINS"
    echo "Found:    $ACTUAL_DOMAINS"
    echo "==== START DIFF"
    diff "$EXPECTED_DOMAINS" "$ACTUAL_DOMAINS" || true
    echo "==== END DIFF"
    exit 1
  fi
)



================================================
FILE: scripts/build.ic-domains.test.expected
================================================
oisy.com ic
audit.oisy.com audit
beta.oisy.com beta
staging.oisy.com staging
fe1.oisy.com test_fe_1
fe2.oisy.com test_fe_2
fe3.oisy.com test_fe_3
fe4.oisy.com test_fe_4
fe5.oisy.com test_fe_5
fe6.oisy.com test_fe_6
e2e.oisy.com e2e



================================================
FILE: scripts/build.ic-domains.test.list
================================================
#!/usr/bin/env bash
set -euxo pipefail

# Prints all known dfx networks:
# - Built-in networks (local & ic)
# - Networks listed in dfx.json
echo ic
# echo local - Already listed in dfx.json
jq -r '.networks|keys[]' dfx.json



================================================
FILE: scripts/build.icp_index.args.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Populates the icp_index init args file.

	# Prerequisites
	This is expected to be run via dfx, and in particular that
	environment variables provided by dfx are set.

	EOF
  exit 0
}
set -euxo pipefail

: START populating the icp_index install args file...
ARGS_FILE="$(jq -re .canisters.icp_index.init_arg_file dfx.json)"
mkdir -p "$(dirname "$ARGS_FILE")"

cat <<EOF >"$ARGS_FILE"
  (record {ledger_id = principal"${CANISTER_ID_ICP_LEDGER}";})
EOF
: FINISH populating the icp_index install args file.



================================================
FILE: scripts/build.icp_index.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Assembles the icp_index canister deploy artefacts.

	# Prerequisites
	This is expected to be run by dfx.  In particular,
	the code that creates the arguments uses environment
	variables set by dfx.

	EOF
  exit 0
}

set -euo pipefail

# Install ICP index locally as documented in:
# https://internetcomputer.org/docs/current/developer-docs/integrations/ledger/ledger-local-setup

scripts/build.icp_index.wasm.sh
scripts/build.icp_index.args.sh



================================================
FILE: scripts/build.icp_index.wasm.sh
================================================
#!/usr/bin/env bash
[[ "${1:-}" != "--help" ]] || {
  cat <<-EOF

	Populates the icp_index Wasm file.

	EOF
  exit 0
}
set -euo pipefail

WASM_FILE="$(jq -re .canisters.icp_index.wasm dfx.json)"
mkdir -p "$(dirname "$WASM_FILE")"
if test -e "${WASM_FILE}"; then
  echo "Using existing icp_index Wasm at: '$WASM_FILE'"
else
  ./scripts/download.icp.sh
fi



================================================
FILE: scripts/build.icp_ledger.args.sh
================================================
#!/usr/bin/env bash
set -euxo pipefail

# Ensure that a minter id exists:
dfx identity get-principal --identity minter 2>/dev/null || dfx identity new minter --storage-mode=plaintext

MINTER_ACCOUNT_ID=$(dfx ledger account-id --identity minter)
CALLER_ACCOUNT_ID=$(dfx ledger account-id)

ARGS_FILE="$(jq -re .canisters.icp_ledger.init_arg_file dfx.json)"
mkdir -p "$(dirname "$ARGS_FILE")"

mkdir -p target/ic
cat <<EOF >"$ARGS_FILE"
  (variant {
    Init = record {
      minting_account = "$MINTER_ACCOUNT_ID";
      initial_values = vec {
        record {
          "$CALLER_ACCOUNT_ID";
          record {
            e8s = 100_000_000_000 : nat64;
          };
        };
      };
      send_whitelist = vec {};
      transfer_fee = opt record {
        e8s = 10_000 : nat64;
      };
      token_symbol = opt "LICP";
      token_name = opt "Local ICP";
    }
  })
EOF



================================================
FILE: scripts/build.icp_ledger.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

# Install ICP ledger locally as documented in:
# https://internetcomputer.org/docs/current/developer-docs/integrations/ledger/ledger-local-setup

scripts/build.icp_ledger.wasm.sh
scripts/build.icp_ledger.args.sh



================================================
FILE: scripts/build.icp_ledger.wasm.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

WASM_FILE="$(jq -re .canisters.icp_ledger.wasm dfx.json)"
mkdir -p "$(dirname "$WASM_FILE")"
if test -e "${WASM_FILE}"; then
  echo "Using existing icp_ledger Wasm at: '$WASM_FILE'"
else
  ./scripts/download.icp.sh
fi



================================================
FILE: scripts/build.icp_swap_factory.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
Creates the ICP Swap Factory installation files:

- The Wasm and Candid files are downloaded.

The files are installed at the locations defined for 'icp_swap_factory' in 'dfx.json'.
EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"
export ICP_SWAP_FACTORY_BUILDENV="$DFX_NETWORK"

FACTORY_RELEASE_URL="https://raw.githubusercontent.com/ICPSwap-Labs/docs/ac989c62fb65ed39769dbebfa94eb57f90c86d8f/_canister/SwapFactory"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${FACTORY_RELEASE_URL}/SwapFactory.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
WASM_URL="${FACTORY_RELEASE_URL}/SwapFactory.wasm"

CANDID_FILE="$(jq -r .canisters.icp_swap_factory.candid dfx.json)"
WASM_FILE_GZ="$(jq -r .canisters.icp_swap_factory.wasm dfx.json)"
WASM_FILE="${WASM_FILE_GZ%.gz}"
ARG_FILE="$(jq -r .canisters.icp_swap_factory.init_arg_file dfx.json)"

download() {
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

# Download candid and wasm
download candid
download wasm

# Compress Wasm
echo "Compressing Wasm: $WASM_FILE_GZ"
gzip -c "$WASM_FILE" >"$WASM_FILE_GZ"

# Generate init args
echo "Generating init args..."
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"

# Set default principals (can be overridden via env if needed)
INFO_CID="aaaaa-aa"
TRUSTED_CANISTER_MANAGER_CID="aaaaa-aa"
GOVERNANCE_CID="aaaaa-aa"
PASSCODE_MANAGER_CID="aaaaa-aa"
BACKUP_CID="aaaaa-aa"
FEE_RECEIVER_CID="aaaaa-aa"

cat <<EOF >"$ARG_FILE"
(
  principal "$INFO_CID",
  principal "$TRUSTED_CANISTER_MANAGER_CID",
  principal "$GOVERNANCE_CID",
  principal "$PASSCODE_MANAGER_CID",
  principal "$BACKUP_CID",
  opt principal "$FEE_RECEIVER_CID",
  principal "$INFO_CID",
)
EOF

cat <<EOF
SUCCESS: The icp_swap_factory installation files have been created:
icp_swap_factory candid:       $CANDID_FILE
icp_swap_factory Wasm:         $WASM_FILE_GZ
icp_swap_factory install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.icp_swap_pool.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the ICP Swap Pool installation files:

	- The Wasm and Candid files are downloaded.

	The files are installed at at the locations defined for 'icp_swap_pool' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

ICP_SWAP_POOL_BUILDENV="$DFX_NETWORK"
export ICP_SWAP_POOL_BUILDENV

ICP_SWAP_REPO_URL="https://raw.githubusercontent.com/ICPSwap-Labs/docs/ac989c62fb65ed39769dbebfa94eb57f90c86d8f/_canister/SwapPool"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${ICP_SWAP_REPO_URL}/SwapPool.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
WASM_URL="${ICP_SWAP_REPO_URL}/SwapPool.wasm"

CANDID_FILE="$(jq -r .canisters.icp_swap_pool.candid dfx.json)"
WASM_FILE_GZ="$(jq -r .canisters.icp_swap_pool.wasm dfx.json)"
WASM_FILE="${WASM_FILE_GZ%.gz}"
ARG_FILE="$(jq -r .canisters.icp_swap_pool.init_arg_file dfx.json)"

download() {
  : 'Downloads a URL to a given file.'
  # shellcheck disable=SC2016 # The $ in the comment is not meant to be expanded.
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

# Download candid and wasm
download candid
download wasm

# Compress Wasm
echo "Compressing Wasm: $WASM_FILE_GZ"
gzip <"$WASM_FILE" >"$WASM_FILE_GZ"

# Set token config
TOKEN0='record { address = "ryjl3-tyaaa-aaaaa-aaaba-cai"; standard = "icrc-1" }'
TOKEN1='record { address = "mxzaz-hqaaa-aaaar-qaada-cai"; standard = "icrc-1" }'

OWNER_PRINCIPAL="$(dfx identity get-principal)"

# Generate init args
echo "Generating init args..."
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"

cat <<EOF >"$ARG_FILE"
(
  $TOKEN0,
  $TOKEN1,
  principal "$OWNER_PRINCIPAL",
  principal "$OWNER_PRINCIPAL",
  principal "$OWNER_PRINCIPAL",
  principal "$OWNER_PRINCIPAL",
)
EOF

####
# Success
cat <<EOF
SUCCESS: The icp_swap_pool installation files have been created:
icp_swap_pool candid:       $CANDID_FILE
icp_swap_pool Wasm:         $WASM_FILE_GZ
icp_swap_pool install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.ii-alternative-origins.mjs
================================================
#!/usr/bin/env node

import { notEmptyString } from '@dfinity/utils';
import { config } from 'dotenv';
import { writeFileSync } from 'node:fs';
import { join } from 'node:path';
import { ENV } from './build.utils.mjs';

config({ path: `.env.${ENV}` });

const writeAlternativeOrigins = (alternativeOrigins) => {
	const iiAlternativeOriginsFile = join(
		process.cwd(),
		'build',
		'.well-known',
		'ii-alternative-origins'
	);
	writeFileSync(iiAlternativeOriginsFile, JSON.stringify(alternativeOrigins));
};

const alternativeOrigins = (process.env['VITE_AUTH_ALTERNATIVE_ORIGINS'] ?? '')
	.split(',')
	.filter(notEmptyString);

if (alternativeOrigins.length === 0) {
	process.exit(0);
}

const assertAlternativeOrigin = (alternativeOrigin) => new URL(alternativeOrigin);
alternativeOrigins.forEach(assertAlternativeOrigin);

writeAlternativeOrigins({
	alternativeOrigins
});



================================================
FILE: scripts/build.kong_backend.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the Kong Backend installation files:

	- The Wasm and Candid files are downloaded.

	The files are installed at at the locations defined for 'kong_backend' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

KONG_BUILDENV="$DFX_NETWORK"
export KONG_BUILDENV

KONG_REPO_URL="https://raw.githubusercontent.com/KongSwap/kong/bea79b2f2259e5bd5a29739297d4a9f5db4fb19a/wasm"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${KONG_REPO_URL}/kong_backend.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
WASM_URL="${KONG_REPO_URL}/kong_backend.wasm.gz"

CANDID_FILE="$(jq -r .canisters.kong_backend.candid dfx.json)"
WASM_FILE="$(jq -r .canisters.kong_backend.wasm dfx.json)"

download() {
  : 'Downloads a URL to a given file.'
  # shellcheck disable=SC2016 # The $ in the comment is not meant to be expanded.
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

####
# Downloads the candid file, if it does not exist already.
download candid

####
# Downloads the Wasm file, if it does not exist already.
download wasm

####
# Success
cat <<EOF
SUCCESS: The kong_backend installation files have been created:
kong_backend candid:       $CANDID_FILE
kong_backend Wasm:         $WASM_FILE
EOF



================================================
FILE: scripts/build.llm.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
Creates the LLM installation files:

- The Wasm and Candid files are downloaded.

The files are installed at the locations defined for 'llm' in 'dfx.json'.
EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"
export LLM_BUILDENV="$DFX_NETWORK"

LLM_RELEASE_URL="https://github.com/dfinity/llm/releases/latest/download/"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${LLM_RELEASE_URL}/llm-canister-ollama.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
WASM_URL="${LLM_RELEASE_URL}/llm-canister-ollama.wasm"

CANDID_FILE="$(jq -r .canisters.llm.candid dfx.json)"
WASM_FILE_GZ="$(jq -r .canisters.llm.wasm dfx.json)"
WASM_FILE="${WASM_FILE_GZ%.gz}"
ARG_FILE="$(jq -r .canisters.llm.init_arg_file dfx.json)"

download() {
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

# Download candid and wasm
download candid
download wasm

# Compress Wasm
echo "Compressing Wasm: $WASM_FILE_GZ"
gzip -c "$WASM_FILE" >"$WASM_FILE_GZ"

# Generate init args
echo "Generating init args..."
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"

# Set default principals (can be overridden via env if needed)
INFO_CID="aaaaa-aa"
TRUSTED_CANISTER_MANAGER_CID="aaaaa-aa"
GOVERNANCE_CID="aaaaa-aa"
PASSCODE_MANAGER_CID="aaaaa-aa"
BACKUP_CID="aaaaa-aa"
FEE_RECEIVER_CID="aaaaa-aa"

cat <<EOF >"$ARG_FILE"
(
  principal "$INFO_CID",
  principal "$TRUSTED_CANISTER_MANAGER_CID",
  principal "$GOVERNANCE_CID",
  principal "$PASSCODE_MANAGER_CID",
  principal "$BACKUP_CID",
  opt principal "$FEE_RECEIVER_CID"
)
EOF

cat <<EOF
SUCCESS: The llm installation files have been created:
llm candid:       $CANDID_FILE
llm Wasm:         $WASM_FILE_GZ
llm install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.metadata.mjs
================================================
#!/usr/bin/env node

import { config } from 'dotenv';
import { readFileSync, writeFileSync } from 'node:fs';
import { join, resolve } from 'node:path';
import { ENV, OISY_IC_DOMAIN, findHtmlFiles, replaceEnv } from './build.utils.mjs';

config({ path: `.env.${ENV}` });

const METADATA_PATH = join(process.cwd(), 'src', 'frontend', 'src', 'env', 'oisy.metadata.json');

const getMetadata = () => JSON.parse(readFileSync(resolve(METADATA_PATH), 'utf-8'));

const parseMetadata = (targetFile) => {
	let content = readFileSync(targetFile, 'utf8');

	const METADATA = {
		...getMetadata(),
		OISY_IC_DOMAIN
	};

	Object.entries(METADATA).forEach(
		([key, value]) => (content = replaceEnv({ content, pattern: `{{${key}}}`, value }))
	);

	// Special use case. We need to build the dapp with a real URL within app.html other build fails.
	content = replaceEnv({
		content,
		pattern: `https://oisy.com`,
		value: OISY_IC_DOMAIN
	});

	writeFileSync(targetFile, content);
};

const parseUrl = (filePath) => {
	let content = readFileSync(filePath, 'utf8');

	content = replaceEnv({
		content,
		pattern: `https://oisy.com`,
		value: OISY_IC_DOMAIN
	});

	writeFileSync(filePath, content);
};

const updateRobotsTxt = () => {
	if (ENV !== 'production') {
		return;
	}

	const content = `User-agent: *
Allow: /
Sitemap: ${OISY_IC_DOMAIN}/sitemap.xml
Host: ${OISY_IC_DOMAIN}`;

	writeFileSync(join(process.cwd(), 'build', 'robots.txt'), content);
};

const removeMetaRobots = (targetFile) => {
	if (ENV !== 'production') {
		return;
	}

	const content = readFileSync(targetFile, 'utf8');

	const update = content.replace(/<meta\s+name="robots"\s+content="noindex"\s*\/>/, '');

	writeFileSync(targetFile, update);
};

const htmlFiles = findHtmlFiles();
htmlFiles.forEach((htmlFile) => parseMetadata(htmlFile));

parseUrl(join(process.cwd(), 'build', 'sitemap.xml'));
parseMetadata(join(process.cwd(), 'build', 'manifest.webmanifest'));

// SEO
htmlFiles.forEach((htmlFile) => removeMetaRobots(htmlFile));
updateRobotsTxt();



================================================
FILE: scripts/build.report.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

# Which Wasm?
CANISTER="$1"

# Hash the files:
sha256sum "out/${CANISTER}".* >out/filelist.txt
# Get the metadata keys:
ic-wasm <(gunzip <"./out/${CANISTER}.wasm.gz") metadata >out/metadata_keys.txt
# Write a report
{
  printf "\n%s\n" "$CANISTER:"
  sha256sum "out/${CANISTER}".*
  printf "\n%s\n" "$CANISTER metadata keys:"
  cat out/metadata_keys.txt
  printf "\n%s\n\n" "To see metadata, use ic-wasm.  For example, to see the git tags:" " ic-wasm <(gunzip < ./out/$CANISTER.wasm.gz) metadata git:tags"
} | tee -a out/report.txt



================================================
FILE: scripts/build.seo.mjs
================================================
import { readFileSync, writeFileSync } from 'node:fs';
import { dirname, join, relative } from 'node:path';
import { OISY_IC_DOMAIN, findHtmlFiles } from './build.utils.mjs';

const OUTPUT_DIR = join(process.cwd(), 'build');
const SITE_ROOT_CANONICAL = OISY_IC_DOMAIN;

const updateCanonical = (htmlFilePath) => {
	// 1. We determine the route based on the output
	const routePath = dirname(relative(OUTPUT_DIR, htmlFilePath));

	// 2. Build the effective canonical route
	const canonicalPath = `${SITE_ROOT_CANONICAL}/${routePath}/`;

	// 2. Read content
	let html = readFileSync(htmlFilePath, 'utf-8');

	// 3. Update canonical
	html = html.replace(
		`<link href="${SITE_ROOT_CANONICAL}" rel="canonical" />`,
		`<link href="${canonicalPath}" rel="canonical" />`
	);

	// 4. Update og:url to reflect the canonical
	html = html.replace(
		`<meta content="${SITE_ROOT_CANONICAL}" property="og:url" />`,
		`<meta content="${canonicalPath}" property="og:url" />`
	);

	// 5. Save the content with the updated canonical URL
	writeFileSync(htmlFilePath, html);
};

// Do not replace canonical for root and 404 pages
const filterSubPages = (htmlFile) => dirname(htmlFile) !== OUTPUT_DIR;

const htmlFiles = findHtmlFiles().filter(filterSubPages);
htmlFiles.forEach(updateCanonical);



================================================
FILE: scripts/build.signer.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the Chain Fusion Signer installation files:

	- The Wasm and Candid files are downloaded.
	- The installation args are computed based on the target network,
	      determined by the DFX_NETWORK environment variable.

	The files are installed at at the locations defined for 'signer' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"

SIGNER_RELEASE="v0.2.8"
SIGNER_RELEASE_URL="https://github.com/dfinity/chain-fusion-signer/releases/download/${SIGNER_RELEASE}"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${SIGNER_RELEASE_URL}/signer.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
WASM_URL="${SIGNER_RELEASE_URL}/signer.wasm.gz"

CANDID_FILE="$(jq -r .canisters.signer.candid dfx.json)"
WASM_FILE="$(jq -r .canisters.signer.wasm dfx.json)"
ARG_FILE="$(jq -r .canisters.signer.init_arg_file dfx.json)"

download() {
  : 'Downloads a URL to a given file.'
  # shellcheck disable=SC2016 # The $ in the comment is not meant to be expanded.
  : '* With argument x, the filename is $X_FILE and the URL is $X_URL'
  : '* If the file already exists, the user is prompted whether to overwrite, keeping the existing file by default.'
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

####
# Downloads the candid file, if it does not exist already.
download candid

####
# Downloads the Wasm file, if it does not exist already.
download wasm

####
# Computes the install args, overwriting any existing args file.

# .. Computes fields for the init args.
case "$DFX_NETWORK" in
"staging")
  ECDSA_KEY_NAME="test_key_1"
  # For security reasons, mainnet root key will be hardcoded in the signer canister.
  ic_root_key_der="null"
  ;;
"ic")
  ECDSA_KEY_NAME="key_1"
  # For security reasons, mainnet root key will be hardcoded in the signer canister.
  ic_root_key_der="null"
  ;;
*)
  ECDSA_KEY_NAME="dfx_test_key"
  # In order to read the root key we grab the array from the '"root_key": [...]' bit, the brackets
  # to match what candid expects ({}), replace the commas between array entries to match
  # what candid expects (semicolon) and annotate the numbers with their type (otherwise dfx assumes 'nat'
  # instead of 'nat8').
  rootkey_did=$(dfx ping "${ENV:-local}" |
    jq -r '.root_key | reduce .[] as $item ("{ "; "\(.) \($item):nat8;") + " }"')
  echo "Parsed rootkey: ${rootkey_did:0:20}..." >&2
  ic_root_key_der="opt vec $rootkey_did"
  ;;
esac

# .. Creates the init args file
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"
cat <<EOF >"$ARG_FILE"
(variant {
    Init = record {
         ecdsa_key_name = "$ECDSA_KEY_NAME";
         ic_root_key_der = $ic_root_key_der;
     }
  })
EOF

####
# Success
cat <<EOF
SUCCESS: The signer installation files have been created:
signer candid:       $CANDID_FILE
signer Wasm:         $WASM_FILE
signer install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.sol_rpc.args.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the Solana RPC installation arguments.

	The file is installed at the location defined for 'sol_rpc' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"
ARG_FILE="$(jq -r .canisters.sol_rpc.init_arg_file dfx.json)"

####
# Computes the install args, overwriting any existing args file.

CANISTER_ID_SOL_RPC="${CANISTER_ID_SOL_RPC:-$(dfx canister id sol_rpc --network "$DFX_NETWORK")}"

# .. Creates the init args file
rm -f "$ARG_FILE"
mkdir -p "$(dirname "$ARG_FILE")"
cat <<EOF >"$ARG_FILE"
(record {})
EOF

####
# Success
cat <<EOF
SUCCESS: The sol_rpc argument file has been created:
sol_rpc install args: $(sha256sum "$ARG_FILE")
EOF



================================================
FILE: scripts/build.sol_rpc.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the Solana RPC installation files:

	- The Wasm and Candid files are downloaded.
	- The installation args are computed based on the target network,
	      determined by the DFX_NETWORK environment variable.

	The files are installed at at the locations defined for 'sol_rpc' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

DFX_NETWORK="${DFX_NETWORK:-local}"

SOL_RPC_RELEASE="v1.0.0"
SOL_RPC_RELEASE_URL="https://github.com/dfinity/sol-rpc-canister/releases/download/${SOL_RPC_RELEASE}"
CANDID_URL="${SOL_RPC_RELEASE_URL}/sol_rpc_canister.did"
WASM_URL="${SOL_RPC_RELEASE_URL}/sol_rpc_canister.wasm.gz"

CANDID_FILE="$(jq -r .canisters.sol_rpc.candid dfx.json)"
WASM_FILE="$(jq -r .canisters.sol_rpc.wasm dfx.json)"
ARG_FILE="$(jq -r .canisters.sol_rpc.init_arg_file dfx.json)"

####
# Downloads the candid file
scripts/download-immutable.sh "$CANDID_URL" "$CANDID_FILE"

####
# Downloads the Wasm file
scripts/download-immutable.sh "$WASM_URL" "$WASM_FILE"

####
# Computes the install args, overwriting any existing args file.
scripts/build.sol_rpc.args.sh

# Success
cat <<EOF
SUCCESS: The sol_rpc installation files have been created:
sol_rpc candid:       $CANDID_FILE
sol_rpc Wasm:         $WASM_FILE
sol_rpc install args: $ARG_FILE
EOF



================================================
FILE: scripts/build.style.mjs
================================================
#!/usr/bin/env node

import { config } from 'dotenv';
import { readFileSync, writeFileSync } from 'node:fs';
import { dirname, join } from 'node:path';
import { ENV, findHtmlFiles } from './build.utils.mjs';
import { findFiles } from './utils.mjs';

config({ path: `.env.${ENV}` });

const PLACEHOLDER = '<!-- ROUTE_STYLE -->';

const src = join(process.cwd(), 'src', 'frontend', 'src', 'routes');
const build = join(process.cwd(), 'build');

const parseStyle = (srcFile) => {
	const parsedSrcFile = srcFile.replace(/\/\([^)]+\)\//, '/'); // Remove e.g. /(sign)/ from path
	const srcDir = dirname(parsedSrcFile);

	const destDir = srcDir.replace(src, build);
	const destFile = join(destDir, 'index.html');

	const style = readFileSync(srcFile, 'utf8');

	// Just in case there is an empty CSS source file. Placeholder is cleaned with another hook.
	if (style.trim().length === 0) {
		return;
	}

	const content = readFileSync(destFile, 'utf8');
	const updatedContent = content.replace(PLACEHOLDER, `<style>\n${style}\n</style>`);

	writeFileSync(destFile, updatedContent);
};

const cleanPlaceholder = (targetFile) => {
	const content = readFileSync(targetFile, 'utf8');
	const updatedContent = content.replace(PLACEHOLDER, '');

	writeFileSync(targetFile, updatedContent);
};

const styleFiles = findFiles({ dir: src, extensions: ['.page.css'] });
styleFiles.forEach(parseStyle);

const htmlFiles = findHtmlFiles();
htmlFiles.forEach(cleanPlaceholder);



================================================
FILE: scripts/build.tokens.ckerc20.ts
================================================
#!/usr/bin/env node

import type {
	EnvCkErc20TokenData,
	EnvCkErc20TokensRaw,
	EnvCkErc20TokensWithMetadata,
	EnvTokensCkErc20
} from '$env/types/env-token-ckerc20';
import type { EnvTokenSymbol } from '$env/types/env-token-common';
import type { LedgerCanisterIdText } from '$icp/types/canister';
import {
	CkETHOrchestratorCanister,
	type ManagedCanisters,
	type OrchestratorInfo
} from '@dfinity/cketh';
import { Principal } from '@dfinity/principal';
import { fromNullable, isNullish, jsonReplacer, nonNullish } from '@dfinity/utils';
import { existsSync, writeFileSync } from 'node:fs';
import { join } from 'node:path';
import { agent, loadMetadata, saveLogo } from './build.tokens.utils';
import { CK_ERC20_JSON_FILE } from './constants.mjs';

interface TokensAndIcons {
	tokens: EnvCkErc20TokensWithMetadata;
	icons: {
		ledgerCanisterId: LedgerCanisterIdText;
		name: EnvTokenSymbol;
		icon: string;
	}[];
}

// Tokens for which the ERC20 and ckERC20 logos are different—i.e., tokens that are presented with their original ERC20 logos but have a custom logo for ckERC20.
const SKIP_CANISTER_IDS_LOGOS: LedgerCanisterIdText[] = [
	// ckUSDC
	'xevnm-gaaaa-aaaar-qafnq-cai',
	// ckUSDT
	'cngnf-vqaaa-aaaar-qag4q-cai',
	// ckSepoliaUSDC
	'yfumr-cyaaa-aaaar-qaela-cai',
	// ckEURC
	'pe5t5-diaaa-aaaar-qahwa-cai',
	// ckXAUT
	'nza5v-qaaaa-aaaar-qahzq-cai'
];

const orchestratorInfo = async ({
	orchestratorId: canisterId
}: {
	orchestratorId: Principal;
}): Promise<OrchestratorInfo> => {
	const { getOrchestratorInfo } = CkETHOrchestratorCanister.create({
		agent,
		canisterId
	});

	return await getOrchestratorInfo({ certified: true });
};

const buildOrchestratorInfo = async (orchestratorId: Principal): Promise<TokensAndIcons> => {
	const { managed_canisters } = await orchestratorInfo({ orchestratorId });

	// eslint-disable-next-line local-rules/prefer-object-params -- This is a destructuring assignment
	const mapManagedCanisters = (
		acc: EnvCkErc20TokensRaw,
		{
			ledger,
			index,
			ckerc20_token_symbol,
			erc20_contract: { address: erc20ContractAddress }
		}: ManagedCanisters
	): EnvCkErc20TokensRaw => {
		const ledgerCanister = fromNullable(ledger);
		const indexCanister = fromNullable(index);

		// Skip tokens without Ledger or Index (by definition, this can happen).
		if (isNullish(ledgerCanister) || isNullish(indexCanister)) {
			return acc;
		}

		const { canister_id: ledgerCanisterId } =
			'Created' in ledgerCanister ? ledgerCanister.Created : ledgerCanister.Installed;
		const { canister_id: indexCanisterId } =
			'Created' in indexCanister ? indexCanister.Created : indexCanister.Installed;

		return {
			...acc,
			[ckerc20_token_symbol]: [
				...(acc[ckerc20_token_symbol] ?? []),
				{
					ledgerCanisterId: ledgerCanisterId.toText(),
					indexCanisterId: indexCanisterId.toText(),
					erc20ContractAddress
				}
			]
		};
	};

	const tokens: EnvCkErc20TokensRaw = managed_canisters.reduce<EnvCkErc20TokensRaw>(
		mapManagedCanisters,
		{}
	);

	const assertUniqueTokenSymbol: EnvCkErc20TokenData[] | undefined = Object.values(tokens).find(
		(value) => value.length > 1
	);

	if (assertUniqueTokenSymbol !== undefined) {
		throw new Error(
			`More than one pair of ledger and index canisters were used for the token symbol ${assertUniqueTokenSymbol}.`
		);
	}

	return await Object.entries(tokens).reduce<Promise<TokensAndIcons>>(
		async (acc, [key, value]) => {
			const { tokens: accTokens, icons: accIcons } = await acc;

			const [token] = value;

			const { ledgerCanisterId, ...rest } = token;

			const metadataWithIcon = await loadMetadata(ledgerCanisterId);

			if (isNullish(metadataWithIcon)) {
				return { tokens: accTokens, icons: accIcons };
			}

			const { icon, ...metadata } = metadataWithIcon;

			return {
				tokens: {
					...accTokens,
					[key]: { ledgerCanisterId, ...rest, ...metadata }
				},
				icons: [
					...accIcons,
					...(nonNullish(icon)
						? [
								{
									ledgerCanisterId,
									name: key,
									icon
								}
							]
						: [])
				]
			};
		},
		Promise.resolve({ tokens: {}, icons: [] })
	);
};

const ORCHESTRATOR_STAGING_ID: Principal = Principal.fromText('2s5qh-7aaaa-aaaar-qadya-cai');
const ORCHESTRATOR_PRODUCTION_ID: Principal = Principal.fromText('vxkom-oyaaa-aaaar-qafda-cai');

const LOGO_FOLDER = join(process.cwd(), 'src', 'frontend', 'src', 'icp-eth', 'assets');

const saveTokenLogo = ({ name, logoData }: { name: EnvTokenSymbol; logoData: string }) => {
	const logoName = name.toLowerCase().replace('ck', '').replace('sepolia', '');
	const file = join(LOGO_FOLDER, `${logoName}.svg`);

	if (existsSync(file)) {
		return;
	}

	saveLogo({ logoData, file, name });
};

const findCkErc20 = async () => {
	const [
		{ tokens: staging, icons: stagingIcons },
		{ tokens: production, icons: productionIcons }
	]: TokensAndIcons[] = await Promise.all(
		[ORCHESTRATOR_STAGING_ID, ORCHESTRATOR_PRODUCTION_ID].map(buildOrchestratorInfo)
	);

	const tokens: EnvTokensCkErc20 = {
		production,
		staging
	};

	writeFileSync(CK_ERC20_JSON_FILE, JSON.stringify(tokens, jsonReplacer, 8));

	await Promise.allSettled(
		[...productionIcons, ...stagingIcons]
			.filter(({ ledgerCanisterId }) => !SKIP_CANISTER_IDS_LOGOS.includes(ledgerCanisterId))
			.map(({ name, icon }) => saveTokenLogo({ name, logoData: icon }))
	);
};

try {
	await findCkErc20();
} catch (err) {
	console.error(err);
}



================================================
FILE: scripts/build.tokens.icrc.ts
================================================
#!/usr/bin/env node

import { EnvAdditionalIcrcTokensSchema } from '$env/schema/env-additional-icrc-token.schema';
import type { EnvAdditionalIcrcTokensWithMetadata } from '$env/types/env-icrc-additional-token';
import type { EnvTokenSymbol } from '$env/types/env-token-common';
import type { LedgerCanisterIdText } from '$icp/types/canister';
import { isNullish, jsonReplacer, jsonReviver, nonNullish } from '@dfinity/utils';
import { existsSync, readFileSync, writeFileSync } from 'node:fs';
import { join } from 'node:path';
import { loadMetadata, saveLogo } from './build.tokens.utils';
import { ADDITIONAL_ICRC_JSON_FILE } from './constants.mjs';

interface TokensAndIcons {
	tokens: EnvAdditionalIcrcTokensWithMetadata;
	icons: {
		ledgerCanisterId: LedgerCanisterIdText;
		name: EnvTokenSymbol;
		icon: string;
	}[];
}

const buildIcrcTokens = async (): Promise<TokensAndIcons> => {
	const icrcTokensJson = JSON.parse(
		readFileSync(ADDITIONAL_ICRC_JSON_FILE).toString(),
		jsonReviver
	);

	const icrcTokensParsed = EnvAdditionalIcrcTokensSchema.safeParse(icrcTokensJson);

	if (!icrcTokensParsed.success) {
		throw new Error(`Error parsing tokens.icrc.json: ${icrcTokensParsed.error.message}`);
	}

	const { data: icrcTokens } = icrcTokensParsed;

	return await Object.entries(icrcTokens).reduce<Promise<TokensAndIcons>>(
		async (acc, [key, token]) => {
			if (isNullish(token)) {
				throw new Error(`Data is missing for token symbol ${key}.`);
			}

			const { ledgerCanisterId, ...rest } = token;

			if (isNullish(ledgerCanisterId)) {
				throw new Error(`Ledger canister ID is missing for token symbol ${key}.`);
			}

			const { tokens: accTokens, icons: accIcons } = await acc;

			const metadataWithIcon = await loadMetadata(ledgerCanisterId);

			if (isNullish(metadataWithIcon)) {
				return {
					tokens: {
						...accTokens,
						[key]: token
					},
					icons: accIcons
				};
			}

			const { icon, ...metadata } = metadataWithIcon;

			return {
				tokens: {
					...accTokens,
					[key]: {
						ledgerCanisterId,
						...rest,
						...metadata
					}
				},
				icons: [
					...accIcons,
					...(nonNullish(icon)
						? [
								{
									ledgerCanisterId,
									name: key,
									icon
								}
							]
						: [])
				]
			};
		},
		Promise.resolve({ tokens: {}, icons: [] })
	);
};

const LOGO_FOLDER = join(process.cwd(), 'src', 'frontend', 'src', 'icp', 'assets');

const saveTokenLogo = ({ name, logoData }: { name: EnvTokenSymbol; logoData: string }) => {
	const logoName = name.toLowerCase();
	const file = join(LOGO_FOLDER, `${logoName}.svg`);

	if (existsSync(file)) {
		return;
	}

	saveLogo({ logoData, file, name });
};

const findAdditionalIcrc = async () => {
	const { tokens, icons }: TokensAndIcons = await buildIcrcTokens();

	writeFileSync(ADDITIONAL_ICRC_JSON_FILE, JSON.stringify(tokens, jsonReplacer, 8));

	await Promise.allSettled(icons.map(({ name, icon }) => saveTokenLogo({ name, logoData: icon })));
};

try {
	await findAdditionalIcrc();
} catch (err) {
	console.error(err);
}



================================================
FILE: scripts/build.tokens.sns.ts
================================================
#!/usr/bin/env node

import { DEPRECATED_SNES } from '$env/tokens/tokens.sns.deprecated.env';
import type { EnvIcrcTokenIcon, EnvIcrcTokenMetadataWithIcon } from '$env/types/env-icrc-token';
import type { EnvSnsTokenWithIcon } from '$env/types/env-sns-token';
import type { CanisterIdText } from '$lib/types/canister';
import type { PartialSpecific } from '$lib/types/utils';
import { IcrcMetadataResponseEntries } from '@dfinity/ledger-icrc';
import {
	candidNumberArrayToBigInt,
	fromNullable,
	isNullish,
	jsonReplacer,
	nonNullish
} from '@dfinity/utils';
import type { UrlSchema } from '@dfinity/zod-schemas';
import { existsSync, mkdirSync, writeFileSync } from 'node:fs';
import { join } from 'node:path';
import type { z } from 'zod';
import { SNS_JSON_FILE } from './constants.mjs';

const AGGREGATOR_PAGE_SIZE = 10;
const SNS_AGGREGATOR_CANISTER_URL = 'https://3r4gx-wqaaa-aaaaq-aaaia-cai.icp0.io';
const AGGREGATOR_CANISTER_VERSION = 'v1';

const AGGREGATOR_URL = `${SNS_AGGREGATOR_CANISTER_URL}/${AGGREGATOR_CANISTER_VERSION}/sns`;

const DATA_FOLDER = join(process.cwd(), 'src', 'frontend', 'src', 'env');
const STATIC_FOLDER = join(process.cwd(), 'src', 'frontend', 'static', 'icons', 'sns');

interface ResponseData {
	canister_ids: {
		ledger_canister_id: CanisterIdText;
		index_canister_id: CanisterIdText;
		root_canister_id: CanisterIdText;
	};
	icrc1_metadata: [[string, { Text: string } | { Nat: [number] }]];
	meta: { name: string; url: z.infer<typeof UrlSchema> };
	swap_state: {
		swap: { lifecycle: number };
	};
}

type SnsTokenWithOptionalMetadata = PartialSpecific<EnvSnsTokenWithIcon, 'metadata'>;

type Logo = Pick<EnvSnsTokenWithIcon, 'ledgerCanisterId' | 'rootCanisterId'> & EnvIcrcTokenIcon;

if (!existsSync(DATA_FOLDER)) {
	mkdirSync(DATA_FOLDER, { recursive: true });
}

if (!existsSync(STATIC_FOLDER)) {
	mkdirSync(STATIC_FOLDER, { recursive: true });
}

const aggregatorPageUrl = (page: number): string => `list/page/${page}/slow.json`;

const querySnsAggregator = async (page = 0): Promise<ResponseData[]> => {
	const response = await fetch(`${AGGREGATOR_URL}/${aggregatorPageUrl(page)}`);

	if (!response.ok) {
		// If the error is after the first page, is because there are no more pages it fails
		if (page > 0) {
			return [];
		}

		throw new Error('Error loading SNS projects from aggregator canister');
	}

	const data = await response.json();

	if (data.length === AGGREGATOR_PAGE_SIZE) {
		const nextPageData = await querySnsAggregator(page + 1);
		return [...data, ...nextPageData];
	}

	return data;
};

const saveLogos = async (logos: Logo[]) => {
	const writeLogo = async ({ icon, ledgerCanisterId, rootCanisterId }: Logo) => {
		// Use ledger icon and fallback on Sns icon if not existing
		const response = await fetch(
			nonNullish(icon) ? icon : `${AGGREGATOR_URL}/root/${rootCanisterId}/logo.png`
		);

		const blob = await response.blob();

		writeFileSync(
			join(STATIC_FOLDER, `${ledgerCanisterId}.png`),
			Buffer.from(await blob.arrayBuffer())
		);
	};

	const activeSnsLogos = logos.filter(({ ledgerCanisterId }) =>
		isNullish(DEPRECATED_SNES[ledgerCanisterId])
	);

	await Promise.all(activeSnsLogos.map(writeLogo));
};

const mapOptionalToken = (
	response: ResponseData['icrc1_metadata']
): EnvIcrcTokenMetadataWithIcon | undefined => {
	const nullishToken = response.reduce<Partial<EnvIcrcTokenMetadataWithIcon>>(
		(acc, [key, value]) => {
			switch (key) {
				case IcrcMetadataResponseEntries.SYMBOL:
					acc = { ...acc, ...('Text' in value && { symbol: value.Text }) };
					break;
				case IcrcMetadataResponseEntries.NAME:
					acc = { ...acc, ...('Text' in value && { name: value.Text }) };
					break;
				case IcrcMetadataResponseEntries.FEE:
					acc = {
						...acc,
						...('Nat' in value &&
							nonNullish(fromNullable(value.Nat)) && { fee: candidNumberArrayToBigInt(value.Nat) })
					};
					break;
				case IcrcMetadataResponseEntries.DECIMALS:
					acc = {
						...acc,
						...('Nat' in value && { decimals: Number(value.Nat) })
					};
					break;
				case IcrcMetadataResponseEntries.LOGO:
					acc = { ...acc, ...('Text' in value && { icon: value.Text }) };
			}

			return acc;
		},
		{}
	);

	const { symbol, name, fee, decimals, ...rest } = nullishToken;

	if (isNullish(symbol) || isNullish(name) || isNullish(fee) || isNullish(decimals)) {
		return undefined;
	}

	return {
		decimals,
		name,
		symbol,
		fee,
		...rest
	};
};

// 3 === Committed
const filterCommittedSns = ({
	swap_state: {
		swap: { lifecycle }
	}
}: ResponseData) => lifecycle === 3;

const mapSnsMetadata = ({
	canister_ids: { ledger_canister_id, index_canister_id, root_canister_id },
	icrc1_metadata,
	meta: { name: alternativeName, url }
}: ResponseData): SnsTokenWithOptionalMetadata => {
	const tokenMetadata = mapOptionalToken(icrc1_metadata);

	return {
		ledgerCanisterId: ledger_canister_id,
		indexCanisterId: index_canister_id,
		rootCanisterId: root_canister_id,
		...(nonNullish(tokenMetadata) && {
			metadata: {
				...tokenMetadata,
				alternativeName: alternativeName.trim(),
				url
			}
		})
	};
};

const filterNonNullishMetadata = (
	token: SnsTokenWithOptionalMetadata
): token is EnvSnsTokenWithIcon => nonNullish(token.metadata);

const mapDeprecatedSnsMetadata = ({
	metadata,
	ledgerCanisterId,
	...rest
}: EnvSnsTokenWithIcon): EnvSnsTokenWithIcon => ({
	metadata: {
		...metadata,
		...(nonNullish(DEPRECATED_SNES[ledgerCanisterId]) && DEPRECATED_SNES[ledgerCanisterId])
	},
	ledgerCanisterId,
	...(nonNullish(DEPRECATED_SNES[ledgerCanisterId]) && { deprecated: true }),
	...rest
});

const findSnses = async () => {
	const data = await querySnsAggregator();

	const snses = data.filter(filterCommittedSns);

	const { tokens, icons } = snses
		.map(mapSnsMetadata)
		.filter(filterNonNullishMetadata)
		.map(mapDeprecatedSnsMetadata)
		.reduce<{ tokens: EnvSnsTokenWithIcon[]; icons: Logo[] }>(
			(
				{ tokens, icons },
				{ metadata: { icon, ...metadata }, ledgerCanisterId, rootCanisterId, ...rest }
			) => ({
				tokens: [
					...tokens,
					{
						ledgerCanisterId,
						rootCanisterId,
						...rest,
						metadata
					}
				],
				icons: [
					...icons,
					{
						ledgerCanisterId,
						rootCanisterId,
						icon
					}
				]
			}),
			{ tokens: [], icons: [] }
		);

	writeFileSync(SNS_JSON_FILE, JSON.stringify(tokens, jsonReplacer, 8));

	await saveLogos(icons);
};

try {
	await findSnses();
} catch (err) {
	console.error(err);
	process.exit(1);
}



================================================
FILE: scripts/build.tokens.utils.ts
================================================
import type { EnvIcrcTokenMetadataWithIcon } from '$env/types/env-icrc-token';
import type { LedgerCanisterIdText } from '$icp/types/canister';
import { AnonymousIdentity, type HttpAgent } from '@dfinity/agent';
import { IcrcLedgerCanister, mapTokenMetadata } from '@dfinity/ledger-icrc';
import type { IcrcTokenMetadataResponse } from '@dfinity/ledger-icrc/dist/types/types/ledger.responses';
import { Principal } from '@dfinity/principal';
import { createAgent } from '@dfinity/utils';
import { closeSync, openSync, writeSync } from 'node:fs';

export const agent: HttpAgent = await createAgent({
	identity: new AnonymousIdentity(),
	host: 'https://icp-api.io'
});

const getMetadata = async (ledgerCanisterId: Principal): Promise<IcrcTokenMetadataResponse> => {
	const { metadata } = IcrcLedgerCanister.create({
		agent,
		canisterId: ledgerCanisterId
	});

	return await metadata({ certified: true });
};

export const loadMetadata = async (
	ledgerCanisterId: LedgerCanisterIdText
): Promise<EnvIcrcTokenMetadataWithIcon | undefined> => {
	const metadata = await getMetadata(Principal.from(ledgerCanisterId));

	return mapTokenMetadata(metadata);
};

export const saveLogo = ({
	logoData,
	file,
	name
}: {
	logoData: string;
	file: string;
	name: string;
}) => {
	if (!logoData.includes(';') || !logoData.includes(',')) {
		console.error(`Invalid logoData format for ${name}: ${logoData}`);
		return;
	}

	if (!logoData.startsWith('data:image/svg+xml;base64,')) {
		const [logoDataPart1, logoDataPart2] = logoData.split(';');
		console.warn(
			`Invalid SVG logo format for ${name}:`,
			`${logoDataPart1};${logoDataPart2.split(',')[0]},...`
		);
		return;
	}

	const [encoding, encodedStr] = logoData.split(';')[1].split(',');

	const svgContent = Buffer.from(encodedStr, encoding as BufferEncoding).toString('utf-8');

	try {
		const fd = openSync(file, 'wx');

		writeSync(fd, svgContent, 0, 'utf-8');
		closeSync(fd);
	} catch (err: unknown) {
		if (typeof err === 'object' && err !== null && 'code' in err && err.code === 'EEXIST') {
			// File already exists, do nothing
			return;
		}

		throw err;
	}
};



================================================
FILE: scripts/build.utils.mjs
================================================
import { join } from 'node:path';
import OISY_DOMAINS from './domains.json' with { type: 'json' };
import { findFiles } from './utils.mjs';

export const findHtmlFiles = (dir = join(process.cwd(), 'build')) =>
	findFiles({ dir, extensions: ['.html'] });

const REQUESTED_ENV = process.env.ENV ?? process.env.DFX_NETWORK ?? '';

export const ENV =
	REQUESTED_ENV === 'ic'
		? 'production'
		: (REQUESTED_ENV ?? '').startsWith('test_fe_')
			? 'staging'
			: REQUESTED_ENV === 'audit'
				? 'staging'
				: REQUESTED_ENV === 'e2e'
					? 'staging'
					: ['staging', 'beta'].includes(REQUESTED_ENV)
						? REQUESTED_ENV
						: 'development';

const domain_for_dfx_network = (dfx_network) =>
	OISY_DOMAINS.frontend[dfx_network] ?? `https://${dfx_network}.oisy.com`;

// The domain name, as in the browser location bar and in the web assets under .well-known/ic-domain
export const OISY_IC_DOMAIN = domain_for_dfx_network(process.env.DFX_NETWORK);

export const replaceEnv = ({ content, pattern, value }) => {
	const regex = new RegExp(pattern, 'g');
	return content.replace(regex, value);
};



================================================
FILE: scripts/build.xtc_ledger.sh
================================================
#!/usr/bin/env bash
set -euo pipefail

print_help() {
  cat <<-EOF
	Creates the XTC Token installation files:

	- The Wasm and Candid files are downloaded.

	The files are installed at at the locations defined for 'xtc_ledger' in 'dfx.json'.
	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

XTC_BUILDENV="$DFX_NETWORK"
export XTC_BUILDENV

XTC_REPO_URL="https://raw.githubusercontent.com/Psychedelic/dank/refs/heads/develop/candid"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
CANDID_URL="${XTC_REPO_URL}/xtc.did"
# shellcheck disable=SC2034 # This variable is used - see ${!asset_url} below.
# Fake wasm since we really don't need to deploy it
WASM_URL="https://github.com/dfinity/cycles-ledger/releases/download/cycles-ledger-v1.0.1/cycles-ledger.wasm.gz"

CANDID_FILE="$(jq -r .canisters.xtc_ledger.candid dfx.json)"
WASM_FILE="$(jq -r .canisters.xtc_ledger.wasm dfx.json)"

download() {
  : 'Downloads a URL to a given file.'
  # shellcheck disable=SC2016 # The $ in the comment is not meant to be expanded.
  : '* With argument x, the filename is $X_FILE and the URL is $X_URL'
  : '* If the file already exists, the user is prompted whether to overwrite, keeping the existing file by default.'
  local asset asset_url asset_file
  asset="$1"
  asset_url="${asset^^}_URL"
  asset_file="${asset^^}_FILE"
  scripts/download-immutable.sh "${!asset_url}" "${!asset_file}"
}

####
# Downloads the candid file, if it does not exist already.
download candid

####
# Downloads the Wasm file, if it does not exist already.
download wasm

####
# Success
cat <<EOF
SUCCESS: The xtc_ledger installation files have been created:
xtc_ledger candid:       $CANDID_FILE
xtc_ledger Wasm:         $WASM_FILE
EOF



================================================
FILE: scripts/check.i18n.mjs
================================================
#!/usr/bin/env node

import { readFileSync } from 'node:fs';
import { join } from 'node:path';
import { findFiles } from './utils.mjs';

const PATH_FROM_ROOT = join(process.cwd(), 'src', 'frontend', 'src');
const PATH_TO_EN_JSON = join(PATH_FROM_ROOT, 'lib', 'i18n', 'en.json');
const PATH_TO_CODEBASE = join(PATH_FROM_ROOT);

const extractKeys = ({ obj, prefix = '' }) =>
	Object.keys(obj).reduce((res, el) => {
		if (typeof obj[el] === 'object') {
			return [...res, ...extractKeys({ obj: obj[el], prefix: `${prefix}${el}.` })];
		}
		return [...res, `${prefix}${el}`];
	}, []);

// It checks if the key is used in the content or if the key is used dynamically
const checkKeyUsage = ({ key, content }) => {
	if (content.includes(`"${key}"`) || content.includes(`'${key}'`) || content.includes(key)) {
		return true;
	}

	const parts = key.split('.');
	const lastKey = parts[parts.length - 1];

	const destructureRegex = new RegExp(`[{,]\\s*${lastKey}\\s*[:}]`);
	if (destructureRegex.test(content)) {
		return true;
	}

	const dynamicPattern = `${parts.slice(0, -1).join('.')}[`;
	if (content.includes(dynamicPattern)) {
		return true;
	}

	return content.includes('get(i18n)') && parts.every((p) => content.includes(p));
};

const main = () => {
	const en = JSON.parse(readFileSync(PATH_TO_EN_JSON, 'utf8'));

	let potentialUnusedKeys = extractKeys({ obj: en });

	const files = findFiles({ dir: PATH_TO_CODEBASE, extensions: ['.svelte', '.ts'] });

	files.forEach((file) => {
		const content = readFileSync(file, 'utf8');
		potentialUnusedKeys = potentialUnusedKeys.filter((key) => !checkKeyUsage({ key, content }));

		if (potentialUnusedKeys.length === 0) {
			console.log('All keys are used.');
			process.exit(0);
		}
	});

	if (potentialUnusedKeys.length === 0) {
		console.log('✅ All keys are used.');
		process.exit(0);
	} else {
		console.error(`❌ ${potentialUnusedKeys.length} unused keys:`);
		potentialUnusedKeys.forEach((key) => console.error(' -', key));
		process.exit(1);
	}
};

main();



================================================
FILE: scripts/check.i18n.sh
================================================
#!/bin/sh

node ./scripts/check.i18n.mjs



================================================
FILE: scripts/check.tokens.erc20.ts
================================================
import {
	ERC20_CONTRACTS_PRODUCTION,
	ERC20_CONTRACTS_SEPOLIA,
	ERC20_TWIN_TOKENS_MAINNET,
	ERC20_TWIN_TOKENS_SEPOLIA
} from '$env/tokens/tokens.erc20.env';
import type { Erc20Contract } from '$eth/types/erc20';

const getAddresses = (contracts: Erc20Contract[]): string[] =>
	contracts.map((contract) => contract.address.toLowerCase());

const productionAddresses = getAddresses(ERC20_CONTRACTS_PRODUCTION);
const twinTokensMainnetAddresses = getAddresses(ERC20_TWIN_TOKENS_MAINNET);

const sepoliaAddresses = getAddresses(ERC20_CONTRACTS_SEPOLIA);
const twinTokensSepoliaAddresses = getAddresses(ERC20_TWIN_TOKENS_SEPOLIA);

const filterDuplicates = ({
	addresses1,
	addresses2
}: {
	addresses1: string[];
	addresses2: string[];
}): string[] => addresses1.filter((address) => addresses2.includes(address));

const mainnetDuplicates = filterDuplicates({
	addresses1: productionAddresses,
	addresses2: twinTokensMainnetAddresses
});
const sepoliaDuplicates = filterDuplicates({
	addresses1: sepoliaAddresses,
	addresses2: twinTokensSepoliaAddresses
});

if (mainnetDuplicates.length > 0 || sepoliaDuplicates.length > 0) {
	if (mainnetDuplicates.length > 0) {
		console.error(
			'Error: Duplicate addresses found between ERC20_CONTRACTS_PRODUCTION and ERC20_TWIN_TOKENS_MAINNET:',
			mainnetDuplicates
		);
	}

	if (sepoliaDuplicates.length > 0) {
		console.error(
			'Error: Duplicate ERC20 token addresses found between ERC20_CONTRACTS_SEPOLIA and ERC20_TWIN_TOKENS_SEPOLIA:',
			sepoliaDuplicates
		);
	}

	process.exit(1);
} else {
	console.log('No ERC20 token duplicates found. All addresses are unique.');
}



================================================
FILE: scripts/check.unused.svelte.mjs
================================================
#!/usr/bin/env node

import { readFileSync, unlinkSync } from 'node:fs';
import { basename, dirname, resolve } from 'node:path';
import { findFiles } from './utils.mjs';

const RED = '\x1b[31m';
const GREEN = '\x1b[32m';
const NC = '\x1b[0m'; // No Colour

const DATA_DIR = 'src/frontend/src';
const DATA_DIR_PATH = resolve(process.cwd(), DATA_DIR);

const REMOVE_FILES = process.argv.includes('--remove-files');

// TODO: Check if the svelte files in the tests are actually used, and used ONLY in the tests
const findSvelteFiles = (dir) => findFiles({ dir, extensions: ['.svelte'], ignoreDirs: ['tests'] });

const findSearchFiles = (dir) => findFiles({ dir, extensions: ['.svelte', '.ts'] });

const noUnusedFiles = () => {
	console.log(`${GREEN}No unused components found.${NC}`);
	process.exit(0);
};

const main = async () => {
	console.log(`${NC}Scanning ${DATA_DIR} folder to find all .svelte files\n`);

	const allSvelteFiles = findSvelteFiles(DATA_DIR_PATH);
	const allSearchFiles = findSearchFiles(DATA_DIR_PATH).filter(
		(file) => !file.includes('.spec.ts')
	);

	let potentialUnusedFiles = allSvelteFiles.filter((file) => !dirname(file).includes('routes'));

	allSearchFiles.forEach((file) => {
		const content = readFileSync(file, 'utf-8');

		potentialUnusedFiles = potentialUnusedFiles.filter((potentialUnusedFile) => {
			const fileBasename = basename(potentialUnusedFile);

			if (content.includes(`./${fileBasename}`)) {
				console.log(`${RED}Relative import of '${fileBasename}' found in ${file}${NC}`);
				return false;
			}

			return !content.includes(`${basename(dirname(potentialUnusedFile))}/${fileBasename}`);
		});

		if (potentialUnusedFiles.length === 0) {
			noUnusedFiles();
		}
	});

	if (potentialUnusedFiles.length === 0) {
		noUnusedFiles();
	} else {
		console.log(`${RED}Found ${potentialUnusedFiles.length} unused component(s).${NC}`);
		potentialUnusedFiles.forEach((file) => {
			console.log(`${RED}Unused Svelte file: ${file}${NC}`);
			if (REMOVE_FILES) {
				unlinkSync(file);
				console.log(`${GREEN}Removed: ${file}${NC}`);
			}
		});

		if (REMOVE_FILES) {
			console.log(
				'Run the script again to check for more unused files after removing the ones above.'
			);
			await main();
		}

		console.log();

		process.exit(1);
	}
};

main().catch((err) => {
	console.error(err);
	process.exit(1);
});



================================================
FILE: scripts/check.unused.svelte.sh
================================================
#!/bin/sh

if [ "$1" = "--remove-files" ]; then
  node ./scripts/check.unused.svelte.mjs --remove-files
else
  node ./scripts/check.unused.svelte.mjs
fi



================================================
FILE: scripts/clap.bash
================================================
# clap - a BASH argument parser
# This parser aims to have similar parsing semantics as Rust's clap parser; if it doesn't look anything like clap it's not just you.

clap_usage=""
clap_flag_match=""
clap_defaults=""
clap_arguments_string=""

# -----------------------------------------------------------------------------------------------------------------------------
function clap.throw_error() {
	local message="$1"
	echo "CLAP: ERROR: $message"
	exit 1
}

# -----------------------------------------------------------------------------------------------------------------------------
function clap.define() {
	if [ $# -lt 3 ]; then
		clap.throw_error "clap.define <short> <long> <variable> [<desc>] [<default>] [<value>] [<nargs>]"
	fi
	local nargs=""
	for option_id in $(seq 1 $#); do
		local option
		option="$(eval "echo \$$option_id")"
		local key
		key="$(echo "$option" | awk -F "=" '{print $1}')"
		local value
		value="$(echo "$option" | awk -F "=" '{print $2}')"

		#essentials: shortname, longname, description
		if [ "$key" = "short" ]; then
			local shortname="$value"
			if [ ${#shortname} -ne 1 ]; then
				clap.throw_error "short name expected to be one character long"
			fi
			local short="-${shortname}"
		elif [ "$key" = "long" ]; then
			local longname="$value"
			if [ ${#longname} -lt 2 ]; then
				clap.throw_error "long name expected to be at least one character long"
			fi
			local long="--${longname}"
		elif [ "$key" = "desc" ]; then
			local desc="$value"
		elif [ "$key" = "default" ]; then
			local default="$value"
		elif [ "$key" = "variable" ]; then
			local variable="$value"
		elif [ "$key" = "value" ]; then
			local val="$value"
		elif [ "$key" = "nargs" ]; then
			local nargs="$value"
		fi
	done

	if [ "$variable" = "" ]; then
		clap.throw_error "You must give a variable for option: (${short:-}/${long:-})"
	fi

	if [ "${val:-}" = "" ]; then
		val="\$OPTARG"
	fi

	# build OPTIONS and help
	clap_usage="${clap_usage}#NL#TB${short:-} $(printf "%-25s %s" "${long}:" "${desc}")"
	if [ "${default:-}" != "" ] && [ "${nargs:-}" != "0" ]; then
		clap_usage="${clap_usage} [default:$default]"
	fi
	clap_flags="${clap_flags:-} ${long}"
	if [ "${nargs:-}" == "" ]; then
		clap_flag_match="${clap_flag_match}#NL#TB#TB${long}${short:+|${short}})#NL#TB#TB#TB${variable}=\"\$1\"; shift 1;;"
	elif [ "${nargs:-}" == "0" ]; then
		clap_flag_match="${clap_flag_match}#NL#TB#TB${long}${short:+|${short}})#NL#TB#TB#TB${variable}=\"true\";;"
	else
		clap_flag_match="${clap_flag_match}#NL#TB#TB${long}${short:+|${short}})#NL#TB#TB#TB${variable}=(); for ((i=0; i<nargs; i++)); do ${variable}+=( \"\$1\" ); shift 1; done;;"
	fi
	if [ "${default:-}" != "" ]; then
		clap_defaults="${clap_defaults}#NL${variable}=${default@Q}"
	fi
	clap_arguments_string="${clap_arguments_string}${shortname:-}"
	if [ "${val:-}" = "\$OPTARG" ]; then
		clap_arguments_string="${clap_arguments_string}:"
	fi
}

# -----------------------------------------------------------------------------------------------------------------------------
function clap.build() {
	local build_file
	build_file="$(mktemp -t "clap-XXXXXX.tmp")"

	# Function usage
	cat <<EOF >"$build_file"
function usage(){
cat << XXX
usage: \$(basename "\$0") [OPTIONS]

OPTIONS:
        ${clap_usage:-}

        -? --help  :  usage

        --verbose  :  show debug info

XXX
}

# Autocomplete
# Manual: https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion.html
[[ "\${COMP_LINE:-}" == "" ]] || [[ "\${COMP_POINT:-}" == "" ]] || {
	COMP_CURRENT="${1:-}"
	case "\$COMP_CURRENT" in
	"")	compgen -W "${clap_flags:-}" -- "\$COMP_CURRENT" ;;
	-*)	compgen -W "${clap_flags:-}" -- "\$COMP_CURRENT" ;;
	*)	compgen -f -- "\$COMP_CURRENT" ;;
	esac
	exit 0
}

# Set default variable values
$clap_defaults

# Contract long options into short options
while [ \$# -ne 0 ]; do
        param="\$1"
        shift 1

        case "\$param" in
                $clap_flag_match
                "-?"|--help)
			[[ "$(type -t print_help)" != function ]] || print_help
			echo
                        usage
                        exit 0;;
		--verbose)
			CLAP_VERBOSE=true
			set -x;;
		--)
			break ;;
                -*)
                        echo -e "Unrecognized option: \$param"
                        usage
                        exit 1 ;;
                *)
			set "\$param" "\${@}"
			break ;;
        esac
done

# Clean up after self
rm $build_file

EOF

	# shellcheck disable=SC2094
		cat <<<"$(sed 's/#NL/\n/g' "$build_file")" > "$build_file"
	# shellcheck disable=SC2094
		cat <<<"$(sed "s/#TB/\t/g" "$build_file")" > "$build_file"

	# Unset global variables
	unset clap_usage
	unset clap_arguments_string
	unset clap_defaults
	unset clap_flag_match

	# Return file name to parent
	echo "$build_file"
}
# -----------------------------------------------------------------------------------------------------------------------------



================================================
FILE: scripts/commit-metadata
================================================
#!/usr/bin/env bash

print_help() {
  cat <<-EOF

	Records the commit and any tags, if we are in a git repository, in 'in/{commit,tags}'.
	Otherwise creates placeholder files.

	EOF
}

[[ "${1:-}" != "--help" ]] || {
  print_help
  exit 0
}

mkdir -p "in"
if test -e .git; then
  git rev-parse HEAD >"in/commit"
  git tag -l --contains HEAD >"in/tags"
else
  touch "in/commit" "in/tags"
fi



================================================
FILE: scripts/constants.mjs
================================================
import { join } from 'node:path';

const DATA_DIR = join(process.cwd(), 'src', 'frontend', 'src', 'env', 'tokens');

export const CK_ERC20_JSON_FILE = join(DATA_DIR, 'tokens.ckerc20.json');

export const SNS_JSON_FILE = join(DATA_DIR, 'tokens.sns.json');

export const ADDITIONAL_ICRC_JSON_FILE = join(DATA_DIR, 'tokens.icrc.json');



================================================
FILE: scripts/deploy.args.sh
================================================
#!/usr/bin/env bash

II_CANISTER_ID="$(dfx canister id internet_identity --network "${ENV:-local}")"
POUH_ISSUER_CANISTER_ID="$(dfx canister id pouh_issuer --network "${ENV:-local}")"
SIGNER_CANISTER_ID="$(dfx canister id signer --network "${ENV:-local}")"

case $ENV in
"staging")
  ECDSA_KEY_NAME="test_key_1"
  # For security reasons, mainnet root key will be hardcoded in the backend canister.
  ic_root_key_der="null"
  # URL used by issuer in the issued verifiable credentials (typically hard-coded)
  # Represents more an ID than a URL
  POUH_ISSUER_VC_URL="https://${POUH_ISSUER_CANISTER_ID}.icp0.io/"
  ;;
"ic")
  ECDSA_KEY_NAME="key_1"
  # For security reasons, mainnet root key will be hardcoded in the backend canister.
  ic_root_key_der="null"
  # URL used by issuer in the issued verifiable credentials (tipically hard-coded)
  # Represents more an ID than a URL
  POUH_ISSUER_VC_URL="https://id.decideai.xyz/"
  ;;
esac

# URL used by II-issuer in the id_alias-verifiable credentials (hard-coded in II)
# Represents more an ID than a URL
II_VC_URL="https://identity.internetcomputer.org"

echo "(variant {
  Init = record {
        ecdsa_key_name = \"$ECDSA_KEY_NAME\";
        allowed_callers = vec {};
        cfs_canister_id = opt principal \"$SIGNER_CANISTER_ID\";
        supported_credentials = opt vec {
          record {
            credential_type = variant { ProofOfUniqueness };
            ii_origin = \"$II_VC_URL\";
            ii_canister_id = principal \"$II_CANISTER_ID\";
            issuer_origin = \"$POUH_ISSUER_VC_URL\";
            issuer_canister_id = principal \"$POUH_ISSUER_CANISTE
