(Files content cropped to 300k characters)

================================================
FILE: README.md
================================================
# DFINITY's Rust Agent Repository
![GitHub Workflow Status](https://github.com/dfinity/agent-rs/workflows/Tests/badge.svg)
<!-- This file is only meant to be read on GitHub. It will not be published anywhere. -->


## Contributing
Please follow the guidelines in the [CONTRIBUTING.md](.github/CONTRIBUTING.md) document.

## Building
We use `cargo` to build this repo. Make sure you have rust stable installed. To build the repo:

```sh
cargo build
```

## Testing
There are two suites of tests that can be executed from this repo; the regular cargo tests and
the ic-ref tests. In order to run the ic-ref tests, you will need a running local reference
server. If you do not have one, those tests will be ignored.

## Release
To release:
- increase the version number in Cargo.toml (`workspace.package` and `workspace.dependencies`)
- add a header for the version under "## Unreleased" in CHANGELOG.md
- run `cargo build` to update the lock file

## Packages
This repo has multiple packages in its Cargo workspace.

| Package Name | Links | Description |
|---|---|---|
| `ic-agent` | [![README](https://img.shields.io/badge/-README-green)](https://github.com/dfinity/agent-rs/tree/next/ic-agent) [![DOC](https://img.shields.io/badge/-DOC-blue)](https://docs.rs/ic_agent) | The `ic-agent` is a library to talk directly to the Replica. |  
| `ic-utils` | [![README](https://img.shields.io/badge/-README-green)](https://github.com/dfinity/agent-rs/tree/next/ic-utils) [![DOC](https://img.shields.io/badge/-DOC-blue)](https://docs.rs/ic_utils) | A library of utilities for managing calls and canisters. |  
| `icx` | [![README](https://img.shields.io/badge/-README-green)](https://github.com/dfinity/agent-rs/tree/next/icx) | A command line utility to use the agent. Not meant to be published, only available in this repo for tests. |
| `ref-tests` | | A package that only exists to run the ic-ref tests with the ic-agent as the connection. |



================================================
FILE: Cargo.toml
================================================
[workspace]
resolver = "2"
members = [
    "ic-agent",
    "icx-cert",
    "ic-identity-hsm",
    "ic-utils",
    "ic-transport-types",
    "icx",
    "ref-tests",
]

[workspace.package]
version = "0.44.2"
authors = ["DFINITY Stiftung <sdk@dfinity.org>"]
edition = "2021"
repository = "https://github.com/dfinity/agent-rs"
# MSRV
# Avoid updating this field unless we use new Rust features
# Sync rust-version in rust-toolchain.toml
rust-version = "1.85.0"
license = "Apache-2.0"

[workspace.lints.clippy]
needless_lifetimes = "allow"

[workspace.dependencies]
ic-agent = { path = "ic-agent", version = "0.44.2", default-features = false }
ic-utils = { path = "ic-utils", version = "0.44.2" }
ic-transport-types = { path = "ic-transport-types", version = "0.44.2" }

ic-certification = "3"
candid = "0.10.10"
candid_parser = "0.1.4"
clap = "4.5.21"
futures-util = "0.3.31"
hex = "0.4.3"
ic-ed25519 = "0.2"
k256 = "0.13.4"
leb128 = "0.2.5"
pocket-ic = "6.0.0"
p256 = "0.13.2"
rand = "0.8.5"
reqwest = { version = "0.12", default-features = false }
serde = "1.0.215"
serde_bytes = "0.11.15"
serde_cbor = "0.11.2"
serde_json = "1.0.133"
serde_repr = "0.1.19"
sha2 = "0.10.8"
thiserror = "2.0.3"
time = "0.3"
tokio = { version = "1.41.1", default-features = false }
ic-management-canister-types = "0.4.0"



================================================
FILE: CHANGELOG.md
================================================

# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## Unreleased

## [0.44.2] - 2025-10-07

* Fix `HttpService call` retry behavior such that only network errors are retried.

## [0.44.1] - 2025-09-15

* Added `read_state_subnet_canister_ranges` which can query the canister id ranges for a given subnet.

## [0.44.0] - 2025-08-25

* BREAKING: Bump `ic-management-canister-types` to v0.4.0.
  * The `CanisterSettings` types contains a new field `environment_variables`.

## [0.43.0] - 2025-08-25

* BREAKING: Change `HttpService` trait to use normal `http` crate `Request` and `Response` types with `Bytes` as a body instead of `reqwest` ones and add `size_limit` argument.
* BREAKING: Change `AgentError::TransportError` enum variant to hold a generic string instead of `reqwest::Error`.
* `ic-utils`: Bump `ic-management-canister-types` to v0.3.3 which changes snapshot upload/download types.

## [0.42.0] - 2025-08-04

* Use [ic-management-canister-types](https://crates.io/crates/ic-management-canister-types/0.3.2) in [ic-utils](./ic-utils/README.md).
  - This change introduces some breaking changes in `ic-utils` due to the type-inconsistency. For example, the `StatusCallResult` defined in `ic-utils` is not consistent to  the `CanisterStatusResult` defined in `ic-management-canister-types`.
  - The legacy types defined in `ic-utils` are marked as deprecated with messages.
  - Some APIs are updated to use the types defined in `ic-management-canister-types`, e.g. `upload_canister_snapshot_metadata`, `upload_canister_snapshot_data`.

* Bump MSRV from `1.78.0` to `1.85.0`.

## [0.41.0] - 2025-07-10

* Add canister snapshot download and upload methods to `ManagementCanister`.

## [0.40.1] - 2025-05-15

* Add `read_state_canister_controllers` and `read_state_canister_module_hash` functions.

## [0.40.0] - 2025-03-17

* BREAKING: Added data about the rejected call to CertifiedReject/UncertifiedReject.
* Updated the serialization of `WasmMemoryPersistence`.
* BREAKING: `AgentBuilder::with_background_dynamic_routing` is no longer `async`.
* Extended `RouteProvider` trait with `fn routes_stats()`, returning the number of total and healthy routes.
* Added `set_k_top_nodes` configuration option to `LatencyRoutingSnapshot` that enables selective routing to only `k` API boundary nodes with best ranking (based on latencies and availabilities).

## [0.39.3] - 2025-01-21

* Added `wasm_memory_threshold` field to `CanisterSettings`.

* Added `CanisterInfo` to `MgmtMethod`.

## [0.39.2] - 2024-12-20

* Bumped `ic-certification` to `3.0.0`.

## [0.39.0]

* The lower-level update call functions now return the certificate in addition to the parsed response data.
* Make ingress_expiry required and set the default value to 3 min.
* Changed `BasicIdentity`'s implementation from `ring` to `ed25519-consensus`.
* Added `AgentBuilder::with_max_polling_time` to config the maximum time to wait for a response from the replica.
* `DelegatedIdentity::new` now checks the delegation chain. The old behavior is available under `new_unchecked`.

## [0.38.2] - 2024-09-30

* Limited the number of HTTP 429 retries. Users receiving this error should configure `with_max_concurrent_requests`.
* Added `Envelope::encode_bytes` and `Query/UpdateBuilder::into_envelope` for external signing workflows.
* Added `AgentBuilder::with_arc_http_middleware` for `Transport`-like functionality at the level of HTTP requests.
* Add support for dynamic routing based on boundary node discovery. This is an internal feature for now, with a feature flag `_internal_dynamic-routing`.

## [0.38.1] - 2024-09-23

* Fix `ic-agent` manifest so that documentation can be built for docs.rs.

## [0.38.0] - 2024-09-20

* Breaking: Removed `Transport` and the `hyper` and `reqwest` features. `ReqwestTransport` is now the default and `HyperTransport` has been removed. Existing `ReqwestTransport` functions have been moved to `AgentBuilder`.
* `Url` now implements `RouteProvider`.
* Add canister snapshot methods to `ManagementCanister`.
* Add `AllowedViewers` to `LogVisibility` enum.
* Remove the cargo feature, `experimental_sync_call`, and enable synchronous update calls by default.

## [0.37.1] - 2024-07-25

* Bug fix: Add `api/v2` prefix to read_state requests for hyper transport

## [0.37.0] - 2024-07-23

* Removed the Bitcoin query methods from `ManagementCanister`. Users should use `BitcoinCanister` for that.
* Added `BitcoinCanister` to `ic-utils`.
* Upgraded MSRV to 1.75.0.
* Changed `ic_utils::interfaces::management_canister::builders::InstallMode::Upgrade` variant to be `Option<CanisterUpgradeOptions>`:
  * `CanisterUpgradeOptions` is a new struct which covers the new upgrade option: `wasm_memory_persistence: Option<WasmMemoryPersistence>`.
  * `WasmMemoryPersistence` is a new enum which controls Wasm main memory retention on upgrades which has two variants: `Keep` and `Replace`.
* Added an experimental feature, `experimental_sync_call`, to enable synchronous update calls. The feature adds a toggle to the `ReqwestTransport` and `HyperTransport` to enable synchronous update calls.

## [0.36.0] - 2024-06-04

* Added a default request timeout to `ReqwestTransport`.
* Introduced transparent http request retry logic for network-related failures. `ReqwestTransport::with_max_tcp_errors_retries()`, `HyperTransport::with_max_tcp_errors_retries()`.
* Changed the SyncCall and AsyncCall traits to use an associated type for their output instead of a generic parameter.
* Call builders now generally implement `IntoFuture`, allowing `.call_and_wait().await` to be shortened to `.await`.
* Added `log_visibility` to canister creation and canister setting update options.

## [0.35.0] - 2024-05-10

* Added a limit to the concurrent requests an agent will make at once. This should make server-side ratelimiting much rarer to encounter, even when sending a high volume of requests (for example, a large `ic_utils::ManagementCanister::install` call).
* The agent will now automatically retry 429 Too Many Requests responses after a short delay.
* BREAKING: Changed Chunk Store API to conform to the interface specification:
  * `ChunkHash` was changed from `[u8; 32]` to a struct.
  * Return types of `ManagementCanister::stored_chunks()` and `ManagementCanister::upload_chunk()`.
  * Argument type of `ManagementCanister::install_chunked_code()`.
  * `InstallChunkedCodeBuilder`.
    * All occurrences of `storage_canister` were changed to `store_canister`.
    * The field `chunk_hashes_list` was changed from `vec<vec<u8>>` to `vec<ChunkHash>`.
* Changed `WalletCanister::from_canister/create`'s version check to not rely on the reject code.
* Added `QueryBuilder::call_with_verification()` and `QueryBuilder::call_without_verification()` which always/never verify query signatures
  regardless the Agent level configuration from `AgentBuilder::with_verify_query_signatures`.
* Function `Agent::fetch_api_boundary_nodes()` is split into two functions: `fetch_api_boundary_nodes_by_canister_id()` and `fetch_api_boundary_nodes_by_subnet_id()`.
* `ReqwestTransport` and `HyperTransport` structures storing the trait object `route_provider: Box<dyn RouteProvider>` have been modified to allow for shared ownership via `Arc<dyn RouteProvider>`.
* Added `wasm_memory_limit` to canister creation and canister setting update options.
* Bumped Reqwest version from `0.11.7` to `0.12.4`

## [0.34.0] - 2024-03-18

* Changed `AgentError::ReplicaError` to `CertifiedReject` or `UncertifiedReject`. `CertifiedReject`s went through consensus, and `UncertifiedReject`s did not. If your code uses `ReplicaError`:
    * for queries: use `UncertifiedReject` in all cases (for now)
    * for updates: use `CertifiedReject` for errors raised after the message successfully reaches the canister, and `UncertifiedReject` otherwise
* Added `Agent::fetch_api_boundary_nodes` for looking up API boundary nodes in the state tree.
* Timestamps are now being checked in `Agent::verify` and `Agent::verify_for_subnet`. If you were using it with old certificates, increase the expiry timeout to continue to verify them.
* Added node metrics, ECDSA, and Bitcoin functions to `MgmtMethod`. Most do not have wrappers in `ManagementCanister` because only canisters can call these functions.
* Added `FetchCanisterLogs` function to `MgmtMethod` and a corresponding wrapper to `ManagementCanister`.
* Updated the `ring` crate to 0.17.7.  `ring` 0.16 has a bug where it requires incorrect Ed25519 PEM encoding. 0.17.7 fixes that and is backwards compatible.
* Removed serde and candid serialization traits from the `Status` type.
* Added commas and newlines to the `Status` fmt::Display output. It is valid JSON now (it was close before).

## [0.33.0] - 2024-02-08

* Changed the return type of `stored_chunks` to a struct.
* Added a prime256v1-based `Identity` impl to complement the ed25519 and secp256k1 `Identity` impls.
* Changed the type of `InstallMode.skip_pre_upgrade` from `bool` to `Option<bool>` to match the interface specification.

## [0.32.0] - 2024-01-18

* Added the chunked wasm API to ic-utils. Existing code that uses `install_code` should probably update to `install`, which works the same but silently handles large wasm modules.
* Added query stats to `StatusCallResult`.
* Upgraded `ic-certification` to v2.2.

## [0.31.0] - 2023-11-27

* Breaking change: Bump candid to 0.10. Downstream libraries need to bump Candid to 0.10 as well.
* Feat: add `idle_cycles_burned_per_day` field to `StatusCallResult`.

## [0.30.2] - 2023-11-16

* Fixed a spurious certificate validation error in the five minutes after a node is added to a subnet

## [0.30.1] - 2023-11-15

* Fixed `HyperTransport` endpoint construction (`//` in the format `/api/v2//canister/5v3p4-iyaaa-aaaaa-qaaaa-cai/query`)

## [0.30.0] - 2023-11-07

* Added node signature certification to query calls, for protection against rogue boundary nodes. This can be disabled with `with_verify_query_signatures`.
* Added `with_nonce_generation` to `QueryBuilder` for precise cache control.
* Added the ability to dispatch to multiple URLs to `ReqwestTransport` and `HyperTransport`, with a `RouteProvider` trait and a provided `RoundRobinRouteProvider` implementation.
* Added `read_subnet_state_raw` to `Agent` and `read_subnet_state` to `Transport` for looking up raw state by subnet ID instead of canister ID.
* Added `read_state_subnet_metrics` to `Agent` to access subnet metrics, such as total spent cycles.
* Types passed to the `to_request_id` function can now contain nested structs, signed integers, and externally tagged enums.
* `Envelope` struct is public also outside of the crate.
* Remove non-optional `ic_api_version` field (whose value is not meaningfully populated by the replica) and optional `impl_source` and `impl_revision` fields (that are not populated by the replica) from the expected `/api/v2/status` endpoint response.
* Drop `senders` field from user delegations (type `Delegation`).

## [0.29.0] - 2023-09-29

* Added `reserved_cycles_limit` to canister creation and canister setting update options.
* Added `reserved_cycles` and `reserved_cycles_limit` to canister status call result.

## [0.28.0] - 2023-09-21

* Added `DelegatedIdentity`, an `Identity` implementation for consuming delegations such as those from Internet Identity.
* Replica protocol type definitions have been moved to an `ic-transport-types` crate. `ic-agent` still reexports the ones for its API.
* The `Unknown` lookup of a request_status path in a certificate results in an `AgentError` (the IC returns `Absent` for non-existing paths).
* For `Canister` type, added methods with no trailing underscore: update(), query(), canister_id(), clone_with()

## [0.27.0] - 2023-08-30

* Breaking change: Remove argument builder form `ic-utils`. `CallBuilder::with_arg` sets a single argument, instead of pushing a new argument to the list. This function can be called at most once. If it's called multiple times, it panics. If you have multiple arguments, use `CallBuilder::with_args((arg1, arg2))` or `CallBuilder::set_raw_arg(candid::Encode!(arg1, arg2)?)`.
* feat: Added `public_key`, `sign_arbitrary`, `sign_delegation` functions to `Identity`.
* Add `From` trait to coerce `candid::Error` into `ic_agent::AgentError`.
* Add `Agent::set_arc_identity` method to switch identity.

## [0.26.1] - 2023-08-22

Switched from rustls crate to rustls-webpki fork to address https://rustsec.org/advisories/RUSTSEC-2023-0052

## [0.26.0] - 2023-08-21

Removed the `arc_type` feature requirement for candid, in order to avoid deprecation warnings.  This is a breaking change.  The call and call_and_wait are no longer `async fn` and instead return a Future or BoxFuture.

## [0.25.0] - 2023-07-05

* Breaking Change: builders are now owning-style rather than borrowing-style; with_arg takes an owned Vec rather than a borrowed Vec
* Breaking Change: Identity::sign takes &EnvelopeContent rather than the request ID.
* Bump Candid crate to 0.9.0

## [0.24.0] - 2023-05-19

* fix: Adjust the default polling parameters to provide better UX. Remove the `CouldNotReadRootKey` error and panic on poisoned mutex.
* chore: remove deprecated code and fix style
* Breaking Change: removing the PasswordManager
* Breaking Change: Enum variant `AgentError::ReplicaError` is now a tuple struct containing `RejectResponse`.
* Handling rejected update calls where status code is 200. See IC-1462
* Reject code type is changed from `u64` to enum `RejectCode`.

* Support WASM targets in the browser via `wasm-bindgen`. Feature `wasm-bindgen` required.
* Do not send `certificate_version` on HTTP Update requests
* Update `certificate_version` to `u16` instead of `u128`, fixes an issue where the asset canister always responds with v1 response verification

### ic-certification

* Breaking change: Content and path storage has been changed from a `Cow<[u8]>` to a user-provided `T: AsRef<u8>`, removing the lifetime from various types.

### icx-cert

* Fixed issue where a missing request header caused the canister to not respond with an `ic-certificate` header.

## [0.23.2] - 2023-04-21

* Expose the root key to clients through `read_root_key`

## [0.23.1] - 2023-03-09

* Add `lookup_subtree` method to HashTree & HashTreeNode to allow for subtree lookups.
* Derive `Clone` on `Certificate` and `Delegation` structs.
* Add certificate version to http_request canister interface.
* (ic-utils) Add specified_id in provisional_create_canister_with_cycles.

## [0.23.0] - 2022-12-01

* Remove `garcon` from API. Callers can remove the dependency and any usages of it; all waiting functions no longer take a waiter parameter.
* Create `ic-certification` crate and move HashTree and Certificate types.

## [0.22.0] - 2022-10-17

* Drop `disable_range_check` flag from certificate delegation checking.

## [0.21.0] - 2022-10-03

* Update `candid` to v0.8.0.
* Move `hash_tree` from `ic-types` and no more re-export ic-types.

## [0.20.1] - 2022-09-27

* Set `default-features = false` for `ic-agent` interdependencies to reduce unused nested dependencies.
* Bump `candid` to `0.7.18`.

### ic-asset

* Fixed custom configured HTTP headers - no longer is the header's value wrapped with double quotes.

### ic-agent

* Switched to `ic-verify-bls-signature` crate for verify BLS signatures
* Added new `hyper` transport `HyperReplicaV2Transport`
* Added Agent::set_identity method (#379)
* Updated lookup_request_status method to handle proofs of absent paths in certificates.

### ic-utils

* Make it possible to specify effective canister id in CreateCanisterBuilder

## [0.20.0] - 2022-07-14

### Breaking change: Updated to ic-types 0.4.0

* Remove `PrincipalInner`
  * `Principal` directly holds `len` and `bytes` fields
* `PrincipalError` enum has different set of variants reflecting changes in `from_text` logic.
* `from_text` accepts input containing uppercase letters which results in Err before.
* `from_text` verifies CRC32 check sequence

### ic-asset

Added support configurable inclusion and exclusion of files and directories (including dotfiles and dot directories), done via `.ic-assets.json` config file:
- example of `.ic-assets.json` file format:
  ```
  [
      {
          "match": ".*",
          "cache": {
              "max_age": 20
          },
          "headers": {
              "X-Content-Type-Options": "nosniff"
          },
          "ignore": false
      }
  ]
  ```
- see [PR](https://github.com/dfinity/agent-rs/pull/361) and [tests](https://github.com/dfinity/agent-rs/blob/f8515d1d0825b47c8048f5528ac3b65018065779/ic-asset/src/sync.rs#L145) for more examples

Added support for configuring HTTP headers for assets in asset canister (via `.ic-assets.json` config file):
- example of `.ic-assets.json` file format:
  ```
  [
      {
          "match": "*",
          "cache": {
              "max_age": 20
          },
          "headers": {
              "X-Content-Type-Options": "nosniff"
          }
      },
      {
          "match": "**/*",
          "headers": null
      },
  ]
  ```
- `headers` from multiple applicable rules are being stacked/concatenated, unless `null` is specified, which resets/empties the headers. Both `"headers": {}` and absence of `headers` don't have any effect on end result.

## [0.19.0] - 2022-07-06

### ic-asset

Added support for asset canister config files in `ic-assets`.
- reads configuration from `.ic-assets.json` config files if placed inside assets directory, multiple config files can be used (nested in subdirectories)
- runs successfully only if the config file is right format (valid JSON, valid glob pattern, JSON fields in correct format)
- example of `.ic-assets.json` file format:
  ```
  [
      {
          "match": "*",
          "cache": {
              "max_age": 20
          }
      }
  ]
  ```
- works only during asset creation
- the config file is being taken into account only when calling `ic_asset::sync` (i.e. `dfx deploy` or `icx-asset sync`)

## [0.18.0] - 2022-06-23

### ic-asset

Breaking change: ic-asset::sync() now synchronizes from multiple source directories.

This is to allow for configuration files located alongside assets in asset source directories.

Also, ic-asset::sync:
- skips files and directories that begin with a ".", as dfx does when copying assets to an output directory.
- reports an error if more than one asset file would resolve to the same asset key

## [0.17.1] - 2022-06-22

[agent-rs/349](https://github.com/dfinity/agent-rs/pull/349) feat: add with_max_response_body_size to ReqwestHttpReplicaV2Transport

## [0.17.0] - 2022-05-19

Updated dependencies.  Some had breaking changes: k256 0.11, pkcs 0.9, and sec1 0.3.

Fixed a potential panic in secp256k1 signature generation.

## [0.16.0] - 2022-04-28

Added `ReqwestHttpReplicaV2Transport::create_with_client`.

Remove `openssl` in favor of pure rust libraries.

Updated minimum version of reqwest to 0.11.7.  This is to avoid the following error, seen with reqwest 0.11.6:

```
Unknown TLS backend passed to use_preconfigured_tls
```

Updated wallet interface for 128-bit API.

Remove parameterized canister pattern.  Use `WalletCanister::create` rather than `Wallet::create`.

wallet_send takes Principal instead of &Canister.


## [0.15.0] - 2022-03-28

Updated `ic_utils::interfaces::http_request` structures to use `&str` to reduce copying.

Removed `Deserialize` from `HttpRequest`.

Changed `HttpResponse` to be generic over entire callback instead of just `ArgToken`.

Added `HttpRequestStreamingCallbackAny` to deserialize any callback, regardless of signature.

Added conversion helpers for `HttpResponse`, `StreamingStrategy` and `CallbackStrategy` across generics.

Changes to `Canister<HttpRequestCanister>` interface.

* Made `http_request`, `http_request_update`, and `http_request_stream_callback` more generic and require fewer string copies.
* Added `_custom` variants to enable custom `token` deserialization.

## [0.14.0] - 2022-03-17

Introduced HttpRequestStreamingCallback to work around https://github.com/dfinity/candid/issues/273.

Response certificate verification will check that the canister id falls within the range of valid canister ids for the subnet.

## [0.13.0] - 2022-03-07
Secp256k1 identity now checks if a curve actually uses the secp256k1 parameters. It cannot be used to load non-secp256k1 identities anymore.

Data type of `cycles` changed to `u128` (was `u64`).

fetch_root_key() only fetches on the first call.

Re-genericized Token to allow use of an arbitrary Token type with StreamingStrategy.

## [0.12.1] - 2022-02-09

Renamed BatchOperationKind._Clear to Clear for compatibility with the certified assets canister.
This avoids decode errors, even though the type isn't referenced here.

## [0.12.0] - 2022-02-03

Changed the 'HttpRequest.upgrade' field to 'Option<bool>' from 'bool'.

## [0.11.1] - 2022-01-10

The `lookup_value` function now takes generics which can be iterated over (`IntoIterator<Item = &'p Label>`)  and transformed into a `Vec<Label>`, rather than just a `Vec<Label>`.

## [0.11.0] - 2022-01-07

### Breaking change: Updated to ic-types 0.3.0

The `lookup_path` method now takes an `Iterator<Label>` rather than an `AsRef<[Label]>`

## [0.10.2] - 2021-12-22

### ic-agent

Added support for upgrading HTTP requests (http_request_update method)

## [0.10.1] - 2021-12-10

Updated crate dependencies, most notably updating rustls,
removing the direct dependency on webpki-roots, and allowing
consumers of ic-agent to update to reqwest 0.11.7.

### ic-agent

#### Added: read_state_canister_metadata

Implements https://github.com/dfinity-lab/ic-ref/pull/371

### ic-asset

#### Fixed: sync and upload will now attempt retries as expected

Fixed a defect in asset synchronization where no retries would be attempted after the first 30 seconds overall.

### icx-asset

#### Fixed: now works with secp256k1 .pem files.

## [0.10.0] - 2021-11-15

Unified all version numbers and removed the zzz-release tool.

### ic-agent

#### Fixed: rewrite all *.ic0.app domains to ic0.app to avoid redirects.

### icx-cert

#### New feature: Add --accept-encoding parameter

It's now possible to specify which encodings will be accepted.  The default (and previous) behavior
is to accept only the identity encoding.  Specifying encodings that browsers more commonly accept
demonstrates the difference in the returned data and certificate.

For example, here is the data and certificate returned when only accepting the identity encoding.

```
$ cargo run -p icx-cert -- print 'http://localhost:8000/index.js?canisterId=ryjl3-tyaaa-aaaaa-aaaba-cai'
DATA HASH: 1495cd574831c23b4db97bc3860666ea495386f0ef0dab73c23ef31db5aa2765
    Label("/index.js", Leaf(0x1495cd574831c23b4db97bc3860666ea495386f0ef0dab73c23ef31db5aa2765)),
```

Here is an example accepting the gzip encoding (as most browsers do), showing that the canister
responded with different data having a different data hash.

```
$ cargo run -p icx-cert -- print --accept-encoding gzip 'http://localhost:8000/index.js?canisterId=ryjl3-tyaaa-aaaaa-aaaba-cai'
DATA HASH: 1770e76af0816ba951320c03eab1263c43de7ac4b0558dd9049cc532b7d6cd01
    Label("/index.js", Leaf(0x1495cd574831c23b4db97bc3860666ea495386f0ef0dab73c23ef31db5aa2765)),
```

### icx-proxy

This project moved to https://github.com/dfinity/icx-proxy.

## [0.9.0] - 2021-10-06

### ic-agent

#### Added

- Added field `replica_health_status` to `Status`.
    - typical values
        - `healthy`
        - `waiting_for_certified_state`



================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright 2020 DFINITY Stiftung.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: rust-toolchain.toml
================================================
[toolchain]
# MSRV
# Avoid updating this field unless we use new Rust features
# Sync rust-version in workspace Cargo.toml
channel = "1.85.0"
components = ["rustfmt", "clippy"]
targets = ["wasm32-unknown-unknown"]



================================================
FILE: .mergify.yml
================================================
pull_request_rules:
  - name: Automatic merge
    conditions:
      - "#approved-reviews-by>=1"
      - "#changes-requested-reviews-by=0"
      - status-success=conventional-pr-title
      - label=automerge-squash
    actions:
      merge:
        method: squash
        strict: smart
        commit_message: title+body
      delete_head_branch: {}

  - name: Clean up automerge tags
    conditions:
      - closed
    actions:
      label:
        remove:
          - automerge-squash

  - name: Auto-approve auto-PRs
    conditions:
      - author=dfinity-bot
    actions:
      review:
        type: APPROVE
        message: This bot trusts that bot



================================================
FILE: e2e/bash/icx.bash
================================================
#!/usr/bin/env bats

# shellcheck disable=SC1090
source "$BATS_SUPPORT"/load.bash

load util/assertions

setup() {
    cd "$(mktemp -d -t icx-e2e-XXXXXXXX)" || exit 1
    dfx new --no-frontend e2e_project
    cd e2e_project || exit 1
    dfx start --background
    dfx deploy
}

teardown() {
    echo teardown
    dfx stop
}

# this test does not work, and is not run in CI
@test "sign update" {
  "$ICX" --pem "$HOME"/.config/dfx/identity/default/identity.pem update --serialize rwlgt-iiaaa-aaaaa-aaaaa-cai greet '("everyone")' > output.txt
  head -n 1 output.txt > update.json
  tail -n 1 output.txt > request_status.json
  "$ICX" send <update.json
  "$ICX" send <request_status.json
}



================================================
FILE: e2e/bash/util/assertions.bash
================================================
#!

# Asserts that a command line succeeds. Still sets $output to the stdout and stderr
# of the command.
# Arguments:
#   $@ - The command to run.
# Returns:
#   none
assert_command() {
    x="$(mktemp)"
    local stderrf="$x"
    x="$(mktemp)"
    local stdoutf="$x"
    x="$(mktemp)"
    local statusf="$x"
    ( set +e; "$@" 2>"$stderrf" >"$stdoutf"; echo -n "$?" > "$statusf" )
    status="$(<"$statusf")"; rm "$statusf"

    stderr="$(cat "$stderrf")"; rm "$stderrf"
    stdout="$(cat "$stdoutf")"; rm "$stdoutf"
    # shellcheck disable=SC2015
    output="$( \
        [ "$stderr" ] && echo "$stderr" || true; \
        [ "$stdout" ] && echo "$stdout" || true; \
    )"

    [[ $status == 0 ]] || \
        (  (echo "$*"; echo "status: $status"; echo "$output" | batslib_decorate "Output") \
         | batslib_decorate "Command failed" \
         | fail)
}

# Asserts that a command line fails. Still sets $output to the stdout and stderr
# of the command.
# Arguments:
#   $@ - The command to run.
# Returns:
#   none
assert_command_fail() {
    x="$(mktemp)"
    local stderrf="$x"
    x="$(mktemp)"
    local stdoutf="$x"
    x="$(mktemp)"
    local statusf="$x"
    ( set +e; "$@" 2>"$stderrf" >"$stdoutf"; echo -n "$?" >"$statusf" )
    status="$(<"$statusf")"; rm "$statusf"

    stderr="$(cat "$stderrf")"; rm "$stderrf"
    stdout="$(cat "$stdoutf")"; rm "$stdoutf"
    # shellcheck disable=SC2015
    output="$(
        [ "$stderr" ] && echo "$stderr" || true;
        [ "$stdout" ] && echo "$stdout" || true;
    )"

    [[ $status != 0 ]] || \
        (  (echo "$*"; echo "$output" | batslib_decorate "Output") \
         | batslib_decorate "Command succeeded (should have failed)" \
         | fail)
}

# Asserts that a string contains another string, using regexp.
# Arguments:
#    $1 - The regex to use to match.
#    $2 - The string to match against (output). By default it will use
#         $output.
assert_match() {
    regex="$1"
    if [[ $# -lt 2 ]]; then
        text="$output"
    else
        text="$2"
    fi
    [[ "$text" =~ $regex ]] || \
        (batslib_print_kv_single_or_multi 10 "regex" "$regex" "actual" "$text" \
         | batslib_decorate "output does not match" \
         | fail)
}

# Asserts that a string does not contain another string, using regexp.
# Arguments:
#    $1 - The regex to use to match.
#    $2 - The string to match against (output). By default it will use
#         $output.
assert_not_match() {
    regex="$1"
    if [[ $# -lt 2 ]]; then
        text="$output"
    else
        text="$2"
    fi
    if [[ "$text" =~ $regex ]]; then
        (batslib_print_kv_single_or_multi 10 "regex" "$regex" "actual" "$text" \
         | batslib_decorate "output matches but is expected not to" \
         | fail)
    fi
}

# Asserts a command will timeout. This assertion will fail if the command finishes before
# the timeout period. If the command fails, it will also fail.
# Arguments:
#   $1 - The amount of time (in seconds) to wait for.
#   $@ - The command to run.

# Asserts that two values are equal.
# Arguments:
#    $1 - The expected value.
#    $2 - The actual value.
assert_eq() {
    expected="$1"
    if [[ $# -lt 2 ]]; then
        actual="$output"
    else
        actual="$2"
    fi

    [[ "$actual" == "$expected" ]] || \
        (batslib_print_kv_single_or_multi 10 "expected" "$expected" "actual" "$actual" \
         | batslib_decorate "output does not match" \
         | fail)
}

# Asserts that two values are not equal.
# Arguments:
#    $1 - The expected value.
#    $2 - The actual value.
assert_neq() {
    expected="$1"
    if [[ $# -lt 2 ]]; then
        actual="$output"
    else
        actual="$2"
    fi

    [[ "$actual" != "$expected" ]] || \
        (batslib_print_kv_single_or_multi 10 "expected" "$expected" "actual" "$actual" \
         | batslib_decorate "output does not match" \
         | fail)
}


# Asserts that a process exits within a timeframe
# Arguments:
#    $1 - the PID
#    $2 - the timeout
assert_process_exits() {
    pid="$1"
    timeout="$2"

    timeout "$timeout" sh -c \
      "while kill -0 $pid; do echo waiting for process $pid to exit; sleep 1; done" \
      || (echo "process $pid did not exit" && ps aux && exit 1)

}

assert_file_eventually_exists() {
    filename="$1"
    timeout="$2"

    timeout "$timeout" sh -c \
      "until [ -f $filename ]; do echo waiting for $filename; sleep 1; done" \
      || (echo "file $filename was never created" && ls && exit 1)
}



================================================
FILE: ic-agent/README.md
================================================
`ic-agent` is a simple-to-use library to interact with the [Internet Computer](https://internetcomputer.org)
in Rust. It is the backend for [`dfx`](https://internetcomputer.org/docs/current/references/cli-reference/).

## Useful links

- [Documentation (master)](https://agent-rust.netlify.app/ic_agent)
- [Documentation (published)](https://docs.rs/ic_agent)



================================================
FILE: ic-agent/Cargo.toml
================================================
[package]
name = "ic-agent"
version.workspace = true
authors.workspace = true
edition.workspace = true
repository.workspace = true
license.workspace = true
rust-version.workspace = true
description = "Agent library to communicate with the Internet Computer, following the Public Specification."
homepage = "https://docs.rs/ic-agent"
documentation = "https://docs.rs/ic-agent"
readme = "README.md"
categories = ["api-bindings", "data-structures", "no-std"]
keywords = ["internet-computer", "agent", "icp", "dfinity"]
include = ["src", "Cargo.toml", "../LICENSE", "README.md"]

[lints]
workspace = true

[dependencies]
arc-swap = "1.7"
async-channel = "1.9"
async-lock = "3.3"
async-trait = "0.1"
async-watch = "0.3"
backoff = "0.4.0"
bytes = "1.10.1"
cached = { version = "0.52", features = ["ahash"], default-features = false }
candid = { workspace = true }
der = "0.7"
ecdsa = "0.16"
# Note
# ed25519-consensus is kept as a dependency for backward compatibility.
# It is only used in the identity constructor `BasicIdentity::from_signing_key`.
# The actual signing and verification is done using `ic-ed25519`.
ed25519-consensus = "2.1.0"
elliptic-curve = "0.13"
futures-util = { workspace = true }
hex = { workspace = true }
http = "1.0.0"
http-body = "1.0.0"
http-body-util = "0.1.3"
ic-certification = { workspace = true }
ic-ed25519 = { workspace = true }
ic-transport-types = { workspace = true }
ic-verify-bls-signature = "0.5"
k256 = { workspace = true, features = ["pem"] }
p256 = { workspace = true, features = ["pem"] }
leb128 = { workspace = true }
pkcs8 = { version = "0.10.2", features = ["std"] }
sec1 = { version = "0.7.2", features = ["pem"] }
rand = { workspace = true }
rangemap = "1.4"
ring = { version = "0.17", optional = true }
serde = { workspace = true, features = ["derive"] }
serde_bytes = { workspace = true }
serde_cbor = { workspace = true }
serde_repr = { workspace = true }
sha2 = { workspace = true }
stop-token = "0.7"
thiserror = { workspace = true }
time = { workspace = true }
tower-service = "0.3"
tracing = { version = "0.1", optional = true }
url = "2.1.0"

[dependencies.reqwest]
workspace = true
default-features = false
features = ["blocking", "json", "rustls-tls-webpki-roots", "stream"]

[dependencies.pem]
version = "3"
optional = true

[target.'cfg(not(target_family = "wasm"))'.dependencies]
tokio = { version = "1.24.2", features = ["time"] }

[target.'cfg(target_family = "wasm")'.dependencies]
getrandom = { version = "0.2", features = ["js"], optional = true }
js-sys = { version = "0.3", optional = true }
wasm-bindgen = { version = "0.2", optional = true }
wasm-bindgen-futures = { version = "0.4", optional = true }
web-sys = { version = "0.3", features = ["Window"], optional = true }

[dev-dependencies]
serde_json.workspace = true
tracing-subscriber = "0.3"
tracing = "0.1"

[target.'cfg(not(target_family = "wasm"))'.dev-dependencies]
tokio = { workspace = true, features = ["full"] }
mockito = "1.0.2"

[target.'cfg(target_family = "wasm")'.dev-dependencies]
wasm-bindgen-test = "0.3.34"
web-sys = { version = "0.3", features = [
    "Navigator",
    "ServiceWorkerContainer",
    "ServiceWorker",
    "ServiceWorkerRegistration",
    "ServiceWorkerState",
] }

[features]
default = ["pem"]
pem = ["dep:pem"]
ring = ["dep:ring"]
ic_ref_tests = ["default"] # Used to separate integration tests for ic-ref which need a server running.
wasm-bindgen = [
    "dep:js-sys",
    "dep:wasm-bindgen",
    "dep:wasm-bindgen-futures",
    "dep:getrandom",
    "dep:web-sys",
    "time/wasm-bindgen",
    "backoff/wasm-bindgen",
    "cached/wasm",
]
_internal_dynamic-routing = []
tracing = ["dep:tracing"] # Does very little right now.

[package.metadata.docs.rs]
targets = ["x86_64-unknown-linux-gnu", "wasm32-unknown-unknown"]
features = ["wasm-bindgen"]



================================================
FILE: ic-agent/http_mock_service_worker.js
================================================
let db = null;

async function getDb() {
    if (db) {
        return db;
    } else {
        return await new Promise((rs, rj) => {
            const req = indexedDB.open("http_mock", 1);
            req.onsuccess = (event) => rs(event.target.result);
            req.onerror = rj;
            req.onupgradeneeded = (event) => {
                db = event.target.result;
                db.createObjectStore("mocks", { keyPath: "nonce" });
            };
        })
    }
}

async function setMock(mock) {
    const db = await getDb();
    await new Promise((rs, rj) => {
        const transaction = db.transaction("mocks", "readwrite");
        transaction.oncomplete = rs;
        transaction.onerror = rj;
        const store = transaction.objectStore("mocks");
        store.put(mock);
    })
}

async function getMock(nonce) {
    const db = await getDb();
    return await new Promise((rs, rj) => {
        const req = db.transaction("mocks")
            .objectStore("mocks")
            .get(nonce);
        req.onsuccess = (event) => rs(event.target.result);
        req.onerror = rj;
    });
}

// Status codes are chosen to avoid being picked up as successes by tests expecting a 404 or 500.

self.addEventListener("fetch", (event) => {
    event.respondWith((async () => {
        try {
            const request = event.request;
            const url = new URL(request.url);
            if (url.host === "mock_configure") {
                const nonce = url.pathname.substring(1);
                const { method, path, status_code, body, headers } = await request.json();
                const mock = await getMock(nonce) ?? { nonce, routes: [] };
                mock.routes.push({ method, path, status_code, body, headers, hits: 0 });
                await setMock(mock);
                return new Response(null, { status: 204 });
            } else if (url.host === "mock_assert") {
                const nonce = url.pathname.substring(1);
                const mock = await getMock(nonce);
                if (mock === undefined) {
                    return new Response(`no such mock id ${nonce}`, { status: 421 });
                }
                const hitsMap = Object.fromEntries(mock.routes.map(route => [`${route.method} ${route.path}`, route.hits]));
                return new Response(JSON.stringify(hitsMap), { status: 200, headers: { 'Content-Type': 'application/json' } });
            } else {
                const nonce = url.host.split('_')[1];
                const mock = await getMock(nonce);
                if (mock === undefined) {
                    return new Response(`no such mock id ${nonce}`, { status: 421 });
                }
                for (const route of mock.routes) {
                    if (request.method === route.method && url.pathname === route.path) {
                        route.hits += 1;
                        await setMock(mock);
                        return new Response(Uint8Array.from(route.body), { status: route.status_code, headers: route.headers });
                    }
                }
                const possiblyMeant = mock.routes.find(route => route.path === url.pathname);
                if (possiblyMeant !== undefined) {
                    return new Response(`expected ${possiblyMeant.method}, got ${request.method}`, { status: 405 })
                } else {
                    return new Response(`expected ${mock.routes.map(route => route.path).join(' | ')}, got ${url.pathname}`, { status: 410 });
                }
            }
        } catch (e) {
            return new Response(e.toString(), { status: 503 });
        }
    })())
});

self.addEventListener("activate", (event) => {
    skipWaiting();
    event.waitUntil(clients.claim());
});



================================================
FILE: ic-agent/src/export.rs
================================================
//! A module to re-export types that are visible through the ic-agent API.
#[doc(inline)]
pub use candid::types::principal::{Principal, PrincipalError};
pub use reqwest;



================================================
FILE: ic-agent/src/lib.rs
================================================
//! The `ic-agent` is a simple-to-use library that enables you to
//! build applications and interact with the [Internet Computer](https://internetcomputer.org)
//! in Rust. It serves as a Rust-based low-level backend for the
//! DFINITY Canister Software Development Kit (SDK) and the command-line execution environment
//! [`dfx`](https://internetcomputer.org/docs/current/developer-docs/setup/install).
//!
//! ## Overview
//! The `ic-agent` is a Rust crate that can connect directly to the Internet
//! Computer through the Internet Computer protocol (ICP).
//! The key software components of the ICP are broadly referred to as the
//! [replica](https://internetcomputer.org/docs/current/concepts/nodes-subnets).
//!
//! The agent is designed to be compatible with multiple versions of the
//! replica API, and to expose both low-level APIs for communicating with
//! Internet Computer protocol components like the replica and to provide
//! higher-level APIs for communicating with software applications deployed
//! as [canisters](https://internetcomputer.org/docs/current/concepts/canisters-code).
//!
//! ## Example
//! The following example illustrates how to use the Agent interface to send
//! a call to an Internet Computer's Ledger Canister to check the total ICP tokens supply.
//!
//! ```rust
//!use anyhow::{Context, Result};
//!use candid::{Decode, Nat};
//!use ic_agent::{export::Principal, Agent};
//!use url::Url;
//!
//!pub async fn create_agent(url: Url, use_mainnet: bool) -> Result<Agent> {
//!    let agent = Agent::builder().with_url(url).build()?;
//!    if !use_mainnet {
//!        agent.fetch_root_key().await?;
//!    }
//!    Ok(agent)
//!}
//!
//!#[tokio::main]
//!async fn main() -> Result<()> {
//!    // IC HTTP Gateway URL
//!    let url = Url::parse("https://ic0.app").unwrap();
//!    let agent = create_agent(url, true).await?;
//!
//!    // ICP Ledger Canister ID
//!    let canister_id = Principal::from_text("ryjl3-tyaaa-aaaaa-aaaba-cai")?;
//!
//!    // Method: icrc1_total_supply (takes no arguments, returns nat)
//!    let method_name = "icrc1_total_supply";
//!
//!    // Encode empty Candid arguments
//!    let args = candid::encode_args(())?;
//!
//!    // Dispatch query call
//!    let response = agent
//!        .query(&canister_id, method_name)
//!        .with_arg(args)
//!        .call()
//!        .await
//!        .context("Failed to query icrc1_total_supply method.")?;
//!
//!    // Decode the response as nat
//!    let total_supply_nat =
//!        Decode!(&response, Nat).context("Failed to decode total supply as nat.")?;
//!
//!    println!("Total ICP Supply: {} ICP", total_supply_nat);
//!
//!    Ok(())
//!}
//! ```
//! For more information about the Agent interface used in this example, see the
//! [Agent] documentation.
//!
//! ## References
//! For an introduction to the Internet Computer and the DFINITY Canister SDK,
//! see the following resources:
//!
//! - [How the IC Works](https://internetcomputer.org/docs/current/concepts/)
//! - [DFINITY Canister SDK](https://internetcomputer.org/docs/current/references/cli-reference/)
//!
//! The Internet Computer protocol and interface specifications are not
//! publicly available yet. When these specifications are made public and
//! generally available, additional details about the versions supported will
//! be available here.

#![warn(
    missing_docs,
    rustdoc::broken_intra_doc_links,
    rustdoc::private_intra_doc_links
)]
#![cfg_attr(not(target_family = "wasm"), warn(clippy::future_not_send))]
#![cfg_attr(docsrs, feature(doc_cfg))]

#[macro_use]
mod util;

pub mod agent;
pub mod export;
pub mod identity;

use agent::response_authentication::LookupPath;
#[doc(inline)]
pub use agent::{agent_error, agent_error::AgentError, Agent, NonceFactory, NonceGenerator};
#[doc(inline)]
pub use ic_transport_types::{to_request_id, RequestId, RequestIdError, TransportCallResponse};
#[doc(inline)]
pub use identity::{Identity, Signature};

// Re-export from ic_certification for backward compatibility.
pub use ic_certification::{hash_tree, Certificate};

/// Looks up a value in the certificate's tree at the specified hash.
///
/// Returns the value if it was found; otherwise, errors with `LookupPathAbsent`, `LookupPathUnknown`, or `LookupPathError`.
pub fn lookup_value<P: LookupPath, Storage: AsRef<[u8]>>(
    tree: &ic_certification::certificate::Certificate<Storage>,
    path: P,
) -> Result<&[u8], AgentError> {
    agent::response_authentication::lookup_value(&tree.tree, path)
}



================================================
FILE: ic-agent/src/util.rs
================================================
#![allow(dead_code)]

use std::future::Future;
use std::time::Duration;

pub async fn sleep(d: Duration) {
    #[cfg(not(all(target_family = "wasm", feature = "wasm-bindgen")))]
    tokio::time::sleep(d).await;
    #[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
    wasm_bindgen_futures::JsFuture::from(js_sys::Promise::new(&mut |rs, rj| {
        if let Err(e) = web_sys::window()
            .expect("global window unavailable")
            .set_timeout_with_callback_and_timeout_and_arguments_0(&rs, d.as_millis() as _)
        {
            use wasm_bindgen::UnwrapThrowExt;
            rj.call1(&rj, &e).unwrap_throw();
        }
    }))
    .await
    .expect("unable to setTimeout");
    #[cfg(all(target_family = "wasm", not(feature = "wasm-bindgen")))]
    const _: () =
        { panic!("Using ic-agent from WASM requires enabling the `wasm-bindgen` feature") };
}

#[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
pub fn spawn(f: impl Future<Output = ()> + 'static) {
    wasm_bindgen_futures::spawn_local(f);
}

#[cfg(not(all(target_family = "wasm", feature = "wasm-bindgen")))]
pub fn spawn(f: impl Future<Output = ()> + Send + 'static) {
    tokio::spawn(f);
}

macro_rules! log {
    ($name:ident, $($t:tt)*) => { #[cfg(feature = "tracing")] { tracing::$name!($($t)*) } };
}



================================================
FILE: ic-agent/src/agent/agent_config.rs
================================================
use reqwest::Client;
use url::Url;

use crate::{
    agent::{NonceFactory, NonceGenerator},
    identity::{anonymous::AnonymousIdentity, Identity},
};
use std::{sync::Arc, time::Duration};

use super::{route_provider::RouteProvider, HttpService};

/// A configuration for an agent.
#[non_exhaustive]
pub struct AgentConfig {
    /// See [`with_nonce_factory`](super::AgentBuilder::with_nonce_factory).
    pub nonce_factory: Arc<dyn NonceGenerator>,
    /// See [`with_identity`](super::AgentBuilder::with_identity).
    pub identity: Arc<dyn Identity>,
    /// See [`with_ingress_expiry`](super::AgentBuilder::with_ingress_expiry).
    pub ingress_expiry: Duration,
    /// See [`with_http_client`](super::AgentBuilder::with_http_client).
    pub client: Option<Client>,
    /// See [`with_route_provider`](super::AgentBuilder::with_route_provider).
    pub route_provider: Option<Arc<dyn RouteProvider>>,
    /// See [`verify_query_signatures`](super::AgentBuilder::with_verify_query_signatures).
    pub verify_query_signatures: bool,
    /// See [`with_max_concurrent_requests`](super::AgentBuilder::with_max_concurrent_requests).
    pub max_concurrent_requests: usize,
    /// See [`with_max_response_body_size`](super::AgentBuilder::with_max_response_body_size).
    pub max_response_body_size: Option<usize>,
    /// See [`with_max_tcp_error_retries`](super::AgentBuilder::with_max_tcp_error_retries).
    pub max_tcp_error_retries: usize,
    /// See [`with_arc_http_middleware`](super::AgentBuilder::with_arc_http_middleware).
    pub http_service: Option<Arc<dyn HttpService>>,
    /// See [`with_max_polling_time`](super::AgentBuilder::with_max_polling_time).
    pub max_polling_time: Duration,
    /// See [`with_background_dynamic_routing`](super::AgentBuilder::with_background_dynamic_routing).
    pub background_dynamic_routing: bool,
    /// See [`with_url`](super::AgentBuilder::with_url).
    pub url: Option<Url>,
}

impl Default for AgentConfig {
    fn default() -> Self {
        Self {
            nonce_factory: Arc::new(NonceFactory::random()),
            identity: Arc::new(AnonymousIdentity {}),
            ingress_expiry: Duration::from_secs(3 * 60),
            client: None,
            http_service: None,
            verify_query_signatures: true,
            max_concurrent_requests: 50,
            route_provider: None,
            max_response_body_size: None,
            max_tcp_error_retries: 0,
            max_polling_time: Duration::from_secs(60 * 5),
            background_dynamic_routing: false,
            url: None,
        }
    }
}



================================================
FILE: ic-agent/src/agent/agent_error.rs
================================================
//! Errors that can occur when using the replica agent.

use crate::{agent::status::Status, RequestIdError};
use candid::Principal;
use ic_certification::Label;
use ic_transport_types::{InvalidRejectCodeError, RejectResponse};
use leb128::read;
use std::time::Duration;
use std::{
    fmt::{Debug, Display, Formatter},
    str::Utf8Error,
};
use thiserror::Error;

/// An error that occurs on transport layer
#[derive(Error, Debug)]
pub enum TransportError {
    /// Reqwest-related error
    #[error("{0}")]
    Reqwest(reqwest::Error),
    #[error("{0}")]
    /// Generic non-specific error
    Generic(String),
}

/// An error that occurred when using the agent.
#[derive(Error, Debug)]
pub enum AgentError {
    /// The replica URL was invalid.
    #[error(r#"Invalid Replica URL: "{0}""#)]
    InvalidReplicaUrl(String),

    /// The request timed out.
    #[error("The request timed out.")]
    TimeoutWaitingForResponse(),

    /// An error occurred when signing with the identity.
    #[error("Identity had a signing error: {0}")]
    SigningError(String),

    /// The data fetched was invalid CBOR.
    #[error("Invalid CBOR data, could not deserialize: {0}")]
    InvalidCborData(#[from] serde_cbor::Error),

    /// There was an error calculating a request ID.
    #[error("Cannot calculate a RequestID: {0}")]
    CannotCalculateRequestId(#[from] RequestIdError),

    /// There was an error when de/serializing with Candid.
    #[error("Candid returned an error: {0}")]
    CandidError(Box<dyn Send + Sync + std::error::Error>),

    /// There was an error parsing a URL.
    #[error(r#"Cannot parse url: "{0}""#)]
    UrlParseError(#[from] url::ParseError),

    /// The HTTP method was invalid.
    #[error(r#"Invalid method: "{0}""#)]
    InvalidMethodError(#[from] http::method::InvalidMethod),

    /// The principal string was not a valid principal.
    #[error("Cannot parse Principal: {0}")]
    PrincipalError(#[from] crate::export::PrincipalError),

    /// The subnet rejected the message.
    #[error("The replica returned a rejection error: reject code {:?}, reject message {}, error code {:?}", .reject.reject_code, .reject.reject_message, .reject.error_code)]
    CertifiedReject {
        /// The rejection returned by the replica.
        reject: RejectResponse,
        /// The operation that was rejected. Not always available.
        operation: Option<Operation>,
    },

    /// The subnet may have rejected the message. This rejection cannot be verified as authentic.
    #[error("The replica returned a rejection error: reject code {:?}, reject message {}, error code {:?}", .reject.reject_code, .reject.reject_message, .reject.error_code)]
    UncertifiedReject {
        /// The rejection returned by the boundary node.
        reject: RejectResponse,
        /// The operation that was rejected. Not always available.
        operation: Option<Operation>,
    },

    /// The replica returned an HTTP error.
    #[error("The replica returned an HTTP Error: {0}")]
    HttpError(HttpErrorPayload),

    /// The status endpoint returned an invalid status.
    #[error("Status endpoint returned an invalid status.")]
    InvalidReplicaStatus,

    /// The call was marked done, but no reply was provided.
    #[error("Call was marked as done but we never saw the reply. Request ID: {0}")]
    RequestStatusDoneNoReply(String),

    /// A string error occurred in an external tool.
    #[error("A tool returned a string message error: {0}")]
    MessageError(String),

    /// There was an error reading a LEB128 value.
    #[error("Error reading LEB128 value: {0}")]
    Leb128ReadError(#[from] read::Error),

    /// A string was invalid UTF-8.
    #[error("Error in UTF-8 string: {0}")]
    Utf8ReadError(#[from] Utf8Error),

    /// The lookup path was absent in the certificate.
    #[error("The lookup path ({0:?}) is absent in the certificate.")]
    LookupPathAbsent(Vec<Label>),

    /// The lookup path was unknown in the certificate.
    #[error("The lookup path ({0:?}) is unknown in the certificate.")]
    LookupPathUnknown(Vec<Label>),

    /// The lookup path did not make sense for the certificate.
    #[error("The lookup path ({0:?}) does not make sense for the certificate.")]
    LookupPathError(Vec<Label>),

    /// The request status at the requested path was invalid.
    #[error("The request status ({1}) at path {0:?} is invalid.")]
    InvalidRequestStatus(Vec<Label>, String),

    /// The certificate verification for a `read_state` call failed.
    #[error("Certificate verification failed.")]
    CertificateVerificationFailed(),

    /// The signature verification for a query call failed.
    #[error("Query signature verification failed.")]
    QuerySignatureVerificationFailed,

    /// The certificate contained a delegation that does not include the `effective_canister_id` in the `canister_ranges` field.
    #[error("Certificate is not authorized to respond to queries for this canister. While developing: Did you forget to set effective_canister_id?")]
    CertificateNotAuthorized(),

    /// The certificate was older than allowed by the `ingress_expiry`.
    #[error("Certificate is stale (over {0:?}). Is the computer's clock synchronized?")]
    CertificateOutdated(Duration),

    /// The certificate contained more than one delegation.
    #[error("The certificate contained more than one delegation")]
    CertificateHasTooManyDelegations,

    /// The query response did not contain any node signatures.
    #[error("Query response did not contain any node signatures")]
    MissingSignature,

    /// The query response contained a malformed signature.
    #[error("Query response contained a malformed signature")]
    MalformedSignature,

    /// The read-state response contained a malformed public key.
    #[error("Read state response contained a malformed public key")]
    MalformedPublicKey,

    /// The query response contained more node signatures than the subnet has nodes.
    #[error("Query response contained too many signatures ({had}, exceeding the subnet's total nodes: {needed})")]
    TooManySignatures {
        /// The number of provided signatures.
        had: usize,
        /// The number of nodes on the subnet.
        needed: usize,
    },

    /// There was a length mismatch between the expected and actual length of the BLS DER-encoded public key.
    #[error(
        r#"BLS DER-encoded public key must be ${expected} bytes long, but is {actual} bytes long."#
    )]
    DerKeyLengthMismatch {
        /// The expected length of the key.
        expected: usize,
        /// The actual length of the key.
        actual: usize,
    },

    /// There was a mismatch between the expected and actual prefix of the BLS DER-encoded public key.
    #[error("BLS DER-encoded public key is invalid. Expected the following prefix: ${expected:?}, but got ${actual:?}")]
    DerPrefixMismatch {
        /// The expected key prefix.
        expected: Vec<u8>,
        /// The actual key prefix.
        actual: Vec<u8>,
    },

    /// The status response did not contain a root key.
    #[error("The status response did not contain a root key.  Status: {0}")]
    NoRootKeyInStatus(Status),

    /// The invocation to the wallet call forward method failed with an error.
    #[error("The invocation to the wallet call forward method failed with the error: {0}")]
    WalletCallFailed(String),

    /// The wallet operation failed.
    #[error("The  wallet operation failed: {0}")]
    WalletError(String),

    /// The wallet canister must be upgraded. See [`dfx wallet upgrade`](https://internetcomputer.org/docs/current/references/cli-reference/dfx-wallet)
    #[error("The wallet canister must be upgraded: {0}")]
    WalletUpgradeRequired(String),

    /// The response size exceeded the provided limit.
    #[error("Response size exceeded limit.")]
    ResponseSizeExceededLimit(),

    /// An unknown error occurred during communication with the replica.
    #[error("An error happened during communication with the replica: {0}")]
    TransportError(TransportError),

    /// There was a mismatch between the expected and actual CBOR data during inspection.
    #[error("There is a mismatch between the CBOR encoded call and the arguments: field {field}, value in argument is {value_arg}, value in CBOR is {value_cbor}")]
    CallDataMismatch {
        /// The field that was mismatched.
        field: String,
        /// The value that was expected to be in the CBOR.
        value_arg: String,
        /// The value that was actually in the CBOR.
        value_cbor: String,
    },

    /// The rejected call had an invalid reject code (valid range 1..5).
    #[error(transparent)]
    InvalidRejectCode(#[from] InvalidRejectCodeError),

    /// Route provider failed to generate a url for some reason.
    #[error("Route provider failed to generate url: {0}")]
    RouteProviderError(String),

    /// Invalid HTTP response.
    #[error("Invalid HTTP response: {0}")]
    InvalidHttpResponse(String),
}

impl PartialEq for AgentError {
    fn eq(&self, other: &Self) -> bool {
        // Verify the debug string is the same. Some of the subtypes of this error
        // don't implement Eq or PartialEq, so we cannot rely on derive.
        format!("{self:?}") == format!("{other:?}")
    }
}

impl From<candid::Error> for AgentError {
    fn from(e: candid::Error) -> AgentError {
        AgentError::CandidError(e.into())
    }
}

/// A HTTP error from the replica.
pub struct HttpErrorPayload {
    /// The HTTP status code.
    pub status: u16,
    /// The MIME type of `content`.
    pub content_type: Option<String>,
    /// The body of the error.
    pub content: Vec<u8>,
}

impl HttpErrorPayload {
    fn fmt_human_readable(&self, f: &mut Formatter<'_>) -> Result<(), std::fmt::Error> {
        // No matter content_type is TEXT or not,
        // always try to parse it as a String.
        // When fail, print the raw byte array
        f.write_fmt(format_args!(
            "Http Error: status {}, content type {:?}, content: {}",
            http::StatusCode::from_u16(self.status)
                .map_or_else(|_| format!("{}", self.status), |code| format!("{code}")),
            self.content_type.clone().unwrap_or_default(),
            String::from_utf8(self.content.clone()).unwrap_or_else(|_| format!(
                "(unable to decode content as UTF-8: {:?})",
                self.content
            ))
        ))?;
        Ok(())
    }
}

impl Debug for HttpErrorPayload {
    fn fmt(&self, f: &mut Formatter<'_>) -> Result<(), std::fmt::Error> {
        self.fmt_human_readable(f)
    }
}

impl Display for HttpErrorPayload {
    fn fmt(&self, f: &mut Formatter<'_>) -> Result<(), std::fmt::Error> {
        self.fmt_human_readable(f)
    }
}

/// An operation that can result in a reject.
#[derive(Debug, Clone, Eq, PartialEq)]
pub enum Operation {
    /// A call to a canister method.
    Call {
        /// The canister whose method was called.
        canister: Principal,
        /// The name of the method.
        method: String,
    },
    /// A read of the state tree, in the context of a canister. This will *not* be returned for request polling.
    ReadState {
        /// The requested paths within the state tree.
        paths: Vec<Vec<String>>,
        /// The canister the read request was made in the context of.
        canister: Principal,
    },
    /// A read of the state tree, in the context of a subnet.
    ReadSubnetState {
        /// The requested paths within the state tree.
        paths: Vec<Vec<String>>,
        /// The subnet the read request was made in the context of.
        subnet: Principal,
    },
}

#[cfg(test)]
mod tests {
    use super::HttpErrorPayload;
    use crate::AgentError;

    #[test]
    fn content_type_none_valid_utf8() {
        let payload = HttpErrorPayload {
            status: 420,
            content_type: None,
            content: vec![104, 101, 108, 108, 111],
        };

        assert_eq!(
            format!("{}", AgentError::HttpError(payload)),
            r#"The replica returned an HTTP Error: Http Error: status 420 <unknown status code>, content type "", content: hello"#,
        );
    }

    #[test]
    fn content_type_none_invalid_utf8() {
        let payload = HttpErrorPayload {
            status: 420,
            content_type: None,
            content: vec![195, 40],
        };

        assert_eq!(
            format!("{}", AgentError::HttpError(payload)),
            r#"The replica returned an HTTP Error: Http Error: status 420 <unknown status code>, content type "", content: (unable to decode content as UTF-8: [195, 40])"#,
        );
    }

    #[test]
    fn formats_text_plain() {
        let payload = HttpErrorPayload {
            status: 420,
            content_type: Some("text/plain".to_string()),
            content: vec![104, 101, 108, 108, 111],
        };

        assert_eq!(
            format!("{}", AgentError::HttpError(payload)),
            r#"The replica returned an HTTP Error: Http Error: status 420 <unknown status code>, content type "text/plain", content: hello"#,
        );
    }

    #[test]
    fn formats_text_plain_charset_utf8() {
        let payload = HttpErrorPayload {
            status: 420,
            content_type: Some("text/plain; charset=utf-8".to_string()),
            content: vec![104, 101, 108, 108, 111],
        };

        assert_eq!(
            format!("{}", AgentError::HttpError(payload)),
            r#"The replica returned an HTTP Error: Http Error: status 420 <unknown status code>, content type "text/plain; charset=utf-8", content: hello"#,
        );
    }

    #[test]
    fn formats_text_html() {
        let payload = HttpErrorPayload {
            status: 420,
            content_type: Some("text/html".to_string()),
            content: vec![119, 111, 114, 108, 100],
        };

        assert_eq!(
            format!("{}", AgentError::HttpError(payload)),
            r#"The replica returned an HTTP Error: Http Error: status 420 <unknown status code>, content type "text/html", content: world"#,
        );
    }
}



================================================
FILE: ic-agent/src/agent/agent_test.rs
================================================
use self::mock::{
    assert_mock, assert_single_mock, assert_single_mock_count, mock, mock_additional,
};
use crate::{agent::Status, export::Principal, Agent, AgentError, Certificate};
use candid::{Encode, Nat};
use futures_util::FutureExt;
use ic_certification::{Delegation, Label};
use ic_transport_types::{
    NodeSignature, QueryResponse, RejectCode, RejectResponse, ReplyResponse, TransportCallResponse,
};
use std::{collections::BTreeMap, str::FromStr, sync::Arc, time::Duration};
#[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
use wasm_bindgen_test::wasm_bindgen_test;

use crate::agent::route_provider::{RoundRobinRouteProvider, RouteProvider};
#[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
wasm_bindgen_test::wasm_bindgen_test_configure!(run_in_browser);

fn make_agent(url: &str) -> Agent {
    let builder = Agent::builder().with_url(url);
    builder.with_verify_query_signatures(false).build().unwrap()
}

fn make_agent_with_route_provider(
    route_provider: Arc<dyn RouteProvider>,
    tcp_retries: usize,
) -> Agent {
    Agent::builder()
        .with_arc_route_provider(route_provider)
        .with_max_tcp_error_retries(tcp_retries)
        .with_verify_query_signatures(false)
        .build()
        .unwrap()
}

fn make_untimed_agent(url: &str) -> Agent {
    Agent::builder()
        .with_url(url)
        .with_verify_query_signatures(false)
        .with_ingress_expiry(Duration::from_secs(u32::MAX.into()))
        .build()
        .unwrap()
}

fn make_certifying_agent(url: &str) -> Agent {
    Agent::builder()
        .with_url(url)
        .with_ingress_expiry(Duration::from_secs(u32::MAX.into()))
        .build()
        .unwrap()
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn query() -> Result<(), AgentError> {
    let blob = Vec::from("Hello World");
    let response = QueryResponse::Replied {
        reply: ReplyResponse { arg: blob.clone() },
        signatures: vec![],
    };

    let (query_mock, url) = mock(
        "POST",
        "/api/v2/canister/aaaaa-aa/query",
        200,
        serde_cbor::to_vec(&response)?,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);
    let result = agent
        .query_raw(
            Principal::management_canister(),
            Principal::management_canister(),
            "main".to_string(),
            vec![],
            None,
            false,
            None,
        )
        .await;

    assert_mock(query_mock).await;

    assert_eq!(result?, blob);

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn query_error() -> Result<(), AgentError> {
    let (query_mock, url) =
        mock("POST", "/api/v2/canister/aaaaa-aa/query", 500, vec![], None).await;
    let agent = make_agent(&url);

    let result = agent
        .query_raw(
            Principal::management_canister(),
            Principal::management_canister(),
            "greet".to_string(),
            vec![],
            None,
            false,
            None,
        )
        .await;

    assert_mock(query_mock).await;

    assert!(result.is_err());

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn query_rejected() -> Result<(), AgentError> {
    let response: QueryResponse = QueryResponse::Rejected {
        reject: RejectResponse {
            reject_code: RejectCode::DestinationInvalid,
            reject_message: "Rejected Message".to_string(),
            error_code: Some("Error code".to_string()),
        },
        signatures: vec![],
    };

    let (query_mock, url) = mock(
        "POST",
        "/api/v2/canister/aaaaa-aa/query",
        200,
        serde_cbor::to_vec(&response)?,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);

    let result = agent
        .query_raw(
            Principal::management_canister(),
            Principal::management_canister(),
            "greet".to_string(),
            vec![],
            None,
            false,
            None,
        )
        .await;

    assert_mock(query_mock).await;

    match result {
        Err(AgentError::UncertifiedReject {
            reject: replica_error,
            ..
        }) => {
            assert_eq!(replica_error.reject_code, RejectCode::DestinationInvalid);
            assert_eq!(replica_error.reject_message, "Rejected Message");
            assert_eq!(replica_error.error_code, Some("Error code".to_string()));
        }
        result => unreachable!("{:?}", result),
    }

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn call_error() -> Result<(), AgentError> {
    let (call_mock, url) = mock("POST", "/api/v3/canister/aaaaa-aa/call", 500, vec![], None).await;

    let agent = make_agent(&url);

    let result = agent
        .update(&Principal::management_canister(), "greet")
        .with_arg([])
        .call()
        .await;

    assert_mock(call_mock).await;

    assert!(result.is_err());

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn call_rejected() -> Result<(), AgentError> {
    let reject_response = RejectResponse {
        reject_code: RejectCode::SysTransient,
        reject_message: "Test reject message".to_string(),
        error_code: Some("Test error code".to_string()),
    };

    let reject_body = TransportCallResponse::NonReplicatedRejection(reject_response.clone());

    let body = serde_cbor::to_vec(&reject_body).unwrap();

    let (call_mock, url) = mock(
        "POST",
        "/api/v3/canister/aaaaa-aa/call",
        200,
        body,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);

    let result = agent
        .update(&Principal::management_canister(), "greet")
        .with_arg([])
        .call()
        .await;

    assert_mock(call_mock).await;

    assert!(
        matches!(result, Err(AgentError::UncertifiedReject { reject, .. }) if reject == reject_response)
    );

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn call_rejected_without_error_code() -> Result<(), AgentError> {
    let non_replicated_reject = RejectResponse {
        reject_code: RejectCode::SysTransient,
        reject_message: "Test reject message".to_string(),
        error_code: None,
    };

    let reject_body = TransportCallResponse::NonReplicatedRejection(non_replicated_reject.clone());

    let canister_id_str = "aaaaa-aa";

    let body = serde_cbor::to_vec(&reject_body).unwrap();

    let (call_mock, url) = mock(
        "POST",
        format!("/api/v3/canister/{canister_id_str}/call").as_str(),
        200,
        body,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);

    let result = agent
        .update(&Principal::from_str(canister_id_str).unwrap(), "greet")
        .with_arg([])
        .call()
        .await;

    assert_mock(call_mock).await;

    assert!(
        matches!(result, Err(AgentError::UncertifiedReject { reject, .. }) if reject == non_replicated_reject)
    );

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn status() -> Result<(), AgentError> {
    let map = BTreeMap::new();
    let response = serde_cbor::Value::Map(map);
    let (read_mock, url) = mock(
        "GET",
        "/api/v2/status",
        200,
        serde_cbor::to_vec(&response)?,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);
    let result = agent.status().await;

    assert_mock(read_mock).await;
    assert!(matches!(result, Ok(Status { .. })));

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn status_okay() -> Result<(), AgentError> {
    let map = BTreeMap::new();
    let response = serde_cbor::Value::Map(map);
    let (read_mock, url) = mock(
        "GET",
        "/api/v2/status",
        200,
        serde_cbor::to_vec(&response)?,
        Some("application/cbor"),
    )
    .await;

    let agent = make_agent(&url);
    let result = agent.status().await;

    assert_mock(read_mock).await;

    assert!(result.is_ok());

    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
async fn reqwest_client_status_okay_when_request_retried() -> Result<(), AgentError> {
    let map = BTreeMap::new();
    let response = serde_cbor::Value::Map(map);
    let (read_mock, url) = mock(
        "GET",
        "/api/v2/status",
        200,
        serde_cbor::to_vec(&response)?,
        Some("application/cbor"),
    )
    .await;
    // Without retry request should fail.
    let non_working_url = "http://127.0.0.1:4444";
    let tcp_retries = 0;
    let route_provider = RoundRobinRouteProvider::new(vec![non_working_url, &url]).unwrap();
    let agent = make_agent_with_route_provider(Arc::new(route_provider), tcp_retries);
    let result = agent.status().await;
    assert!(result.is_err());

    // With retry request should succeed.
    let tcp_retries = 1;
    let route_provider = RoundRobinRouteProvider::new(vec![non_working_url, &url]).unwrap();
    let agent = make_agent_with_route_provider(Arc::new(route_provider), tcp_retries);
    let result = agent.status().await;

    assert_mock(read_mock).await;

    assert!(result.is_ok());
    Ok(())
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
// test that the agent (re)tries to reach the server.
// We spawn an agent that waits 400ms between requests, and times out after 600ms. The agent is
// expected to hit the server at ~ 0ms and ~ 400 ms, and then shut down at 600ms, so we check that
// the server got two requests.
async fn status_error() -> Result<(), AgentError> {
    // This mock is never asserted as we don't know (nor do we need to know) how many times
    // it is called.
    let (_read_mock, url) = mock("GET", "/api/v2/status", 500, vec![], None).await;

    let agent = make_agent(&url);
    let result = agent.status().await;

    assert!(result.is_err());

    Ok(())
}

// these values for canister, paths, and mock_response are captured from a real request to mainnet
// the response amounts to "method not found"
// we don't really care about the response since we're just testing the cert verification
const REQ_WITH_DELEGATED_CERT_PATH: [&str; 2] = [
    "726571756573745F737461747573",
    "92F03ABDDC774EE97882320CF15F2029A868FFCFE3BE48FEF84FC97B5A13E04A",
];
const REQ_WITH_DELEGATED_CERT_CANISTER: &str = "ivg37-qiaaa-aaaab-aaaga-cai";
const REQ_WITH_DELEGATED_CERT_RESPONSE: &[u8] =
    include_bytes!("agent_test/req_with_delegated_cert_response.bin");

// this is the same response as REQ_WITH_DELEGATED_CERT_RESPONSE, but with a manually pruned
// /subnet/<subnetid>/canister_ranges field
const PRUNED_SUBNET: &[u8] = include_bytes!("agent_test/pruned_subnet.bin");

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
// asserts that a delegated certificate with correct /subnet/<subnetid>/canister_ranges
// passes the certificate verification
async fn check_subnet_range_with_valid_range() {
    let (_read_mock, url) = mock(
        "POST",
        "/api/v2/canister/ivg37-qiaaa-aaaab-aaaga-cai/read_state",
        200,
        REQ_WITH_DELEGATED_CERT_RESPONSE.into(),
        Some("application/cbor"),
    )
    .await;
    let agent = make_untimed_agent(&url);
    let _result = agent
        .read_state_raw(
            vec![REQ_WITH_DELEGATED_CERT_PATH
                .into_iter()
                .map(Label::from)
                .collect()],
            Principal::from_text(REQ_WITH_DELEGATED_CERT_CANISTER).unwrap(),
        )
        .await
        .expect("read state failed");
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
// asserts that a delegated certificate with /subnet/<subnetid>/canister_ranges that don't include
// the canister gets rejected by the cert verification because the subnet is not authorized to
// respond to requests for this canister. We do this by using a correct response but serving it
// for the wrong canister, which a malicious node might do.
async fn check_subnet_range_with_unauthorized_range() {
    let wrong_canister = Principal::from_text("ryjl3-tyaaa-aaaaa-aaaba-cai").unwrap();
    let (_read_mock, url) = mock(
        "POST",
        "/api/v2/canister/ryjl3-tyaaa-aaaaa-aaaba-cai/read_state",
        200,
        REQ_WITH_DELEGATED_CERT_RESPONSE.into(),
        Some("application/cbor"),
    )
    .await;
    let agent = make_untimed_agent(&url);
    let result = agent
        .read_state_raw(
            vec![REQ_WITH_DELEGATED_CERT_PATH
                .into_iter()
                .map(Label::from)
                .collect()],
            wrong_canister,
        )
        .await;
    assert_eq!(result, Err(AgentError::CertificateNotAuthorized()));
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
// asserts that a delegated certificate with pruned/removed /subnet/<subnetid>/canister_ranges
// gets rejected by the cert verification. We do this by using a correct response that has
// the leaf manually pruned
async fn check_subnet_range_with_pruned_range() {
    let canister = Principal::from_text("ivg37-qiaaa-aaaab-aaaga-cai").unwrap();
    let (_read_mock, url) = mock(
        "POST",
        "/api/v2/canister/ivg37-qiaaa-aaaab-aaaga-cai/read_state",
        200,
        PRUNED_SUBNET.into(),
        Some("application/cbor"),
    )
    .await;
    let agent = make_untimed_agent(&url);
    let result = agent
        .read_state_raw(
            vec![REQ_WITH_DELEGATED_CERT_PATH
                .into_iter()
                .map(Label::from)
                .collect()],
            canister,
        )
        .await;
    assert!(result.is_err());
}

const WRONG_SUBNET_CERT: &[u8] = include_bytes!("agent_test/wrong_subnet.bin");

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn wrong_subnet_query_certificate() {
    let canister = Principal::from_text("224od-giaaa-aaaao-ae5vq-cai").unwrap();
    let (mut read_mock, url) = mock(
        "POST",
        "/api/v2/canister/224od-giaaa-aaaao-ae5vq-cai/read_state",
        200,
        WRONG_SUBNET_CERT.into(),
        Some("application/cbor"),
    )
    .await;
    let blob = Encode!(&Nat::from(12u8)).unwrap();
    let response = QueryResponse::Replied {
        reply: ReplyResponse { arg: blob.clone() },
        signatures: vec![NodeSignature {
            timestamp: 1_697_831_349_698_624_964,
            signature: hex::decode("4bb6ba316623395d56d8e2834ece39d2c81d47e76a9fd122e1457963be6a83a5589e2c98c7b4d8b3c6c7b11c74b8ce9dcb345b5d1bd91706a643f33c7b509b0b").unwrap(),
            identity: "oo4np-rrvnz-5vram-kglex-enhkp-uew6q-vdf6z-whj4x-v44jd-tebaw-nqe".parse().unwrap()
        }],
    };
    mock_additional(
        &mut read_mock,
        "POST",
        "/api/v2/canister/224od-giaaa-aaaao-ae5vq-cai/query",
        200,
        serde_cbor::to_vec(&response).unwrap(),
        Some("application/cbor"),
    )
    .await;
    let agent = make_certifying_agent(&url);
    let result = agent.query(&canister, "getVersion").call().await;
    assert!(matches!(
        result.unwrap_err(),
        AgentError::CertificateNotAuthorized()
    ));
    assert_single_mock(
        "POST",
        "/api/v2/canister/224od-giaaa-aaaao-ae5vq-cai/read_state",
        &read_mock,
    )
    .await;
}

const GOOD_SUBNET_KEYS: &[u8] = include_bytes!("agent_test/subnet_keys.bin");

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn no_cert() {
    let canister = Principal::from_text("224od-giaaa-aaaao-ae5vq-cai").unwrap();
    let (mut read_mock, url) = mock(
        "POST",
        "/api/v2/canister/224od-giaaa-aaaao-ae5vq-cai/read_state",
        200,
        GOOD_SUBNET_KEYS.into(),
        Some("application/cbor"),
    )
    .await;
    let blob = Encode!(&Nat::from(12u8)).unwrap();
    let response = QueryResponse::Replied {
        reply: ReplyResponse { arg: blob.clone() },
        signatures: vec![],
    };
    mock_additional(
        &mut read_mock,
        "POST",
        "/api/v2/canister/224od-giaaa-aaaao-ae5vq-cai/query",
        200,
        serde_cbor::to_vec(&response).unwrap(),
        Some("application/cbor"),
    )
    .await;
    let agent = make_certifying_agent(&url);
    let result = agent.query(&canister, "getVersion").call().await;
    assert!(matches!(result.unwrap_err(), AgentError::MissingSignature));
    assert_mock(read_mock).await;
}

const RESP_WITH_SUBNET_KEY: &[u8] = include_bytes!("agent_test/with_subnet_key.bin");

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn too_many_delegations() {
    // Use the certificate as its own delegation, and repeat the process the specified number of times
    fn self_delegate_cert(subnet_id: &[u8], cert: &Certificate, depth: u32) -> Certificate {
        let mut current = cert.clone();
        for _ in 0..depth {
            current = Certificate {
                tree: current.tree.clone(),
                signature: current.signature.clone(),
                delegation: Some(Delegation {
                    subnet_id: subnet_id.to_vec(),
                    certificate: serde_cbor::to_vec(&current).unwrap(),
                }),
            }
        }
        current
    }

    let canister_id_str = "rdmx6-jaaaa-aaaaa-aaadq-cai";
    let canister_id = Principal::from_text(canister_id_str).unwrap();
    let subnet_id = Vec::from(
        Principal::from_text("uzr34-akd3s-xrdag-3ql62-ocgoh-ld2ao-tamcv-54e7j-krwgb-2gm4z-oqe")
            .unwrap()
            .as_slice(),
    );

    let (_read_mock, url) = mock(
        "POST",
        format!("/api/v2/canister/{canister_id_str}/read_state").as_str(),
        200,
        RESP_WITH_SUBNET_KEY.into(),
        Some("application/cbor"),
    )
    .await;
    let path_label = Label::from_bytes("subnet".as_bytes());
    let agent = make_untimed_agent(&url);
    let cert = agent
        .read_state_raw(vec![vec![path_label]], canister_id)
        .await
        .expect("read state failed");
    let new_cert = self_delegate_cert(&subnet_id, &cert, 1);
    assert!(matches!(
        agent.verify(&new_cert, canister_id).unwrap_err(),
        AgentError::CertificateHasTooManyDelegations
    ));
}

#[cfg_attr(not(target_family = "wasm"), tokio::test)]
#[cfg_attr(target_family = "wasm", wasm_bindgen_test)]
async fn retry_ratelimit() {
    let (mut mock, url) = mock(
        "POST",
        "/api/v2/canister/ryjl3-tyaaa-aaaaa-aaaba-cai/query",
        429,
        vec![],
        Some("text/plain"),
    )
    .await;
    let agent = make_agent(&url);
    futures_util::select! {
        _ = agent.query(&"ryjl3-tyaaa-aaaaa-aaaba-cai".parse().unwrap(), "greet").call().fuse() => panic!("did not retry 429"),
        _ = crate::util::sleep(Duration::from_millis(500)).fuse() => {},
    };
    assert_single_mock_count(
        "POST",
        "/api/v2/canister/ryjl3-tyaaa-aaaaa-aaaba-cai/query",
        2,
        &mut mock,
    )
    .await;
}

#[cfg(not(target_family = "wasm"))]
mod mock {

    use std::collections::HashMap;

    use mockito::{Mock, Server, ServerGuard};

    pub async fn mock(
        method: &str,
        path: &str,
        status_code: u16,
        body: Vec<u8>,
        content_type: Option<&str>,
    ) -> ((ServerGuard, HashMap<String, Mock>), String) {
        let mut server = Server::new_async().await;
        let mut mock = server
            .mock(method, path)
            .with_status(status_code as _)
            .with_body(body);
        if let Some(content_type) = content_type {
            mock = mock.with_header("Content-Type", content_type);
        }
        let mock = mock.create_async().await;
        let url = server.url();
        (
            (server, HashMap::from([(format!("{method} {path}"), mock)])),
            url,
        )
    }

    pub async fn mock_additional(
        orig: &mut (ServerGuard, HashMap<String, Mock>),
        method: &str,
        path: &str,
        status_code: u16,
        body: Vec<u8>,
        content_type: Option<&str>,
    ) {
        let mut mock = orig
            .0
            .mock(method, path)
            .with_status(status_code as _)
            .with_body(body);
        if let Some(content_type) = content_type {
            mock = mock.with_header("Content-Type", content_type);
        }
        orig.1
            .insert(format!("{method} {path}"), mock.create_async().await);
    }

    pub async fn assert_mock((_, mocks): (ServerGuard, HashMap<String, Mock>)) {
        for mock in mocks.values() {
            mock.assert_async().await;
        }
    }

    pub async fn assert_single_mock(
        method: &str,
        path: &str,
        (_, mocks): &(ServerGuard, HashMap<String, Mock>),
    ) {
        mocks[&format!("{method} {path}")].assert_async().await;
    }

    pub async fn assert_single_mock_count(
        method: &str,
        path: &str,
        n: usize,
        (_, mocks): &mut (ServerGuard, HashMap<String, Mock>),
    ) {
        let k = format!("{method} {path}");
        let mut mock = mocks.remove(&k).unwrap();
        mock = mock.expect_at_least(n);
        mock.assert_async().await;
        mocks.insert(k, mock);
    }
}

#[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
mod mock {
    use js_sys::*;
    use reqwest::Client;
    use serde::Serialize;
    use std::collections::HashMap;
    use wasm_bindgen::{prelude::*, JsCast};
    use wasm_bindgen_futures::JsFuture;
    use web_sys::*;

    #[wasm_bindgen(module = "/http_mock_service_worker.js")]
    extern "C" {}

    #[derive(Debug, Serialize)]
    struct MockConfig {
        pub kind: String,
        pub method: String,
        pub path: String,
        pub status_code: u16,
        pub headers: Option<HashMap<String, String>>,
        pub body: Vec<u8>,
    }

    pub async fn mock(
        method: &str,
        path: &str,
        status_code: u16,
        body: Vec<u8>,
        content_type: Option<&str>,
    ) -> (String, String) {
        let swc = window().unwrap().navigator().service_worker();
        let registration: ServiceWorkerRegistration =
            JsFuture::from(swc.register("/http_mock_service_worker.js"))
                .await
                .unwrap()
                .unchecked_into();
        JsFuture::from(swc.ready().unwrap()).await.unwrap();
        let sw = registration.active().unwrap();
        let mut nonce = [0; 16];
        getrandom::getrandom(&mut nonce).unwrap();
        let nonce = hex::encode(nonce);
        let config = MockConfig {
            kind: "config".into(),
            method: method.into(),
            path: path.into(),
            status_code,
            body,
            headers: content_type.map(|c| HashMap::from([("Content-Type".into(), c.into())])),
        };
        if sw.state() == ServiceWorkerState::Activating {
            JsFuture::from(Promise::new(&mut |rs, _| sw.set_onstatechange(Some(&rs))))
                .await
                .unwrap();
        }
        Client::new()
            .post(&format!("http://mock_configure/{nonce}"))
            .json(&config)
            .send()
            .await
            .unwrap()
            .error_for_status()
            .unwrap();
        (nonce.clone(), format!("http://mock_{}/", nonce))
    }

    pub async fn mock_additional(
        orig: &mut String,
        method: &str,
        path: &str,
        status_code: u16,
        body: Vec<u8>,
        content_type: Option<&str>,
    ) {
        let config = MockConfig {
            kind: "config".into(),
            method: method.into(),
            path: path.into(),
            status_code,
            body,
            headers: content_type.map(|c| HashMap::from([("Content-Type".into(), c.into())])),
        };
        Client::new()
            .post(&format!("http://mock_configure/{orig}"))
            .json(&config)
            .send()
            .await
            .unwrap()
            .error_for_status()
            .unwrap();
    }

    async fn get_hits(nonce: &str) -> HashMap<String, i64> {
        Client::new()
            .get(&format!("http://mock_assert/{}", nonce))
            .send()
            .await
            .unwrap()
            .error_for_status()
            .unwrap()
            .json()
            .await
            .unwrap()
    }

    pub async fn assert_mock(nonce: String) {
        let hits = get_hits(&nonce).await;
        assert!(hits.values().all(|x| *x > 0));
    }

    pub async fn assert_single_mock(method: &str, path: &str, nonce: &String) {
        let hits = get_hits(nonce).await;
        assert!(hits[&format!("{method} {path}")] > 0);
    }

    pub async fn assert_single_mock_count(method: &str, path: &str, n: usize, nonce: &mut String) {
        let hits = get_hits(&*nonce).await;
        assert!(hits[&format!("{method} {path}")] >= n as i64);
    }
}



================================================
FILE: ic-agent/src/agent/builder.rs
================================================
use crate::{
    agent::{agent_config::AgentConfig, Agent},
    AgentError, Identity, NonceFactory, NonceGenerator,
};
use std::sync::Arc;

use super::{route_provider::RouteProvider, HttpService};

/// A builder for an [`Agent`].
#[derive(Default)]
pub struct AgentBuilder {
    config: AgentConfig,
}

impl AgentBuilder {
    /// Create an instance of [Agent] with the information from this builder.
    pub fn build(self) -> Result<Agent, AgentError> {
        Agent::new(self.config)
    }

    /// Set the dynamic transport layer for the [`Agent`], performing continuous discovery of the API boundary nodes
    /// and routing traffic via them based on latency. Cannot be set together with `with_route_provider`.
    ///
    /// See [`DynamicRouteProvider`](super::route_provider::DynamicRouteProvider) if more customization is needed such as polling intervals.
    pub fn with_background_dynamic_routing(mut self) -> Self {
        assert!(
            self.config.route_provider.is_none(),
            "with_background_dynamic_routing cannot be called with with_route_provider"
        );
        self.config.background_dynamic_routing = true;
        self
    }

    /// Set the URL of the [`Agent`]. Either this or `with_route_provider` must be called (but not both).
    pub fn with_url<S: Into<String>>(mut self, url: S) -> Self {
        assert!(
            self.config.route_provider.is_none(),
            "with_url cannot be called with with_route_provider"
        );
        self.config.url = Some(url.into().parse().unwrap());
        self
    }

    /// Add a `NonceFactory` to this Agent. By default, no nonce is produced.
    pub fn with_nonce_factory(self, nonce_factory: NonceFactory) -> AgentBuilder {
        self.with_nonce_generator(nonce_factory)
    }

    /// Same as [`Self::with_nonce_factory`], but for any `NonceGenerator` type
    pub fn with_nonce_generator<N: 'static + NonceGenerator>(
        self,
        nonce_factory: N,
    ) -> AgentBuilder {
        self.with_arc_nonce_generator(Arc::new(nonce_factory))
    }

    /// Same as [`Self::with_nonce_generator`], but reuses an existing `Arc`.
    pub fn with_arc_nonce_generator(
        mut self,
        nonce_factory: Arc<dyn NonceGenerator>,
    ) -> AgentBuilder {
        self.config.nonce_factory = Arc::new(nonce_factory);
        self
    }

    /// Add an identity provider for signing messages. This is required.
    pub fn with_identity<I>(self, identity: I) -> Self
    where
        I: 'static + Identity,
    {
        self.with_arc_identity(Arc::new(identity))
    }

    /// Same as [`Self::with_identity`], but reuses an existing box
    pub fn with_boxed_identity(self, identity: Box<dyn Identity>) -> Self {
        self.with_arc_identity(Arc::from(identity))
    }

    /// Same as [`Self::with_identity`], but reuses an existing `Arc`
    pub fn with_arc_identity(mut self, identity: Arc<dyn Identity>) -> Self {
        self.config.identity = identity;
        self
    }

    /// Provides a _default_ ingress expiry. This is the delta that will be applied
    /// at the time an update or query is made. The default expiry cannot be a
    /// fixed system time. This is also used when checking certificate timestamps.
    ///
    /// The timestamp corresponding to this duration may be rounded in order to reduce
    /// cache misses. The current implementation rounds to the nearest minute if the
    /// expiry is more than a minute, but this is not guaranteed.
    pub fn with_ingress_expiry(mut self, ingress_expiry: std::time::Duration) -> Self {
        self.config.ingress_expiry = ingress_expiry;
        self
    }

    /// Allows disabling query signature verification. Query signatures improve resilience but require
    /// a separate read-state call to fetch node keys.
    pub fn with_verify_query_signatures(mut self, verify_query_signatures: bool) -> Self {
        self.config.verify_query_signatures = verify_query_signatures;
        self
    }

    /// Sets the maximum number of requests that the agent will make concurrently. The replica is configured
    /// to only permit 50 concurrent requests per client. Set this value lower if you have multiple agents,
    /// to avoid the slowdown of retrying any 429 errors.
    pub fn with_max_concurrent_requests(mut self, max_concurrent_requests: usize) -> Self {
        self.config.max_concurrent_requests = max_concurrent_requests;
        self
    }

    /// Add a `RouteProvider` to this agent, to provide the URLs of boundary nodes.
    pub fn with_route_provider(self, provider: impl RouteProvider + 'static) -> Self {
        self.with_arc_route_provider(Arc::new(provider))
    }

    /// Same as [`Self::with_route_provider`], but reuses an existing `Arc`.
    pub fn with_arc_route_provider(mut self, provider: Arc<dyn RouteProvider>) -> Self {
        assert!(
            !self.config.background_dynamic_routing,
            "with_background_dynamic_routing cannot be called with with_route_provider"
        );
        assert!(
            self.config.url.is_none(),
            "with_url cannot be called with with_route_provider"
        );
        self.config.route_provider = Some(provider);
        self
    }

    /// Provide a pre-configured HTTP client to use. Use this to set e.g. HTTP timeouts or proxy configuration.
    pub fn with_http_client(mut self, client: reqwest::Client) -> Self {
        assert!(
            self.config.http_service.is_none(),
            "with_arc_http_middleware cannot be called with with_http_client"
        );
        self.config.client = Some(client);
        self
    }

    /// Provide a custom `reqwest`-compatible HTTP service, e.g. to add per-request headers for custom boundary nodes.
    /// Most users will not need this and should use `with_http_client`. Cannot be called with `with_http_client`.
    ///
    /// The trait is automatically implemented for any `tower::Service` impl matching the one `reqwest::Client` uses,
    /// including `reqwest-middleware`. This is a low-level interface, and direct implementations must provide all automatic retry logic.
    pub fn with_arc_http_middleware(mut self, service: Arc<dyn HttpService>) -> Self {
        assert!(
            self.config.client.is_none(),
            "with_arc_http_middleware cannot be called with with_http_client"
        );
        self.config.http_service = Some(service);
        self
    }

    /// Retry up to the specified number of times upon encountering underlying TCP errors.
    pub fn with_max_tcp_error_retries(mut self, retries: usize) -> Self {
        self.config.max_tcp_error_retries = retries;
        self
    }

    /// Don't accept HTTP bodies any larger than `max_size` bytes.
    pub fn with_max_response_body_size(mut self, max_size: usize) -> Self {
        self.config.max_response_body_size = Some(max_size);
        self
    }
    /// Set the maximum time to wait for a response from the replica.
    pub fn with_max_polling_time(mut self, max_polling_time: std::time::Duration) -> Self {
        self.config.max_polling_time = max_polling_time;
        self
    }
}



================================================
FILE: ic-agent/src/agent/nonce.rs
================================================
use rand::{rngs::OsRng, Rng};
use std::sync::{
    atomic::{AtomicU64, Ordering},
    Arc, Mutex,
};

/// A Factory for nonce blobs.
#[derive(Clone)]
pub struct NonceFactory {
    inner: Arc<dyn NonceGenerator>,
}

impl NonceFactory {
    /// Creates a nonce factory from an iterator over blobs. The iterator is not assumed to be fused.
    pub fn from_iterator(iter: Box<dyn Iterator<Item = Vec<u8>> + Send>) -> Self {
        Self {
            inner: Arc::new(Iter::from(iter)),
        }
    }

    /// Creates a nonce factory that generates random blobs using `getrandom`.
    pub fn random() -> NonceFactory {
        Self {
            inner: Arc::new(RandomBlob {}),
        }
    }

    /// Creates a nonce factory that returns None every time.
    pub fn empty() -> NonceFactory {
        Self {
            inner: Arc::new(Empty),
        }
    }

    /// Creates a nonce factory that generates incrementing blobs.
    pub fn incrementing() -> NonceFactory {
        Self {
            inner: Arc::new(Incrementing::default()),
        }
    }

    /// Generates a nonce, if one is available. Otherwise, returns None.
    pub fn generate(&self) -> Option<Vec<u8>> {
        NonceGenerator::generate(self)
    }
}

impl NonceGenerator for NonceFactory {
    fn generate(&self) -> Option<Vec<u8>> {
        self.inner.generate()
    }
}

/// An interface for generating nonces.
pub trait NonceGenerator: Send + Sync {
    /// Generates a nonce, if one is available. Otherwise, returns None.
    fn generate(&self) -> Option<Vec<u8>>;
}

pub struct Func<T>(pub T);
impl<T: Send + Sync + Fn() -> Option<Vec<u8>>> NonceGenerator for Func<T> {
    fn generate(&self) -> Option<Vec<u8>> {
        (self.0)()
    }
}

pub struct Iter<T>(Mutex<T>);
impl<T: Send + Iterator<Item = Vec<u8>>> From<T> for Iter<T> {
    fn from(val: T) -> Iter<T> {
        Iter(Mutex::new(val))
    }
}
impl<T: Send + Iterator<Item = Vec<u8>>> NonceGenerator for Iter<T> {
    fn generate(&self) -> Option<Vec<u8>> {
        self.0.lock().unwrap().next()
    }
}

#[derive(Default)]
pub struct RandomBlob {}
impl NonceGenerator for RandomBlob {
    fn generate(&self) -> Option<Vec<u8>> {
        Some(OsRng.gen::<[u8; 16]>().to_vec())
    }
}

#[derive(Default)]
pub struct Empty;
impl NonceGenerator for Empty {
    fn generate(&self) -> Option<Vec<u8>> {
        None
    }
}

#[derive(Default)]
pub struct Incrementing {
    next: AtomicU64,
}
impl From<u64> for Incrementing {
    fn from(val: u64) -> Incrementing {
        Incrementing {
            next: AtomicU64::new(val),
        }
    }
}
impl NonceGenerator for Incrementing {
    fn generate(&self) -> Option<Vec<u8>> {
        let val = self.next.fetch_add(1, Ordering::Relaxed);
        Some(val.to_le_bytes().to_vec())
    }
}

impl<N: NonceGenerator + ?Sized> NonceGenerator for Box<N> {
    fn generate(&self) -> Option<Vec<u8>> {
        (**self).generate()
    }
}
impl<N: NonceGenerator + ?Sized> NonceGenerator for Arc<N> {
    fn generate(&self) -> Option<Vec<u8>> {
        (**self).generate()
    }
}



================================================
FILE: ic-agent/src/agent/response_authentication.rs
================================================
use crate::agent::{ApiBoundaryNode, RejectCode, RejectResponse, RequestStatusResponse};
use crate::{export::Principal, AgentError, RequestId};
use ic_certification::hash_tree::{HashTree, SubtreeLookupResult};
use ic_certification::{certificate::Certificate, hash_tree::Label, LookupResult};
use ic_transport_types::{ReplyResponse, SubnetMetrics};
use rangemap::RangeInclusiveSet;
use std::collections::{HashMap, HashSet};
use std::str::from_utf8;

use super::Subnet;

const DER_PREFIX: &[u8; 37] = b"\x30\x81\x82\x30\x1d\x06\x0d\x2b\x06\x01\x04\x01\x82\xdc\x7c\x05\x03\x01\x02\x01\x06\x0c\x2b\x06\x01\x04\x01\x82\xdc\x7c\x05\x03\x02\x01\x03\x61\x00";
const KEY_LENGTH: usize = 96;

pub fn extract_der(buf: Vec<u8>) -> Result<Vec<u8>, AgentError> {
    let expected_length = DER_PREFIX.len() + KEY_LENGTH;
    if buf.len() != expected_length {
        return Err(AgentError::DerKeyLengthMismatch {
            expected: expected_length,
            actual: buf.len(),
        });
    }

    let prefix = &buf[0..DER_PREFIX.len()];
    if prefix[..] != DER_PREFIX[..] {
        return Err(AgentError::DerPrefixMismatch {
            expected: DER_PREFIX.to_vec(),
            actual: prefix.to_vec(),
        });
    }

    let key = &buf[DER_PREFIX.len()..];
    Ok(key.to_vec())
}

pub(crate) fn lookup_time<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
) -> Result<u64, AgentError> {
    let mut time = lookup_value(&certificate.tree, ["time".as_bytes()])?;
    Ok(leb128::read::unsigned(&mut time)?)
}

pub(crate) fn lookup_canister_info<Storage: AsRef<[u8]>>(
    certificate: Certificate<Storage>,
    canister_id: Principal,
    path: &str,
) -> Result<Vec<u8>, AgentError> {
    let path_canister = [
        "canister".as_bytes(),
        canister_id.as_slice(),
        path.as_bytes(),
    ];
    lookup_value(&certificate.tree, path_canister).map(<[u8]>::to_vec)
}

pub(crate) fn lookup_canister_metadata<Storage: AsRef<[u8]>>(
    certificate: Certificate<Storage>,
    canister_id: Principal,
    path: &str,
) -> Result<Vec<u8>, AgentError> {
    let path_canister = [
        "canister".as_bytes(),
        canister_id.as_slice(),
        "metadata".as_bytes(),
        path.as_bytes(),
    ];

    lookup_value(&certificate.tree, path_canister).map(<[u8]>::to_vec)
}

pub(crate) fn lookup_subnet_metrics<Storage: AsRef<[u8]>>(
    certificate: Certificate<Storage>,
    subnet_id: Principal,
) -> Result<SubnetMetrics, AgentError> {
    let path_stats = [b"subnet", subnet_id.as_slice(), b"metrics"];
    let metrics = lookup_value(&certificate.tree, path_stats)?;
    Ok(serde_cbor::from_slice(metrics)?)
}

pub(crate) fn lookup_subnet_canister_ranges<Storage: AsRef<[u8]>>(
    certificate: Certificate<Storage>,
    subnet_id: Principal,
) -> Result<Vec<(Principal, Principal)>, AgentError> {
    let path_ranges = [b"subnet", subnet_id.as_slice(), b"canister_ranges"];
    let ranges = lookup_value(&certificate.tree, path_ranges)?;
    Ok(serde_cbor::from_slice(ranges)?)
}

pub(crate) fn lookup_request_status<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<RequestStatusResponse, AgentError> {
    use AgentError::*;
    let path_status = [
        "request_status".into(),
        request_id.to_vec().into(),
        "status".into(),
    ];
    match certificate.tree.lookup_path(&path_status) {
        LookupResult::Absent => Ok(RequestStatusResponse::Unknown),
        LookupResult::Unknown => Err(LookupPathUnknown(path_status.to_vec())),
        LookupResult::Found(status) => match from_utf8(status)? {
            "done" => Ok(RequestStatusResponse::Done),
            "processing" => Ok(RequestStatusResponse::Processing),
            "received" => Ok(RequestStatusResponse::Received),
            "rejected" => lookup_rejection(certificate, request_id),
            "replied" => lookup_reply(certificate, request_id),
            other => Err(InvalidRequestStatus(path_status.into(), other.to_string())),
        },
        LookupResult::Error => Err(LookupPathError(path_status.into())),
    }
}

pub(crate) fn lookup_rejection<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<RequestStatusResponse, AgentError> {
    let reject_code = lookup_reject_code(certificate, request_id)?;
    let reject_message = lookup_reject_message(certificate, request_id)?;
    let error_code = lookup_error_code(certificate, request_id)?;

    Ok(RequestStatusResponse::Rejected(RejectResponse {
        reject_code,
        reject_message,
        error_code,
    }))
}

pub(crate) fn lookup_reject_code<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<RejectCode, AgentError> {
    let path = [
        "request_status".as_bytes(),
        request_id.as_slice(),
        "reject_code".as_bytes(),
    ];
    let code = lookup_value(&certificate.tree, path)?;
    let mut readable = code;
    let code_digit = leb128::read::unsigned(&mut readable)?;
    Ok(RejectCode::try_from(code_digit)?)
}

pub(crate) fn lookup_reject_message<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<String, AgentError> {
    let path = [
        "request_status".as_bytes(),
        request_id.as_slice(),
        "reject_message".as_bytes(),
    ];
    let msg = lookup_value(&certificate.tree, path)?;
    Ok(from_utf8(msg)?.to_string())
}

pub(crate) fn lookup_error_code<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<Option<String>, AgentError> {
    let path = [
        "request_status".as_bytes(),
        request_id.as_slice(),
        "error_code".as_bytes(),
    ];
    let msg = lookup_value(&certificate.tree, path);
    match msg {
        Ok(val) => Ok(Some(from_utf8(val)?.to_string())),
        Err(AgentError::LookupPathAbsent(_)) => Ok(None),
        Err(e) => Err(e),
    }
}

pub(crate) fn lookup_reply<Storage: AsRef<[u8]>>(
    certificate: &Certificate<Storage>,
    request_id: &RequestId,
) -> Result<RequestStatusResponse, AgentError> {
    let path = [
        "request_status".as_bytes(),
        request_id.as_slice(),
        "reply".as_bytes(),
    ];
    let reply_data = lookup_value(&certificate.tree, path)?;
    let arg = Vec::from(reply_data);
    Ok(RequestStatusResponse::Replied(ReplyResponse { arg }))
}

pub(crate) fn lookup_subnet<Storage: AsRef<[u8]> + Clone>(
    certificate: &Certificate<Storage>,
    root_key: &[u8],
) -> Result<(Principal, Subnet), AgentError> {
    let subnet_id = if let Some(delegation) = &certificate.delegation {
        Principal::from_slice(delegation.subnet_id.as_ref())
    } else {
        Principal::self_authenticating(root_key)
    };
    let subnet_tree = lookup_tree(&certificate.tree, [b"subnet", subnet_id.as_slice()])?;
    let key = lookup_value(&subnet_tree, [b"public_key".as_ref()])?.to_vec();
    let canister_ranges: Vec<(Principal, Principal)> =
        if let Some(delegation) = &certificate.delegation {
            let delegation: Certificate<Vec<u8>> =
                serde_cbor::from_slice(delegation.certificate.as_ref())?;
            serde_cbor::from_slice(lookup_value(
                &delegation.tree,
                [b"subnet", subnet_id.as_slice(), b"canister_ranges"],
            )?)?
        } else {
            serde_cbor::from_slice(lookup_value(&subnet_tree, [b"canister_ranges".as_ref()])?)?
        };
    let node_keys_subtree = lookup_tree(&subnet_tree, [b"node".as_ref()])?;
    let mut node_keys = HashMap::new();
    for path in node_keys_subtree.list_paths() {
        if path.len() < 2 {
            // if it's absent, it's because this is the wrong subnet
            return Err(AgentError::CertificateNotAuthorized());
        }
        if path[1].as_bytes() != b"public_key" {
            continue;
        }
        if path.len() > 2 {
            return Err(AgentError::LookupPathError(
                path.into_iter()
                    .map(|label| label.as_bytes().to_vec().into())
                    .collect(),
            ));
        }
        let node_id = Principal::from_slice(path[0].as_bytes());
        let node_key = lookup_value(&node_keys_subtree, [node_id.as_slice(), b"public_key"])?;
        node_keys.insert(node_id, node_key.to_vec());
    }
    let mut range_set = RangeInclusiveSet::new_with_step_fns();
    for (low, high) in canister_ranges {
        range_set.insert(low..=high);
    }
    let subnet = Subnet {
        canister_ranges: range_set,
        _key: key,
        node_keys,
    };
    Ok((subnet_id, subnet))
}

pub(crate) fn lookup_api_boundary_nodes<Storage: AsRef<[u8]> + Clone>(
    certificate: Certificate<Storage>,
) -> Result<Vec<ApiBoundaryNode>, AgentError> {
    // API boundary nodes paths in the state tree, as defined in the spec (https://internetcomputer.org/docs/current/references/ic-interface-spec#state-tree-api-bn).
    let api_bn_path = "api_boundary_nodes".as_bytes();
    let domain_path = "domain".as_bytes();
    let ipv4_path = "ipv4_address".as_bytes();
    let ipv6_path = "ipv6_address".as_bytes();

    let api_bn_tree = lookup_tree(&certificate.tree, [api_bn_path])?;

    let mut api_bns = Vec::<ApiBoundaryNode>::new();
    let paths = api_bn_tree.list_paths();
    let node_ids: HashSet<&[u8]> = paths.iter().map(|path| path[0].as_bytes()).collect();

    for node_id in node_ids {
        let domain =
            String::from_utf8(lookup_value(&api_bn_tree, [node_id, domain_path])?.to_vec())
                .map_err(|err| AgentError::Utf8ReadError(err.utf8_error()))?;

        let ipv6_address =
            String::from_utf8(lookup_value(&api_bn_tree, [node_id, ipv6_path])?.to_vec())
                .map_err(|err| AgentError::Utf8ReadError(err.utf8_error()))?;

        let ipv4_address = match lookup_value(&api_bn_tree, [node_id, ipv4_path]) {
            Ok(ipv4) => Some(
                String::from_utf8(ipv4.to_vec())
                    .map_err(|err| AgentError::Utf8ReadError(err.utf8_error()))?,
            ),
            // By convention an absent path `/api_boundary_nodes/<node_id>/ipv4_address` in the state tree signifies that ipv4 is None.
            Err(AgentError::LookupPathAbsent(_)) => None,
            Err(err) => return Err(err),
        };

        let api_bn = ApiBoundaryNode {
            domain,
            ipv6_address,
            ipv4_address,
        };

        api_bns.push(api_bn);
    }

    Ok(api_bns)
}

/// The path to [`lookup_value`]
pub trait LookupPath {
    type Item: AsRef<[u8]>;
    type Iter<'a>: Iterator<Item = &'a Self::Item>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_>;
    fn into_vec(self) -> Vec<Label<Vec<u8>>>;
}

impl<'b, const N: usize> LookupPath for [&'b [u8]; N] {
    type Item = &'b [u8];
    type Iter<'a>
        = std::slice::Iter<'a, &'b [u8]>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        self.as_slice().iter()
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.map(Label::from_bytes).into()
    }
}
impl<'b, 'c> LookupPath for &'c [&'b [u8]] {
    type Item = &'b [u8];
    type Iter<'a>
        = std::slice::Iter<'a, &'b [u8]>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self)
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.iter().map(|v| Label::from_bytes(v)).collect()
    }
}
impl<'b> LookupPath for Vec<&'b [u8]> {
    type Item = &'b [u8];
    type Iter<'a>
        = std::slice::Iter<'a, &'b [u8]>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self.as_slice())
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.into_iter().map(Label::from_bytes).collect()
    }
}

impl<const N: usize> LookupPath for [Vec<u8>; N] {
    type Item = Vec<u8>;
    type Iter<'a>
        = std::slice::Iter<'a, Vec<u8>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        self.as_slice().iter()
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.map(Label::from).into()
    }
}
impl<'c> LookupPath for &'c [Vec<u8>] {
    type Item = Vec<u8>;
    type Iter<'a>
        = std::slice::Iter<'a, Vec<u8>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self)
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.iter().map(|v| Label::from(v.clone())).collect()
    }
}
impl LookupPath for Vec<Vec<u8>> {
    type Item = Vec<u8>;
    type Iter<'a>
        = std::slice::Iter<'a, Vec<u8>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self.as_slice())
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.into_iter().map(Label::from).collect()
    }
}

impl<Storage: AsRef<[u8]> + Into<Vec<u8>>, const N: usize> LookupPath for [Label<Storage>; N] {
    type Item = Label<Storage>;
    type Iter<'a>
        = std::slice::Iter<'a, Label<Storage>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        self.as_slice().iter()
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.map(Label::from_label).into()
    }
}
impl<'c, Storage: AsRef<[u8]> + Into<Vec<u8>>> LookupPath for &'c [Label<Storage>] {
    type Item = Label<Storage>;
    type Iter<'a>
        = std::slice::Iter<'a, Label<Storage>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self)
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self.iter()
            .map(|v| Label::from_bytes(v.as_bytes()))
            .collect()
    }
}
impl LookupPath for Vec<Label<Vec<u8>>> {
    type Item = Label<Vec<u8>>;
    type Iter<'a>
        = std::slice::Iter<'a, Label<Vec<u8>>>
    where
        Self: 'a;
    fn iter(&self) -> Self::Iter<'_> {
        <[_]>::iter(self.as_slice())
    }
    fn into_vec(self) -> Vec<Label<Vec<u8>>> {
        self
    }
}

/// Looks up a value in the certificate's tree at the specified hash.
///
/// Returns the value if it was found; otherwise, errors with `LookupPathAbsent`, `LookupPathUnknown`, or `LookupPathError`.
pub fn lookup_value<P: LookupPath, Storage: AsRef<[u8]>>(
    tree: &HashTree<Storage>,
    path: P,
) -> Result<&[u8], AgentError> {
    use AgentError::*;
    match tree.lookup_path(path.iter()) {
        LookupResult::Absent => Err(LookupPathAbsent(path.into_vec())),
        LookupResult::Unknown => Err(LookupPathUnknown(path.into_vec())),
        LookupResult::Found(value) => Ok(value),
        LookupResult::Error => Err(LookupPathError(path.into_vec())),
    }
}

/// Looks up a subtree in the certificate's tree at the specified hash.
///
/// Returns the value if it was found; otherwise, errors with `LookupPathAbsent` or `LookupPathUnknown`.
pub fn lookup_tree<P: LookupPath, Storage: AsRef<[u8]> + Clone>(
    tree: &HashTree<Storage>,
    path: P,
) -> Result<HashTree<Storage>, AgentError> {
    use AgentError::*;
    match tree.lookup_subtree(path.iter()) {
        SubtreeLookupResult::Absent => Err(LookupPathAbsent(path.into_vec())),
        SubtreeLookupResult::Unknown => Err(LookupPathUnknown(path.into_vec())),
        SubtreeLookupResult::Found(value) => Ok(value),
    }
}



================================================
FILE: ic-agent/src/agent/route_provider.rs
================================================
//! A [`RouteProvider`] for dynamic generation of routing urls.
use arc_swap::ArcSwapOption;
use dynamic_routing::{
    dynamic_route_provider::DynamicRouteProviderBuilder,
    node::Node,
    snapshot::{
        latency_based_routing::LatencyRoutingSnapshot,
        round_robin_routing::RoundRobinRoutingSnapshot,
    },
};
use std::{
    future::Future,
    str::FromStr,
    sync::{
        atomic::{AtomicUsize, Ordering},
        Arc,
    },
    time::Duration,
};
use url::Url;

use crate::agent::AgentError;

use super::HttpService;
#[cfg(not(feature = "_internal_dynamic-routing"))]
pub(crate) mod dynamic_routing;
#[cfg(feature = "_internal_dynamic-routing")]
pub mod dynamic_routing;

const IC0_DOMAIN: &str = "ic0.app";
const ICP0_DOMAIN: &str = "icp0.io";
const ICP_API_DOMAIN: &str = "icp-api.io";
const LOCALHOST_DOMAIN: &str = "localhost";
const IC0_SUB_DOMAIN: &str = ".ic0.app";
const ICP0_SUB_DOMAIN: &str = ".icp0.io";
const ICP_API_SUB_DOMAIN: &str = ".icp-api.io";
const LOCALHOST_SUB_DOMAIN: &str = ".localhost";

/// Statistical info about routing urls.
#[derive(Debug, PartialEq)]
pub struct RoutesStats {
    /// Total number of existing routes (both healthy and unhealthy).
    pub total: usize,

    /// Number of currently healthy routes, or None if health status information is unavailable.
    /// A healthy route is one that is available and ready to receive traffic.
    /// The specific criteria for what constitutes a "healthy" route is implementation dependent.
    pub healthy: Option<usize>,
}

impl RoutesStats {
    /// Creates an new instance of [`RoutesStats`].
    pub fn new(total: usize, healthy: Option<usize>) -> Self {
        Self { total, healthy }
    }
}

/// A [`RouteProvider`] for dynamic generation of routing urls.
pub trait RouteProvider: std::fmt::Debug + Send + Sync {
    /// Generates the next routing URL based on the internal routing logic.
    ///
    /// This method returns a single `Url` that can be used for routing.
    /// The logic behind determining the next URL can vary depending on the implementation
    fn route(&self) -> Result<Url, AgentError>;

    /// Generates up to `n` different routing URLs in order of priority.
    ///
    /// This method returns a vector of `Url` instances, each representing a routing
    /// endpoint. The URLs are ordered by priority, with the most preferred route
    /// appearing first. The returned vector can contain fewer than `n` URLs if
    /// fewer are available.
    fn n_ordered_routes(&self, n: usize) -> Result<Vec<Url>, AgentError>;

    /// Returns statistics about the total number of existing routes and the number of healthy routes.
    fn routes_stats(&self) -> RoutesStats;
}

/// A simple implementation of the [`RouteProvider`] which produces an even distribution of the urls from the input ones.
#[derive(Debug)]
pub struct RoundRobinRouteProvider {
    routes: Vec<Url>,
    current_idx: AtomicUsize,
}

impl RouteProvider for RoundRobinRouteProvider {
    /// Generates a url for the given endpoint.
    fn route(&self) -> Result<Url, AgentError> {
        if self.routes.is_empty() {
            return Err(AgentError::RouteProviderError(
                "No routing urls provided".to_string(),
            ));
        }
        // This operation wraps around an overflow, i.e. after max is reached the value is reset back to 0.
        let prev_idx = self.current_idx.fetch_add(1, Ordering::Relaxed);
        Ok(self.routes[prev_idx % self.routes.len()].clone())
    }

    fn n_ordered_routes(&self, n: usize) -> Result<Vec<Url>, AgentError> {
        if n == 0 {
            return Ok(Vec::new());
        }

        if n >= self.routes.len() {
            return Ok(self.routes.clone());
        }

        let idx = self.current_idx.fetch_add(n, Ordering::Relaxed) % self.routes.len();
        let mut urls = Vec::with_capacity(n);

        if self.routes.len() - idx >= n {
            urls.extend_from_slice(&self.routes[idx..idx + n]);
        } else {
            urls.extend_from_slice(&self.routes[idx..]);
            urls.extend_from_slice(&self.routes[..n - urls.len()]);
        }

        Ok(urls)
    }

    fn routes_stats(&self) -> RoutesStats {
        RoutesStats::new(self.routes.len(), None)
    }
}

impl RoundRobinRouteProvider {
    /// Construct [`RoundRobinRouteProvider`] from a vector of urls.
    pub fn new<T: AsRef<str>>(routes: Vec<T>) -> Result<Self, AgentError> {
        let routes: Result<Vec<Url>, _> = routes
            .into_iter()
            .map(|url| {
                Url::from_str(url.as_ref()).and_then(|mut url| {
                    // rewrite *.ic0.app to ic0.app
                    if let Some(domain) = url.domain() {
                        if domain.ends_with(IC0_SUB_DOMAIN) {
                            url.set_host(Some(IC0_DOMAIN))?;
                        } else if domain.ends_with(ICP0_SUB_DOMAIN) {
                            url.set_host(Some(ICP0_DOMAIN))?;
                        } else if domain.ends_with(ICP_API_SUB_DOMAIN) {
                            url.set_host(Some(ICP_API_DOMAIN))?;
                        } else if domain.ends_with(LOCALHOST_SUB_DOMAIN) {
                            url.set_host(Some(LOCALHOST_DOMAIN))?;
                        }
                    }
                    Ok(url)
                })
            })
            .collect();
        Ok(Self {
            routes: routes?,
            current_idx: AtomicUsize::new(0),
        })
    }
}

impl RouteProvider for Url {
    fn route(&self) -> Result<Url, AgentError> {
        Ok(self.clone())
    }
    fn n_ordered_routes(&self, _: usize) -> Result<Vec<Url>, AgentError> {
        Ok(vec![self.route()?])
    }
    fn routes_stats(&self) -> RoutesStats {
        RoutesStats::new(1, None)
    }
}

/// A [`RouteProvider`] that will attempt to discover new boundary nodes and cycle through them, optionally prioritizing those with low latency.
#[derive(Debug)]
pub struct DynamicRouteProvider {
    inner: Box<dyn RouteProvider>,
}

impl DynamicRouteProvider {
    /// Create a new `DynamicRouter` from a list of seed domains and a routing strategy.
    pub async fn run_in_background(
        seed_domains: Vec<String>,
        client: Arc<dyn HttpService>,
        strategy: DynamicRoutingStrategy,
    ) -> Result<Self, AgentError> {
        let seed_nodes: Result<Vec<_>, _> = seed_domains.into_iter().map(Node::new).collect();
        let boxed = match strategy {
            DynamicRoutingStrategy::ByLatency => Box::new(
                DynamicRouteProviderBuilder::new(
                    LatencyRoutingSnapshot::new(),
                    seed_nodes?,
                    client,
                )
                .build()
                .await,
            ) as Box<dyn RouteProvider>,
            DynamicRoutingStrategy::RoundRobin => Box::new(
                DynamicRouteProviderBuilder::new(
                    RoundRobinRoutingSnapshot::new(),
                    seed_nodes?,
                    client,
                )
                .build()
                .await,
            ),
        };
        Ok(Self { inner: boxed })
    }
    /// Same as [`run_in_background`](Self::run_in_background), but with custom intervals for refreshing the routing list and health-checking nodes.
    pub async fn run_in_background_with_intervals(
        seed_domains: Vec<String>,
        client: Arc<dyn HttpService>,
        strategy: DynamicRoutingStrategy,
        list_update_interval: Duration,
        health_check_interval: Duration,
    ) -> Result<Self, AgentError> {
        let seed_nodes: Result<Vec<_>, _> = seed_domains.into_iter().map(Node::new).collect();
        let boxed = match strategy {
            DynamicRoutingStrategy::ByLatency => Box::new(
                DynamicRouteProviderBuilder::new(
                    LatencyRoutingSnapshot::new(),
                    seed_nodes?,
                    client,
                )
                .with_fetch_period(list_update_interval)
                .with_check_period(health_check_interval)
                .build()
                .await,
            ) as Box<dyn RouteProvider>,
            DynamicRoutingStrategy::RoundRobin => Box::new(
                DynamicRouteProviderBuilder::new(
                    RoundRobinRoutingSnapshot::new(),
                    seed_nodes?,
                    client,
                )
                .with_fetch_period(list_update_interval)
                .with_check_period(health_check_interval)
                .build()
                .await,
            ),
        };
        Ok(Self { inner: boxed })
    }
}

impl RouteProvider for DynamicRouteProvider {
    fn route(&self) -> Result<Url, AgentError> {
        self.inner.route()
    }
    fn n_ordered_routes(&self, n: usize) -> Result<Vec<Url>, AgentError> {
        self.inner.n_ordered_routes(n)
    }
    fn routes_stats(&self) -> RoutesStats {
        self.inner.routes_stats()
    }
}

/// Strategy for [`DynamicRouteProvider`]'s routing mechanism.
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub enum DynamicRoutingStrategy {
    /// Prefer nodes with low latency.
    ByLatency,
    /// Cycle through discovered nodes with no regard for latency.
    RoundRobin,
}

#[derive(Debug)]
pub(crate) struct UrlUntilReady<R> {
    url: Url,
    router: ArcSwapOption<R>,
}

impl<R: RouteProvider + 'static> UrlUntilReady<R> {
    pub(crate) fn new<
        #[cfg(not(target_family = "wasm"))] F: Future<Output = R> + Send + 'static,
        #[cfg(target_family = "wasm")] F: Future<Output = R> + 'static,
    >(
        url: Url,
        fut: F,
    ) -> Arc<Self> {
        let s = Arc::new(Self {
            url,
            router: ArcSwapOption::empty(),
        });
        let weak = Arc::downgrade(&s);
        crate::util::spawn(async move {
            let router = fut.await;
            if let Some(outer) = weak.upgrade() {
                outer.router.store(Some(Arc::new(router)))
            }
        });
        s
    }
}

impl<R: RouteProvider> RouteProvider for UrlUntilReady<R> {
    fn n_ordered_routes(&self, n: usize) -> Result<Vec<Url>, AgentError> {
        if let Some(r) = &*self.router.load() {
            r.n_ordered_routes(n)
        } else {
            self.url.n_ordered_routes(n)
        }
    }
    fn route(&self) -> Result<Url, AgentError> {
        if let Some(r) = &*self.router.load() {
            r.route()
        } else {
            self.url.route()
        }
    }
    fn routes_stats(&self) -> RoutesStats {
        RoutesStats::new(1, None)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_empty_routes() {
        let provider = RoundRobinRouteProvider::new::<&str>(vec![])
            .expect("failed to create a route provider");
        let result = provider.route().unwrap_err();
        assert_eq!(
            result,
            AgentError::RouteProviderError("No routing urls provided".to_string())
        );
    }

    #[test]
    fn test_routes_rotation() {
        let provider = RoundRobinRouteProvider::new(vec!["https://url1.com", "https://url2.com"])
            .expect("failed to create a route provider");
        let url_strings = ["https://url1.com", "https://url2.com", "https://url1.com"];
        let expected_urls: Vec<Url> = url_strings
            .iter()
            .map(|url_str| Url::parse(url_str).expect("Invalid URL"))
            .collect();
        let urls: Vec<Url> = (0..3)
            .map(|_| provider.route().expect("failed to get next url"))
            .collect();
        assert_eq!(expected_urls, urls);
    }

    #[test]
    fn test_n_routes() {
        // Test with an empty list of urls
        let provider = RoundRobinRouteProvider::new(Vec::<&str>::new())
            .expect("failed to create a route provider");
        let urls_iter = provider.n_ordered_routes(1).expect("failed to get urls");
        assert!(urls_iter.is_empty());
        // Test with non-empty list of urls
        let provider = RoundRobinRouteProvider::new(vec![
            "https://url1.com",
            "https://url2.com",
            "https://url3.com",
            "https://url4.com",
            "https://url5.com",
        ])
        .expect("failed to create a route provider");
        // First call
        let urls: Vec<_> = provider.n_ordered_routes(3).expect("failed to get urls");
        let expected_urls: Vec<Url> = ["https://url1.com", "https://url2.com", "https://url3.com"]
            .iter()
            .map(|url_str| Url::parse(url_str).expect("invalid URL"))
            .collect();
        assert_eq!(urls, expected_urls);
        // Second call
        let urls: Vec<_> = provider.n_ordered_routes(3).expect("failed to get urls");
        let expected_urls: Vec<Url> = ["https://url4.com", "https://url5.com", "https://url1.com"]
            .iter()
            .map(|url_str| Url::parse(url_str).expect("invalid URL"))
            .collect();
        assert_eq!(urls, expected_urls);
        // Third call
        let urls: Vec<_> = provider.n_ordered_routes(2).expect("failed to get urls");
        let expected_urls: Vec<Url> = ["https://url2.com", "https://url3.com"]
            .iter()
            .map(|url_str| Url::parse(url_str).expect("invalid URL"))
            .collect();
        assert_eq!(urls, expected_urls);
        // Fourth call
        let urls: Vec<_> = provider.n_ordered_routes(5).expect("failed to get urls");
        let expected_urls: Vec<Url> = [
            "https://url1.com",
            "https://url2.com",
            "https://url3.com",
            "https://url4.com",
            "https://url5.com",
        ]
        .iter()
        .map(|url_str| Url::parse(url_str).expect("invalid URL"))
        .collect();
        assert_eq!(urls, expected_urls);
    }
}



================================================
FILE: ic-agent/src/agent/status.rs
================================================
//! Types for interacting with the status endpoint of a replica. See [`Status`] for details.

use std::{collections::BTreeMap, fmt::Debug};

/// Value returned by the status endpoint of a replica. This is a loose mapping to CBOR values.
/// Because the agent should not return [`serde_cbor::Value`] directly across API boundaries,
/// we reimplement it as [`Value`] here.
#[derive(Debug, Ord, PartialOrd, Eq, PartialEq, Clone, Hash)]
pub enum Value {
    /// See [`Null`](serde_cbor::Value::Null).
    Null,
    /// See [`String`](serde_cbor::Value::Text).
    String(String),
    /// See [`Integer`](serde_cbor::Value::Integer).
    Integer(i64),
    /// See [`Bool`](serde_cbor::Value::Bool).
    Bool(bool),
    /// See [`Bytes`](serde_cbor::Value::Bytes).
    Bytes(Vec<u8>),
    /// See [`Vec`](serde_cbor::Value::Array).
    Vec(Vec<Value>),
    /// See [`Map`](serde_cbor::Value::Map).
    Map(BTreeMap<String, Box<Value>>),
}

impl std::fmt::Display for Value {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Value::Null => f.write_str("null"),
            Value::String(s) => f.write_fmt(format_args!(r#""{}""#, s.escape_debug())),
            Value::Integer(i) => f.write_str(&i.to_string()),
            Value::Bool(true) => f.write_str("true"),
            Value::Bool(false) => f.write_str("false"),
            Value::Bytes(b) => f.debug_list().entries(b).finish(),
            Value::Vec(v) => f.debug_list().entries(v).finish(),
            Value::Map(m) => f.debug_map().entries(m).finish(),
        }
    }
}

/// The structure returned by [`super::Agent::status`], containing the information returned
/// by the status endpoint of a replica.
#[derive(Debug, Ord, PartialOrd, PartialEq, Eq)]
pub struct Status {
    /// Optional. The precise git revision of the Internet Computer Protocol implementation.
    pub impl_version: Option<String>,

    /// Optional.  The health status of the replica.  One hopes it's "healthy".
    pub replica_health_status: Option<String>,

    /// Optional.  The root (public) key used to verify certificates.
    pub root_key: Option<Vec<u8>>,

    /// Contains any additional values that the replica gave as status.
    pub values: BTreeMap<String, Box<Value>>,
}

impl std::fmt::Display for Status {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.write_str("{\n")?;
        let mut first = true;
        for (key, value) in &self.values {
            if first {
                first = false;
            } else {
                f.write_str(",\n")?;
            }
            f.write_fmt(format_args!(r#"  "{}": "#, key.escape_debug()))?;
            std::fmt::Display::fmt(&value, f)?;
        }
        f.write_str("\n}")
    }
}

fn cbor_value_to_value(value: &serde_cbor::Value) -> Result<Value, ()> {
    match value {
        serde_cbor::Value::Null => Ok(Value::Null),
        serde_cbor::Value::Bool(b) => Ok(Value::Bool(*b)),
        serde_cbor::Value::Integer(i) => Ok(Value::Integer(*i as i64)),
        serde_cbor::Value::Bytes(b) => Ok(Value::Bytes(b.to_owned())),
        serde_cbor::Value::Text(s) => Ok(Value::String(s.to_owned())),
        serde_cbor::Value::Array(a) => Ok(Value::Vec(
            a.iter()
                .map(cbor_value_to_value)
                .collect::<Result<Vec<Value>, ()>>()
                .map_err(|_| ())?,
        )),
        serde_cbor::Value::Map(m) => {
            let mut map = BTreeMap::new();
            for (key, value) in m {
                let k = match key {
                    serde_cbor::Value::Text(t) => t.to_owned(),
                    serde_cbor::Value::Integer(i) => i.to_string(),
                    _ => return Err(()),
                };
                let v = Box::new(cbor_value_to_value(value)?);

                map.insert(k, v);
            }
            Ok(Value::Map(map))
        }
        serde_cbor::Value::Tag(_, v) => cbor_value_to_value(v.as_ref()),
        _ => Err(()),
    }
}

impl std::convert::TryFrom<&serde_cbor::Value> for Status {
    type Error = ();

    fn try_from(value: &serde_cbor::Value) -> Result<Self, ()> {
        let v = cbor_value_to_value(value)?;

        match v {
            Value::Map(map) => {
                let impl_version: Option<String> = map.get("impl_version").and_then(|v| {
                    if let Value::String(s) = v.as_ref() {
                        Some(s.to_owned())
                    } else {
                        None
                    }
                });
                let replica_health_status: Option<String> =
                    map.get("replica_health_status").and_then(|v| {
                        if let Value::String(s) = v.as_ref() {
                            Some(s.to_owned())
                        } else {
                            None
                        }
                    });
                let root_key: Option<Vec<u8>> = map.get("root_key").and_then(|v| {
                    if let Value::Bytes(bytes) = v.as_ref() {
                        Some(bytes.to_owned())
                    } else {
                        None
                    }
                });

                Ok(Status {
                    impl_version,
                    replica_health_status,
                    root_key,
                    values: map,
                })
            }
            _ => Err(()),
        }
    }
}



================================================
FILE: ic-agent/src/agent/http_transport/mod.rs
================================================
//! This module has been deprecated in favor of builder methods on `AgentBuilder`.

#[deprecated(since = "0.38.0", note = "use the AgentBuilder methods")]
#[doc(hidden)]
pub mod reqwest_transport;
#[doc(hidden)]
#[allow(deprecated)]
pub use reqwest_transport::ReqwestTransport;



================================================
FILE: ic-agent/src/agent/http_transport/reqwest_transport.rs
================================================
//! This module has been deprecated in favor of builder methods on `AgentBuilder`.
#![allow(deprecated)]
pub use reqwest;
use std::sync::Arc;

use reqwest::Client;

use crate::{
    agent::{
        route_provider::{RoundRobinRouteProvider, RouteProvider},
        AgentBuilder,
    },
    AgentError,
};

/// A legacy configuration object. `AgentBuilder::with_transport` will apply these settings to the builder.
#[derive(Debug, Clone)]
pub struct ReqwestTransport {
    route_provider: Arc<dyn RouteProvider>,
    client: Client,
    max_response_body_size: Option<usize>,
    max_tcp_error_retries: usize,
}

impl ReqwestTransport {
    /// Equivalent to [`AgentBuilder::with_url`].
    #[deprecated(since = "0.38.0", note = "Use AgentBuilder::with_url")]
    pub fn create<U: Into<String>>(url: U) -> Result<Self, AgentError> {
        #[cfg(not(target_family = "wasm"))]
        {
            Self::create_with_client(
                url,
                Client::builder()
                    .use_rustls_tls()
                    .timeout(std::time::Duration::from_secs(360))
                    .build()
                    .expect("Could not create HTTP client."),
            )
        }
        #[cfg(all(target_family = "wasm", feature = "wasm-bindgen"))]
        {
            Self::create_with_client(url, Client::new())
        }
    }

    /// Equivalent to [`AgentBuilder::with_url`] and [`AgentBuilder::with_http_client`].
    #[deprecated(
        since = "0.38.0",
        note = "Use AgentBuilder::with_url and AgentBuilder::with_http_client"
    )]
    pub fn create_with_client<U: Into<String>>(url: U, client: Client) -> Result<Self, AgentError> {
        let route_provider = Arc::new(RoundRobinRouteProvider::new(vec![url.into()])?);
        Self::create_with_client_route(route_provider, client)
    }

    /// Equivalent to [`AgentBuilder::with_http_client`] and [`AgentBuilder::with_route_provider`].
    #[deprecated(
        since = "0.38.0",
        note = "Use AgentBuilder::with_http_client and AgentBuilder::with_arc_route_provider"
    )]
    pub fn create_with_client_route(
        route_provider: Arc<dyn RouteProvider>,
        client: Client,
    ) -> Result<Self, AgentError> {
        Ok(Self {
            route_provider,
            client,
            max_response_body_size: None,
            max_tcp_error_retries: 0,
        })
    }

    /// Equivalent to [`AgentBuilder::with_max_response_body_size`].
    #[deprecated(
        since = "0.38.0",
        note = "Use AgentBuilder::with_max_response_body_size"
    )]
    pub fn with_max_response_body_size(self, max_response_body_size: usize) -> Self {
        ReqwestTransport {
            max_response_body_size: Some(max_response_body_size),
            ..self
        }
    }

    /// Equivalent to [`AgentBuilder::with_max_tcp_error_retries`].
    #[deprecated(
        since = "0.38.0",
        note = "Use AgentBuilder::with_max_tcp_error_retries"
    )]
    pub fn with_max_tcp_errors_retries(self, retries: usize) -> Self {
        ReqwestTransport {
            max_tcp_error_retries: retries,
            ..self
        }
    }
}

impl AgentBuilder {
    #[doc(hidden)]
    #[deprecated(since = "0.38.0", note = "Use the dedicated methods on AgentBuilder")]
    pub fn with_transport(self, transport: ReqwestTransport) -> Self {
        let mut builder = self
            .with_arc_route_provider(transport.route_provider)
            .with_http_client(transport.client)
            .with_max_tcp_error_retries(transport.max_tcp_error_retries);
        if let Some(max_size) = transport.max_response_body_size {
            builder = builder.with_max_response_body_size(max_size);
        }
        builder
    }
    #[doc(hidden)]
    #[deprecated(since = "0.38.0", note = "Use the dedicated methods on AgentBuilder")]
    pub fn with_arc_transport(self, transport: Arc<ReqwestTransport>) -> Self {
        self.with_transport((*transport).clone())
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/dynamic_route_provider.rs
================================================
//! An implementation of [`RouteProvider`] for dynamic generation of routing urls.

use std::{
    sync::Arc,
    time::{Duration, Instant},
};

use arc_swap::ArcSwap;
use candid::Principal;
use futures_util::FutureExt;
use stop_token::StopSource;
use thiserror::Error;
use url::Url;

use crate::{
    agent::{
        route_provider::{
            dynamic_routing::{
                health_check::{HealthCheck, HealthChecker, HealthManagerActor},
                messages::FetchedNodes,
                node::Node,
                nodes_fetch::{Fetch, NodesFetchActor, NodesFetcher},
                snapshot::routing_snapshot::RoutingSnapshot,
                type_aliases::AtomicSwap,
            },
            RouteProvider, RoutesStats,
        },
        HttpService,
    },
    AgentError,
};

/// The default seed domain for boundary node discovery.
#[allow(unused)]
pub const IC0_SEED_DOMAIN: &str = "ic0.app";

const MAINNET_ROOT_SUBNET_ID: &str =
    "tdb26-jop6k-aogll-7ltgs-eruif-6kk7m-qpktf-gdiqx-mxtrf-vb5e6-eqe";

const FETCH_PERIOD: Duration = Duration::from_secs(5);
const FETCH_RETRY_INTERVAL: Duration = Duration::from_millis(250);
const TIMEOUT_AWAIT_HEALTHY_SEED: Duration = Duration::from_millis(1000);
#[allow(unused)]
const HEALTH_CHECK_TIMEOUT: Duration = Duration::from_secs(1);
const HEALTH_CHECK_PERIOD: Duration = Duration::from_secs(1);
#[allow(unused)]
const DYNAMIC_ROUTE_PROVIDER: &str = "DynamicRouteProvider";

/// A dynamic route provider.
/// It spawns the discovery service (`NodesFetchActor`) for fetching the latest nodes topology.
/// It also spawns the `HealthManagerActor`, which orchestrates the health check tasks for each node and updates routing snapshot.
#[derive(Debug)]
pub struct DynamicRouteProvider<S> {
    /// Fetcher for fetching the latest nodes topology.
    fetcher: Arc<dyn Fetch>,
    /// Periodicity of fetching the latest nodes topology.
    fetch_period: Duration,
    /// Interval for retrying fetching the nodes in case of error.
    fetch_retry_interval: Duration,
    /// Health checker for checking the health of the nodes.
    checker: Arc<dyn HealthCheck>,
    /// Periodicity of checking the health of the nodes.
    check_period: Duration,
    /// Snapshot of the routing nodes.
    routing_snapshot: AtomicSwap<S>,
    /// Initial seed nodes, which are used for the initial fetching of the nodes.
    seeds: Vec<Node>,
    /// Cancellation token for stopping the spawned tasks.
    token: StopSource,
}

/// An error that occurred when the `DynamicRouteProvider` service was running.
#[derive(Error, Debug)]
pub enum DynamicRouteProviderError {
    /// An error when fetching topology of the API nodes.
    #[error("An error when fetching API nodes: {0}")]
    NodesFetchError(String),
    /// An error when checking API node's health.
    #[error("An error when checking API node's health: {0}")]
    HealthCheckError(String),
}

/// A builder for the `DynamicRouteProvider`.
pub struct DynamicRouteProviderBuilder<S> {
    fetcher: Arc<dyn Fetch>,
    fetch_period: Duration,
    fetch_retry_interval: Duration,
    checker: Arc<dyn HealthCheck>,
    check_period: Duration,
    routing_snapshot: AtomicSwap<S>,
    seeds: Vec<Node>,
}

impl<S> DynamicRouteProviderBuilder<S> {
    /// Creates a new instance of the builder.
    pub fn new(snapshot: S, seeds: Vec<Node>, http_client: Arc<dyn HttpService>) -> Self {
        let fetcher = Arc::new(NodesFetcher::new(
            http_client.clone(),
            Principal::from_text(MAINNET_ROOT_SUBNET_ID).unwrap(),
            None,
        ));
        let checker = Arc::new(HealthChecker::new(
            http_client,
            #[cfg(not(target_family = "wasm"))]
            HEALTH_CHECK_TIMEOUT,
        ));
        Self {
            fetcher,
            fetch_period: FETCH_PERIOD,
            fetch_retry_interval: FETCH_RETRY_INTERVAL,
            checker,
            check_period: HEALTH_CHECK_PERIOD,
            seeds,
            routing_snapshot: Arc::new(ArcSwap::from_pointee(snapshot)),
        }
    }

    /// Sets the fetcher of the nodes in the topology.
    #[allow(unused)]
    pub fn with_fetcher(mut self, fetcher: Arc<dyn Fetch>) -> Self {
        self.fetcher = fetcher;
        self
    }

    /// Sets the fetching periodicity.
    pub fn with_fetch_period(mut self, period: Duration) -> Self {
        self.fetch_period = period;
        self
    }

    /// Sets the node health checker.
    #[allow(unused)]
    pub fn with_checker(mut self, checker: Arc<dyn HealthCheck>) -> Self {
        self.checker = checker;
        self
    }

    /// Sets the periodicity of node health checking.
    pub fn with_check_period(mut self, period: Duration) -> Self {
        self.check_period = period;
        self
    }

    /// Builds an instance of the `DynamicRouteProvider`.
    pub async fn build(self) -> DynamicRouteProvider<S>
    where
        S: RoutingSnapshot + 'static,
    {
        let route_provider = DynamicRouteProvider {
            fetcher: self.fetcher,
            fetch_period: self.fetch_period,
            fetch_retry_interval: self.fetch_retry_interval,
            checker: self.checker,
            check_period: self.check_period,
            routing_snapshot: self.routing_snapshot,
            seeds: self.seeds,
            token: StopSource::new(),
        };

        route_provider.run().await;

        route_provider
    }
}

impl<S> RouteProvider for DynamicRouteProvider<S>
where
    S: RoutingSnapshot + 'static,
{
    fn route(&self) -> Result<Url, AgentError> {
        let snapshot = self.routing_snapshot.load();
        let node = snapshot.next_node().ok_or_else(|| {
            AgentError::RouteProviderError("No healthy API nodes found.".to_string())
        })?;
        Ok(node.to_routing_url())
    }

    fn n_ordered_routes(&self, n: usize) -> Result<Vec<Url>, AgentError> {
        let snapshot = self.routing_snapshot.load();
        let nodes = snapshot.next_n_nodes(n);
        if nodes.is_empty() {
            return Err(AgentError::RouteProviderError(
                "No healthy API nodes found.".to_string(),
            ));
        };
        let urls = nodes.iter().map(|n| n.to_routing_url()).collect();
        Ok(urls)
    }

    fn routes_stats(&self) -> RoutesStats {
        let snapshot = self.routing_snapshot.load();
        snapshot.routes_stats()
    }
}

impl<S> DynamicRouteProvider<S>
where
    S: RoutingSnapshot + 'static,
{
    /// Starts two background tasks:
    /// - Task1: `NodesFetchActor`
    ///   - Periodically fetches existing API nodes (gets latest nodes topology) and sends discovered nodes to `HealthManagerActor`.
    /// - Task2: `HealthManagerActor`:
    ///   - Listens to the fetched nodes messages from the `NodesFetchActor`.
    ///   - Starts/stops health check tasks (`HealthCheckActors`) based on the newly added/removed nodes.
    ///   - These spawned health check tasks periodically update the snapshot with the latest node health info.
    pub async fn run(&self) {
        log!(info, "{DYNAMIC_ROUTE_PROVIDER}: started ...");
        // Communication channel between NodesFetchActor and HealthManagerActor.
        let (fetch_sender, fetch_receiver) = async_watch::channel(None);

        // Communication channel with HealthManagerActor to receive info about healthy seed nodes (used only once).
        let (init_sender, init_receiver) = async_channel::bounded(1);

        // Start the receiving part first.
        let health_manager_actor = HealthManagerActor::new(
            Arc::clone(&self.checker),
            self.check_period,
            Arc::clone(&self.routing_snapshot),
            fetch_receiver,
            init_sender,
            self.token.token(),
        );
        crate::util::spawn(async move { health_manager_actor.run().await });

        // Dispatch all seed nodes for initial health checks
        if let Err(_err) = fetch_sender.send(Some(FetchedNodes {
            nodes: self.seeds.clone(),
        })) {
            log!(
                error,
                "{DYNAMIC_ROUTE_PROVIDER}: failed to send results to HealthManager: {_err:?}"
            );
        }

        // Try await for healthy seeds.
        let _start = Instant::now();
        futures_util::select! {
            _ = crate::util::sleep(TIMEOUT_AWAIT_HEALTHY_SEED).fuse() => {
                log!(
                    warn,
                    "{DYNAMIC_ROUTE_PROVIDER}: no healthy seeds found within {:?}",
                    _start.elapsed()
                );
            }
            _ = init_receiver.recv().fuse() => {
                log!(
                    info,
                    "{DYNAMIC_ROUTE_PROVIDER}: found healthy seeds within {:?}",
                    _start.elapsed()
                );
            }
        }
        // We can close the channel now.
        init_receiver.close();

        let fetch_actor = NodesFetchActor::new(
            Arc::clone(&self.fetcher),
            self.fetch_period,
            self.fetch_retry_interval,
            fetch_sender,
            Arc::clone(&self.routing_snapshot),
            self.token.token(),
        );
        crate::util::spawn(async move { fetch_actor.run().await });
        log!(
            info,
            "{DYNAMIC_ROUTE_PROVIDER}: NodesFetchActor and HealthManagerActor started successfully"
        );
    }
}

#[cfg(all(test, not(target_family = "wasm")))]
mod tests {
    use candid::Principal;
    use reqwest::Client;
    use std::{
        sync::{Arc, Once},
        time::{Duration, Instant},
    };
    use tracing::Level;
    use tracing_subscriber::FmtSubscriber;

    use crate::{
        agent::route_provider::{
            dynamic_routing::{
                dynamic_route_provider::{
                    DynamicRouteProviderBuilder, IC0_SEED_DOMAIN, MAINNET_ROOT_SUBNET_ID,
                },
                node::Node,
                snapshot::{
                    latency_based_routing::LatencyRoutingSnapshot,
                    round_robin_routing::RoundRobinRoutingSnapshot,
                },
                test_utils::{
                    assert_routed_domains, route_n_times, NodeHealthCheckerMock, NodesFetcherMock,
                },
            },
            RouteProvider, RoutesStats,
        },
        Agent, AgentError,
    };

    static TRACING_INIT: Once = Once::new();

    pub fn setup_tracing() {
        TRACING_INIT.call_once(|| {
            FmtSubscriber::builder()
                .with_max_level(Level::TRACE)
                .with_test_writer()
                .init();
        });
    }

    async fn assert_no_routing_via_domains(
        route_provider: Arc<dyn RouteProvider>,
        excluded_domains: Vec<&str>,
        timeout: Duration,
        route_call_interval: Duration,
    ) {
        if excluded_domains.is_empty() {
            panic!("List of excluded domains can't be empty");
        }

        let route_calls = 30;
        let start = Instant::now();

        while start.elapsed() < timeout {
            let routed_domains = (0..route_calls)
                .map(|_| {
                    route_provider.route().map(|url| {
                        let domain = url.domain().expect("no domain name in url");
                        domain.to_string()
                    })
                })
                .collect::<Result<Vec<String>, _>>()
                .unwrap_or_default();

            // Exit when excluded domains are not used for routing any more.
            if !routed_domains.is_empty()
                && !routed_domains
                    .iter()
                    .any(|d| excluded_domains.contains(&d.as_str()))
            {
                return;
            }

            tokio::time::sleep(route_call_interval).await;
        }
        panic!("Expected excluded domains {excluded_domains:?} are still observed in routing over the last {route_calls} calls");
    }

    #[tokio::test]
    async fn test_mainnet() {
        // Setup.
        setup_tracing();
        let seed = Node::new(IC0_SEED_DOMAIN).unwrap();
        let client = Client::builder().build().unwrap();
        let route_provider = DynamicRouteProviderBuilder::new(
            LatencyRoutingSnapshot::new(),
            vec![seed],
            Arc::new(client.clone()),
        )
        .build()
        .await;
        let route_provider = Arc::new(route_provider) as Arc<dyn RouteProvider>;
        let agent = Agent::builder()
            .with_arc_route_provider(Arc::clone(&route_provider))
            .with_http_client(client)
            .build()
            .expect("failed to create an agent");
        let subnet_id = Principal::from_text(MAINNET_ROOT_SUBNET_ID).unwrap();
        // Assert that seed (ic0.app) is not used for routing. Henceforth, only discovered API nodes are used.
        assert_no_routing_via_domains(
            Arc::clone(&route_provider),
            vec![IC0_SEED_DOMAIN],
            Duration::from_secs(40),
            Duration::from_secs(2),
        )
        .await;
        // Act: perform /read_state call via dynamically discovered API BNs.
        let api_bns = agent
            .fetch_api_boundary_nodes_by_subnet_id(subnet_id)
            .await
            .expect("failed to fetch api boundary nodes");
        assert!(!api_bns.is_empty());
    }

    #[tokio::test]
    async fn test_routing_with_topology_and_node_health_updates() {
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        fetcher.overwrite_nodes(vec![node_1.clone()]);
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // A single healthy node exists in the topology. This node happens to be the seed node.
        fetcher.overwrite_nodes(vec![node_1.clone()]);
        checker.overwrite_healthy_nodes(vec![node_1.clone()]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider =
            DynamicRouteProviderBuilder::new(snapshot, vec![node_1.clone()], Arc::new(client))
                .with_fetcher(fetcher.clone())
                .with_checker(checker.clone())
                .with_fetch_period(fetch_interval)
                .with_check_period(check_interval)
                .build()
                .await;
        let route_provider = Arc::new(route_provider);

        // This time span is required for the snapshot to be fully updated with the new nodes and their health info.
        let snapshot_update_duration = fetch_interval + 2 * check_interval;

        // Test 1: multiple route() calls return a single domain=ic0.app.
        // Only a single node exists, which is initially healthy.
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain()], 6);
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(1, Some(1)));

        // Test 2: multiple route() calls return 3 different domains with equal fairness (repetition).
        // Two healthy nodes are added to the topology.
        let node_2 = Node::new("api1.com").unwrap();
        let node_3 = Node::new("api2.com").unwrap();
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_2.clone(), node_3.clone()]);
        fetcher.overwrite_nodes(vec![node_1.clone(), node_2.clone(), node_3.clone()]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(
            routed_domains,
            vec![node_1.domain(), node_2.domain(), node_3.domain()],
            2,
        );
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(3, Some(3)));

        // Test 3:  multiple route() calls return 2 different domains with equal fairness (repetition).
        // One node is set to unhealthy.
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_3.clone()]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain(), node_3.domain()], 3);
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(3, Some(2)));

        // Test 4: multiple route() calls return 3 different domains with equal fairness (repetition).
        // Unhealthy node is set back to healthy.
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_2.clone(), node_3.clone()]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(
            routed_domains,
            vec![node_1.domain(), node_2.domain(), node_3.domain()],
            2,
        );
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(3, Some(3)));

        // Test 5: multiple route() calls return 3 different domains with equal fairness (repetition).
        // One healthy node is added, but another one goes unhealthy.
        let node_4 = Node::new("api3.com").unwrap();
        checker.overwrite_healthy_nodes(vec![node_2.clone(), node_3.clone(), node_4.clone()]);
        fetcher.overwrite_nodes(vec![
            node_1.clone(),
            node_2.clone(),
            node_3.clone(),
            node_4.clone(),
        ]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(
            routed_domains,
            vec![node_2.domain(), node_3.domain(), node_4.domain()],
            2,
        );
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(4, Some(3)));

        // Test 6: multiple route() calls return a single domain=api1.com.
        // One node is set to unhealthy and one is removed from the topology.
        checker.overwrite_healthy_nodes(vec![node_2.clone(), node_3.clone()]);
        fetcher.overwrite_nodes(vec![node_1.clone(), node_2.clone(), node_4.clone()]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(3, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_2.domain()], 3);
        assert_eq!(route_provider.routes_stats(), RoutesStats::new(3, Some(1)));
    }

    #[tokio::test]
    async fn test_route_with_initially_unhealthy_seeds_becoming_healthy() {
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        let node_2 = Node::new("api1.com").unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // Two nodes exist, which are initially unhealthy.
        fetcher.overwrite_nodes(vec![node_1.clone(), node_2.clone()]);
        checker.overwrite_healthy_nodes(vec![]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider = DynamicRouteProviderBuilder::new(
            snapshot,
            vec![node_1.clone(), node_2.clone()],
            Arc::new(client),
        )
        .with_fetcher(fetcher)
        .with_checker(checker.clone())
        .with_fetch_period(fetch_interval)
        .with_check_period(check_interval)
        .build()
        .await;
        let route_provider = Arc::new(route_provider);

        // Test 1: calls to route() return an error, as no healthy seeds exist.
        for _ in 0..4 {
            tokio::time::sleep(check_interval).await;
            let result = route_provider.route();
            assert_eq!(
                result.unwrap_err(),
                AgentError::RouteProviderError("No healthy API nodes found.".to_string())
            );
        }

        // Test 2: calls to route() return both seeds, as they become healthy.
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_2.clone()]);
        tokio::time::sleep(3 * check_interval).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain(), node_2.domain()], 3);
    }

    #[tokio::test]
    async fn test_routing_with_no_healthy_nodes_returns_an_error() {
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // A single seed node which is initially healthy.
        fetcher.overwrite_nodes(vec![node_1.clone()]);
        checker.overwrite_healthy_nodes(vec![node_1.clone()]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider =
            DynamicRouteProviderBuilder::new(snapshot, vec![node_1.clone()], Arc::new(client))
                .with_fetcher(fetcher)
                .with_checker(checker.clone())
                .with_fetch_period(fetch_interval)
                .with_check_period(check_interval)
                .build()
                .await;
        let route_provider = Arc::new(route_provider);

        // Test 1: multiple route() calls return a single domain=ic0.app, as the seed is healthy.
        tokio::time::sleep(2 * check_interval).await;
        let routed_domains = route_n_times(3, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain()], 3);

        // Test 2: calls to route() return an error, as no healthy nodes exist.
        checker.overwrite_healthy_nodes(vec![]);
        tokio::time::sleep(2 * check_interval).await;
        for _ in 0..4 {
            let result = route_provider.route();
            assert_eq!(
                result.unwrap_err(),
                AgentError::RouteProviderError("No healthy API nodes found.".to_string())
            );
        }
    }

    #[tokio::test]
    async fn test_route_with_no_healthy_seeds_errors() {
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // No healthy seed nodes present, this should lead to errors.
        fetcher.overwrite_nodes(vec![]);
        checker.overwrite_healthy_nodes(vec![]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider =
            DynamicRouteProviderBuilder::new(snapshot, vec![node_1.clone()], Arc::new(client))
                .with_fetcher(fetcher)
                .with_checker(checker)
                .with_fetch_period(fetch_interval)
                .with_check_period(check_interval)
                .build()
                .await;

        // Test: calls to route() return an error, as no healthy seeds exist.
        for _ in 0..4 {
            tokio::time::sleep(check_interval).await;
            let result = route_provider.route();
            assert_eq!(
                result.unwrap_err(),
                AgentError::RouteProviderError("No healthy API nodes found.".to_string())
            );
        }
    }

    #[tokio::test]
    async fn test_route_with_one_healthy_and_one_unhealthy_seed() {
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        let node_2 = Node::new("api1.com").unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // One healthy seed is present, it should be discovered during the initialization time.
        fetcher.overwrite_nodes(vec![node_1.clone(), node_2.clone()]);
        checker.overwrite_healthy_nodes(vec![node_1.clone()]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider = DynamicRouteProviderBuilder::new(
            snapshot,
            vec![node_1.clone(), node_2.clone()],
            Arc::new(client),
        )
        .with_fetcher(fetcher)
        .with_checker(checker.clone())
        .with_fetch_period(fetch_interval)
        .with_check_period(check_interval)
        .build()
        .await;
        let route_provider = Arc::new(route_provider);

        // Test 1: calls to route() return only a healthy seed ic0.app.
        let routed_domains = route_n_times(3, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain()], 3);

        // Test 2: calls to route() return two healthy seeds, as the unhealthy seed becomes healthy.
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_2.clone()]);
        tokio::time::sleep(2 * check_interval).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain(), node_2.domain()], 3);
    }

    #[tokio::test]
    async fn test_routing_with_an_empty_fetched_list_of_api_nodes() {
        // Check resiliency to an empty list of fetched API nodes (this should never happen in normal IC operation).
        // Setup.
        setup_tracing();
        let node_1 = Node::new(IC0_SEED_DOMAIN).unwrap();
        // Set nodes fetching params: topology, fetching periodicity.
        let fetcher = Arc::new(NodesFetcherMock::new());
        let fetch_interval = Duration::from_secs(2);
        // Set health checking params: healthy nodes, checking periodicity.
        let checker = Arc::new(NodeHealthCheckerMock::new());
        let check_interval = Duration::from_secs(1);
        // One healthy seed is initially present, but the topology has no node.
        fetcher.overwrite_nodes(vec![]);
        checker.overwrite_healthy_nodes(vec![node_1.clone()]);
        // Configure RouteProvider
        let snapshot = RoundRobinRoutingSnapshot::new();
        let client = Client::builder().build().unwrap();
        let route_provider =
            DynamicRouteProviderBuilder::new(snapshot, vec![node_1.clone()], Arc::new(client))
                .with_fetcher(fetcher.clone())
                .with_checker(checker.clone())
                .with_fetch_period(fetch_interval)
                .with_check_period(check_interval)
                .build()
                .await;
        let route_provider = Arc::new(route_provider);

        // This time span is required for the snapshot to be fully updated with the new nodes topology and health info.
        let snapshot_update_duration = fetch_interval + 2 * check_interval;

        // Test 1: multiple route() calls return a single domain=ic0.app.
        // HealthManagerActor shouldn't update the snapshot, if the list of fetched nodes is empty, thus we observe the healthy seed.
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(3, Arc::clone(&route_provider));
        assert_routed_domains(routed_domains, vec![node_1.domain()], 3);

        // Test 2: multiple route() calls should now return 3 different domains with equal fairness (repetition).
        // Three nodes are added to the topology, i.e. now the fetched nodes list is non-empty.
        let node_2 = Node::new("api1.com").unwrap();
        let node_3 = Node::new("api2.com").unwrap();
        fetcher.overwrite_nodes(vec![node_1.clone(), node_2.clone(), node_3.clone()]);
        checker.overwrite_healthy_nodes(vec![node_1.clone(), node_2.clone(), node_3.clone()]);
        tokio::time::sleep(snapshot_update_duration).await;
        let routed_domains = route_n_times(6, Arc::clone(&route_provider));
        assert_routed_domains(
            routed_domains,
            vec![node_1.domain(), node_2.domain(), node_3.domain()],
            2,
        );
    }
}

// - none of the seeds [] are healthy
// - none of the API node [] is healthy
// - return a vector of errors: HealthCheckErrors, FetchErrors, etc.



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/health_check.rs
================================================
use async_trait::async_trait;
use bytes::Bytes;
use futures_util::FutureExt;
use http::{Method, Request, StatusCode, Uri};
use std::{
    fmt::Debug,
    str::FromStr,
    sync::Arc,
    time::{Duration, Instant},
};
use stop_token::{StopSource, StopToken};

use crate::agent::{
    route_provider::dynamic_routing::{
        dynamic_route_provider::DynamicRouteProviderError,
        messages::{FetchedNodes, NodeHealthState},
        node::Node,
        snapshot::routing_snapshot::RoutingSnapshot,
        type_aliases::{AtomicSwap, ReceiverMpsc, ReceiverWatch, SenderMpsc},
    },
    HttpService,
};

const CHANNEL_BUFFER: usize = 128;

/// A trait representing a health check of the node.
#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
pub trait HealthCheck: Send + Sync + Debug {
    /// Checks the health of the node.
    async fn check(&self, node: &Node) -> Result<HealthCheckStatus, DynamicRouteProviderError>;
}

/// A struct representing the health check status of the node.
#[derive(Clone, PartialEq, Debug, Default)]
pub struct HealthCheckStatus {
    latency: Option<Duration>,
}

impl HealthCheckStatus {
    /// Creates a new `HealthCheckStatus` instance.
    pub fn new(latency: Option<Duration>) -> Self {
        Self { latency }
    }

    /// Checks if the node is healthy.
    pub fn is_healthy(&self) -> bool {
        self.latency.is_some()
    }

    /// Get the latency of the health check.
    pub fn latency(&self) -> Option<Duration> {
        self.latency
    }
}

/// A struct implementing the `HealthCheck` for the nodes.
#[derive(Debug)]
pub struct HealthChecker {
    http_client: Arc<dyn HttpService>,
    #[cfg(not(target_family = "wasm"))]
    timeout: Duration,
}

impl HealthChecker {
    /// Creates a new `HealthChecker` instance.
    pub fn new(
        http_client: Arc<dyn HttpService>,
        #[cfg(not(target_family = "wasm"))] timeout: Duration,
    ) -> Self {
        Self {
            http_client,
            #[cfg(not(target_family = "wasm"))]
            timeout,
        }
    }
}

const HEALTH_CHECKER: &str = "HealthChecker";

#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
impl HealthCheck for HealthChecker {
    #[allow(unused_mut)]
    async fn check(&self, node: &Node) -> Result<HealthCheckStatus, DynamicRouteProviderError> {
        // API boundary node exposes /health endpoint and should respond with 204 (No Content) if it's healthy.
        let uri = Uri::from_str(&format!("https://{}/health", node.domain())).unwrap();

        let request = Request::builder()
            .method(Method::GET)
            .uri(uri.clone())
            .body(Bytes::new())
            .unwrap();

        let start = Instant::now();
        #[cfg(not(target_family = "wasm"))]
        let response = tokio::time::timeout(
            self.timeout,
            self.http_client.call(&|| Ok(request.clone()), 1, None),
        )
        .await
        .map_err(|_| {
            DynamicRouteProviderError::HealthCheckError(format!("GET request to {uri} timed out"))
        })?;
        #[cfg(target_family = "wasm")]
        let response = self
            .http_client
            .call(&|| Ok(request.clone()), 1, None)
            .await;

        let response = response.map_err(|err| {
            DynamicRouteProviderError::HealthCheckError(format!(
                "Failed to execute GET request to {uri}: {err}"
            ))
        })?;
        let latency = start.elapsed();

        if response.status() != StatusCode::NO_CONTENT {
            let err_msg = format!(
                "{HEALTH_CHECKER}: Unexpected http status code {} for url={uri} received",
                response.status()
            );
            log!(error, err_msg);
            return Err(DynamicRouteProviderError::HealthCheckError(err_msg));
        }

        Ok(HealthCheckStatus::new(Some(latency)))
    }
}

#[allow(unused)]
const HEALTH_CHECK_ACTOR: &str = "HealthCheckActor";

/// A struct performing the health check of the node and sending the health status to the listener.
struct HealthCheckActor {
    /// The health checker.
    checker: Arc<dyn HealthCheck>,
    /// The period of the health check.
    period: Duration,
    /// The node to check.
    node: Node,
    /// The sender channel (listener) to send the health status.
    sender_channel: SenderMpsc<NodeHealthState>,
    /// The cancellation token of the actor.
    token: StopToken,
}

impl HealthCheckActor {
    fn new(
        checker: Arc<dyn HealthCheck>,
        period: Duration,
        node: Node,
        sender_channel: SenderMpsc<NodeHealthState>,
        token: StopToken,
    ) -> Self {
        Self {
            checker,
            period,
            node,
            sender_channel,
            token,
        }
    }

    /// Runs the actor.
    async fn run(self) {
        loop {
            let health = self.checker.check(&self.node).await.unwrap_or_default();
            let message = NodeHealthState {
                node: self.node.clone(),
                health,
            };
            // Inform the listener about node's health. It can only fail if the listener was closed/dropped.
            self.sender_channel
                .send(message)
                .await
                .expect("Failed to send node's health state");
            futures_util::select! {
                _ = crate::util::sleep(self.period).fuse() => {
                    continue;
                }
                _ = self.token.clone().fuse() => {
                    log!(info, "{HEALTH_CHECK_ACTOR}: was gracefully cancelled for node {:?}", self.node);
                    break;
                }
            }
        }
    }
}

/// The name of the health manager actor.
#[allow(unused)]
pub(super) const HEALTH_MANAGER_ACTOR: &str = "HealthManagerActor";

/// A struct managing the health checks of the nodes.
/// It receives the fetched nodes from the `NodesFetchActor` and starts the health checks for them.
/// It also receives the health status of the nodes from the `HealthCheckActor/s` and updates the routing snapshot.
pub(super) struct HealthManagerActor<S> {
    /// The health checker.
    checker: Arc<dyn HealthCheck>,
    /// The period of the health check.
    period: Duration,
    /// The routing snapshot, storing the nodes.   
    routing_snapshot: AtomicSwap<S>,
    /// The receiver channel to listen to the fetched nodes messages.
    fetch_receiver: ReceiverWatch<FetchedNodes>,
    /// The sender channel to send the health status of the nodes back to `HealthManagerActor`.
    check_sender: SenderMpsc<NodeHealthState>,
    /// The receiver channel to receive the health status of the nodes from the `HealthCheckActor/s`.
    check_receiver: ReceiverMpsc<NodeHealthState>,
    /// The sender channel to send the initialization status to `DynamicRouteProvider` (used only once in the init phase).
    init_sender: SenderMpsc<bool>,
    /// The cancellation token of the actor.
    token: StopToken,
    /// The cancellation token for all the health checks.
    nodes_token: StopSource,
    /// The flag indicating if this actor is initialized with healthy nodes.
    is_initialized: bool,
}

impl<S> HealthManagerActor<S>
where
    S: RoutingSnapshot,
{
    /// Creates a new `HealthManagerActor` instance.
    pub fn new(
        checker: Arc<dyn HealthCheck>,
        period: Duration,
        routing_snapshot: AtomicSwap<S>,
        fetch_receiver: ReceiverWatch<FetchedNodes>,
        init_sender: SenderMpsc<bool>,
        token: StopToken,
    ) -> Self {
        let (check_sender, check_receiver) = async_channel::bounded(CHANNEL_BUFFER);

        Self {
            checker,
            period,
            routing_snapshot,
            fetch_receiver,
            check_sender,
            check_receiver,
            init_sender,
            token,
            nodes_token: StopSource::new(),
            is_initialized: false,
        }
    }

    /// Runs the actor.
    pub async fn run(mut self) {
        loop {
            futures_util::select! {
                // Process a new array of fetched nodes from NodesFetchActor, if it appeared in the channel.
                result = self.fetch_receiver.recv().fuse() => {
                    let value = match result {
                        Ok(value) => value,
                        Err(_err) => {
                            log!(error, "{HEALTH_MANAGER_ACTOR}: nodes fetch sender has been dropped: {_err:?}");
                            continue;
                        }
                    };
                    // Get the latest value from the channel and mark it as seen.
                    let Some(FetchedNodes { nodes }) = value else { continue };
                    self.handle_fetch_update(nodes).await;
                }
                // Receive health check messages from all running HealthCheckActor/s.
                msg_opt = self.check_receiver.recv().fuse() => {
                    if let Ok(msg) = msg_opt {
                        self.handle_health_update(msg).await;
                    }
                }
                _ = self.token.clone().fuse() => {
                    self.stop_all_checks().await;
                    self.check_receiver.close();
                    log!(warn, "{HEALTH_MANAGER_ACTOR}: was gracefully cancelled, all nodes health checks stopped");
                    break;
                }
            }
        }
    }

    async fn handle_health_update(&mut self, msg: NodeHealthState) {
        let current_snapshot = self.routing_snapshot.load_full();
        let mut new_snapshot = (*current_snapshot).clone();
        new_snapshot.update_node(&msg.node, msg.health.clone());
        self.routing_snapshot.store(Arc::new(new_snapshot));
        if !self.is_initialized && msg.health.is_healthy() {
            self.is_initialized = true;
            // If TIMEOUT_AWAIT_HEALTHY_SEED has been exceeded, the receiver was dropped and send would thus fail. We ignore the failure.
            let _ = self.init_sender.send(true).await;
        }
    }

    async fn handle_fetch_update(&mut self, nodes: Vec<Node>) {
        if nodes.is_empty() {
            // This is a bug in the IC registry. There should be at least one API Boundary Node in the registry.
            // Updating nodes snapshot with an empty array, would lead to an irrecoverable error, as new nodes couldn't be fetched.
            // We avoid such updates and just wait for a non-empty list.
            log!(
                error,
                "{HEALTH_MANAGER_ACTOR}: list of fetched nodes is empty"
            );
            return;
        }
        log!(
            debug,
            "{HEALTH_MANAGER_ACTOR}: fetched nodes received {:?}",
            nodes
        );
        let current_snapshot = self.routing_snapshot.load_full();
        let mut new_snapshot = (*current_snapshot).clone();
        // If the snapshot has changed, store it and restart all node's health checks.
        if new_snapshot.sync_nodes(&nodes) {
            self.routing_snapshot.store(Arc::new(new_snapshot));
            self.stop_all_checks().await;
            self.start_checks(nodes.to_vec());
        }
    }

    fn start_checks(&mut self, nodes: Vec<Node>) {
        // Create a single cancellation token for all started health checks.
        self.nodes_token = StopSource::new();
        for node in nodes {
            log!(
                debug,
                "{HEALTH_MANAGER_ACTOR}: starting health check for node {node:?}"
            );
            let actor = HealthCheckActor::new(
                Arc::clone(&self.checker),
                self.period,
                node,
                self.check_sender.clone(),
                self.nodes_token.token(),
            );
            crate::util::spawn(async move { actor.run().await });
        }
    }

    async fn stop_all_checks(&mut self) {
        log!(
            warn,
            "{HEALTH_MANAGER_ACTOR}: stopping all running health checks"
        );
        self.nodes_token = StopSource::new();
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/messages.rs
================================================
use crate::agent::route_provider::dynamic_routing::{health_check::HealthCheckStatus, node::Node};

/// Represents a message with fetched nodes.
#[derive(Debug, Clone)]
pub struct FetchedNodes {
    /// The fetched nodes.
    pub nodes: Vec<Node>,
}

/// Represents a message with the health state of a node.
pub struct NodeHealthState {
    /// The node.
    pub node: Node,
    /// The health state of the node.
    pub health: HealthCheckStatus,
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/mod.rs
================================================
//! A dynamic routing provider for the Internet Computer (IC) Agent that enables resilient, adaptive request routing through API boundary nodes.
//!
//! The `DynamicRouteProvider` is an implementation of the [`RouteProvider`](super::RouteProvider) trait. It dynamically discovers and monitors API boundary nodes, filters out unhealthy nodes, and routes API calls across healthy nodes using configurable strategies such as round-robin or latency-based routing.
//! This ensures robust and performant interactions with the IC network by adapting to changes in node availability and topology.
//!
//! # Overview
//! The IC Agent is capable of dispatching API calls to destination endpoints exposing an [HTTPS interface](https://internetcomputer.org/docs/references/ic-interface-spec#http-interface). These endpoints can be:
//! 1. **Replica nodes**: part of the ICP.
//! 2. **API boundary nodes**: part of the ICP.
//! 3. **HTTP Gateways**: Third-party services that proxy requests to API boundary nodes, e.g., gateways hosted on the `ic0.app` domain.
//!
//! The Agent uses the [`RouteProvider`](super::RouteProvider) trait, namely its [`route()`](super::RouteProvider::route()) method to determine the destination endpoint for each call.
//! For example this trait is implemented for [`Url`](https://docs.rs/url/latest/url/) and [`RoundRobinRouteProvider`](super::RoundRobinRouteProvider).
//! The `DynamicRouteProvider` is a more complex implementation, which is intended to be used only for option (2), it provides:
//! - **Automatic API Node Discovery**: periodically fetches the latest API boundary node topology.
//! - **Health Monitoring**: Continuously checks health of all nodes in the topology.
//! - **Flexible Routing**: Directs requests to healthy nodes using built-in or custom strategies:
//!   - [`RoundRobinRoutingSnapshot`](snapshot::round_robin_routing::RoundRobinRoutingSnapshot): Evenly distributes requests across healthy nodes.
//!   - [`LatencyRoutingSnapshot`](snapshot::latency_based_routing::LatencyRoutingSnapshot): Prioritizes low-latency nodes via weighted round-robin, with optional penalties if nodes are unavailable within a sliding time window.
//! - **Customizability**: Supports custom node fetchers, health checkers, and routing logic.
//! # Usage
//! The `DynamicRouteProvider` can be used standalone or injected into the agent to enable dynamic routing. There are several ways to instantiate it:
//! 1. **Via high-Level Agent API**: Initializes the agent with built-in dynamic routing. This method is user-friendly but provides limited customization options.
//! 2. **Via [`DynamicRouteProviderBuilder`](dynamic_route_provider::DynamicRouteProviderBuilder)**: Creates a customized `DynamicRouteProvider` with a specific routing strategy and parameters.
//!
//! This instance can be used standalone or integrated into the agent via [`AgentBuilder::with_route_provider()`](super::super::AgentBuilder::with_route_provider).
//! ## Example: High-Level Agent API
//! ```rust
//! use anyhow::Result;
//! use ic_agent::Agent;
//! use url::Url;
//!
//! #[tokio::main]
//! async fn main() -> Result<()> {
//!     // Use the URL of an IC HTTP Gateway or even better - API boundary node as the initial seed
//!     let seed_url = Url::parse("https://ic0.app")?;
//!
//!     // The agent starts with the seed node and discovers healthy API nodes dynamically
//!     // Until then, requests go through the seed, but only if it's healthy.
//!     let agent = Agent::builder()
//!         .with_url(seed_url)
//!         .with_background_dynamic_routing()
//!         .build()?;
//!
//!     // ... use the agent for API calls
//!
//!     Ok(())
//! }
//! ```
//! **Note**: In the example above, `ic0.app` is used as a seed for initial topology discovery. However, it is not a true seed, as it is not an API boundary node in the ICP topology.
//! It will be discarded after the first successful discovery.
//! ## Example: Customized instantiation
//! ```rust
//! use std::{sync::Arc, time::Duration};
//!
//! use anyhow::Result;
//! use ic_agent::{
//!     agent::route_provider::{
//!         dynamic_routing::{
//!             dynamic_route_provider::{DynamicRouteProvider, DynamicRouteProviderBuilder},
//!             node::Node,
//!             snapshot::latency_based_routing::LatencyRoutingSnapshot,
//!         },
//!         RouteProvider,
//!     },
//!     Agent,
//! };
//! use reqwest::Client;
//!
//! #[tokio::main]
//! async fn main() -> Result<()> {
//!     // Choose a routing strategy: top 3 lowest-latency API boundary nodes selected via weighted round-robin
//!     let routing_strategy = LatencyRoutingSnapshot::new().set_k_top_nodes(3);
//!
//!     // Alternatively, use a basic round-robin routing across all healthy API boundary nodes
//!     // let routing_strategy = RoundRobinRoutingSnapshot::new();
//!
//!     // Or implement and provide your own custom routing strategy
//!
//!     // Seed nodes for initial topology discovery
//!     let seed_nodes = vec![
//!         Node::new("ic0.app")?,
//!         // Optional: add known API boundary nodes to improve resilience
//!         // Node::new("<api-boundary-node-domain>")?,
//!     ];
//!
//!     // HTTP client for health checks and topology discovery
//!     let client = Client::builder().build()?;
//!
//!     // Build dynamic route provider
//!     let route_provider: DynamicRouteProvider<LatencyRoutingSnapshot> =
//!         DynamicRouteProviderBuilder::new(routing_strategy, seed_nodes, Arc::new(client))
//!             // Set how often to fetch the latest API boundary node topology
//!             .with_fetch_period(Duration::from_secs(10))
//!             // Set how often to perform health checks on the API boundary nodes
//!             .with_check_period(Duration::from_secs(2))
//!             // Or optionally provide a custom node health checker implementation
//!             // .with_checker(custom_checker)
//!             // Or optionally provide a custom topology fetcher implementation
//!             // .with_fetcher(custom_fetcher)
//!             .build()
//!             .await;
//!
//!     // Example: generate routing URLs
//!     let url_1 = route_provider.route().expect("failed to get routing URL");
//!     eprintln!("Generated URL: {url_1}");
//!
//!     let url_2 = route_provider.route().expect("failed to get routing URL");
//!     eprintln!("Generated URL: {url_2}");
//!
//!     // Or inject route_provider into the agent for dynamic routing
//!     let agent = Agent::builder()
//!         .with_route_provider(route_provider)
//!         .build()?;
//!
//!     // ... use the agent for API calls
//!
//!     Ok(())
//! }
//! ```
//! # Implementation Details
//! The `DynamicRouteProvider` spawns two background services:
//! 1. `NodesFetchActor`: Periodically fetches the latest API boundary node topology and sends updates to the `HealthManagerActor`.
//! 2. `HealthManagerActor`: Manages health checks for nodes, starts and stops `HealthCheckActor`s and updates the routing table (routing snapshot) with health information.
//!
//! These background services ensure the routing table remains up-to-date.
//! # Configuration
//! The [`DynamicRouteProviderBuilder`](dynamic_route_provider::DynamicRouteProviderBuilder) allows customized instantiation of `DynamicRouteProvider`:
//! - **Fetch Period**: How often to fetch node topology (default: 5 seconds).
//! - **Health Check Period**: How often to check node health (default: 1 second).
//! - **Nodes Fetcher**: Custom implementation of the [`Fetch`](nodes_fetch::Fetch) trait for node discovery.
//! - **Health Checker**: Custom implementation of the [`HealthCheck`](health_check::HealthCheck) trait for health monitoring.
//! - **Routing Strategy**: Custom implementation of the [`RoutingSnapshot`](snapshot::routing_snapshot::RoutingSnapshot) trait for routing logic.
//!
//! Two built-in strategies are available: [`LatencyRoutingSnapshot`](snapshot::latency_based_routing::LatencyRoutingSnapshot) and [`RoundRobinRoutingSnapshot`](snapshot::round_robin_routing::RoundRobinRoutingSnapshot).
//!
//! # Error Handling
//! Errors during node fetching or health checking are encapsulated in the [`DynamicRouteProviderError`](dynamic_route_provider::DynamicRouteProviderError) enum:
//! - `NodesFetchError`: Occurs when fetching the topology fails.
//! - `HealthCheckError`: Occurs when node health checks fail.
//!
//! These errors are not propagated to the caller. Instead, they are logged internally using the `tracing` crate. To capture these errors, configure a `tracing` subscriber in your application.
//! If no healthy nodes are available, the [`route()`](super::RouteProvider::route()) method returns an [`AgentError::RouteProviderError`](super::super::agent_error::AgentError::RouteProviderError).
//! # Testing
//! The module includes comprehensive tests covering:
//! - Mainnet integration with dynamic node discovery.
//! - Routing behavior with topology and health updates.
//! - Edge cases like initially unhealthy seeds, no healthy nodes, and empty topology fetches.
//!
//! These tests ensure the `DynamicRouteProvider` behaves correctly in various scenarios.
pub mod dynamic_route_provider;
/// Health check implementation.
pub mod health_check;
/// Messages used in dynamic routing.
pub(super) mod messages;
/// Node implementation.
pub mod node;
/// Nodes fetch implementation.
pub mod nodes_fetch;
/// Routing snapshot implementation.
pub mod snapshot;
#[cfg(test)]
#[cfg_attr(target_family = "wasm", allow(unused))]
pub(super) mod test_utils;
/// Type aliases used in dynamic routing.
pub(super) mod type_aliases;



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/node.rs
================================================
use url::Url;

use crate::agent::ApiBoundaryNode;

/// Represents a node in the dynamic routing.
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Node {
    domain: String,
}

impl Node {
    /// Creates a new `Node` instance from the domain name.
    pub fn new(domain: impl Into<String>) -> Result<Self, url::ParseError> {
        let domain = domain.into();
        check_valid_domain(&domain)?;
        Ok(Self { domain })
    }

    /// Returns the domain name of the node.
    pub fn domain(&self) -> &str {
        &self.domain
    }
}

impl Node {
    /// Converts the node to a routing URL.
    pub fn to_routing_url(&self) -> Url {
        Url::parse(&format!("https://{}", self.domain)).expect("failed to parse URL")
    }
}

impl From<&Node> for Url {
    fn from(node: &Node) -> Self {
        // Parsing can't fail, as the domain was checked at node instantiation.
        Url::parse(&format!("https://{}", node.domain)).expect("failed to parse URL")
    }
}

impl TryFrom<ApiBoundaryNode> for Node {
    type Error = url::ParseError;

    fn try_from(value: ApiBoundaryNode) -> Result<Self, Self::Error> {
        Node::new(value.domain)
    }
}

/// Checks if the given domain is a valid URL.
fn check_valid_domain<S: AsRef<str>>(domain: S) -> Result<(), url::ParseError> {
    // Prepend scheme to make it a valid URL
    let url_string = format!("http://{}", domain.as_ref());
    Url::parse(&url_string)?;
    Ok(())
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/nodes_fetch.rs
================================================
use async_trait::async_trait;
use candid::Principal;
use futures_util::FutureExt;
use std::{fmt::Debug, sync::Arc, time::Duration};
use stop_token::StopToken;
use url::Url;

#[allow(unused)]
use crate::agent::route_provider::dynamic_routing::health_check::HEALTH_MANAGER_ACTOR;
use crate::agent::{
    route_provider::dynamic_routing::{
        dynamic_route_provider::DynamicRouteProviderError,
        messages::FetchedNodes,
        node::Node,
        snapshot::routing_snapshot::RoutingSnapshot,
        type_aliases::{AtomicSwap, SenderWatch},
    },
    Agent, HttpService,
};
#[allow(unused)]
const NODES_FETCH_ACTOR: &str = "NodesFetchActor";

/// Fetcher of nodes in the topology.
#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
pub trait Fetch: Sync + Send + Debug {
    /// Fetches the nodes from the topology.
    async fn fetch(&self, url: Url) -> Result<Vec<Node>, DynamicRouteProviderError>;
}

/// A struct representing the fetcher of the nodes from the topology.
#[derive(Debug)]
pub struct NodesFetcher {
    http_client: Arc<dyn HttpService>,
    subnet_id: Principal,
    // By default, the nodes fetcher is configured to talk to the mainnet of Internet Computer, and verifies responses using a hard-coded public key.
    // However, for testnets one can set up a custom public key.
    root_key: Option<Vec<u8>>,
}

impl NodesFetcher {
    /// Creates a new `NodesFetcher` instance.
    pub fn new(
        http_client: Arc<dyn HttpService>,
        subnet_id: Principal,
        root_key: Option<Vec<u8>>,
    ) -> Self {
        Self {
            http_client,
            subnet_id,
            root_key,
        }
    }
}

#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
impl Fetch for NodesFetcher {
    async fn fetch(&self, url: Url) -> Result<Vec<Node>, DynamicRouteProviderError> {
        let agent = Agent::builder()
            .with_url(url)
            .with_arc_http_middleware(self.http_client.clone())
            .build()
            .map_err(|err| {
                DynamicRouteProviderError::NodesFetchError(format!(
                    "Failed to build the agent: {err}"
                ))
            })?;
        if let Some(key) = self.root_key.clone() {
            agent.set_root_key(key);
        }
        let api_bns = agent
            .fetch_api_boundary_nodes_by_subnet_id(self.subnet_id)
            .await
            .map_err(|err| {
                DynamicRouteProviderError::NodesFetchError(format!(
                    "Failed to fetch API nodes: {err}"
                ))
            })?;
        // If some API BNs have invalid domain names, they are discarded.
        let nodes = api_bns
            .into_iter()
            .filter_map(|api_node| api_node.try_into().ok())
            .collect();
        return Ok(nodes);
    }
}

/// A struct representing the actor responsible for fetching existing nodes and communicating it with the listener.
pub(super) struct NodesFetchActor<S> {
    /// The fetcher object responsible for fetching the nodes.
    fetcher: Arc<dyn Fetch>,
    /// Time period between fetches.
    period: Duration,
    /// The interval to wait before retrying to fetch the nodes in case of failures.
    fetch_retry_interval: Duration,
    /// Communication channel with the listener.
    fetch_sender: SenderWatch<FetchedNodes>,
    /// The snapshot of the routing table.
    routing_snapshot: AtomicSwap<S>,
    /// The token to cancel/stop the actor.
    token: StopToken,
}

impl<S> NodesFetchActor<S>
where
    S: RoutingSnapshot,
{
    /// Creates a new `NodesFetchActor` instance.
    pub fn new(
        fetcher: Arc<dyn Fetch>,
        period: Duration,
        retry_interval: Duration,
        fetch_sender: SenderWatch<FetchedNodes>,
        snapshot: AtomicSwap<S>,
        token: StopToken,
    ) -> Self {
        Self {
            fetcher,
            period,
            fetch_retry_interval: retry_interval,
            fetch_sender,
            routing_snapshot: snapshot,
            token,
        }
    }

    /// Runs the actor.
    pub async fn run(self) {
        loop {
            // Retry until success:
            // - try to get a healthy node from the routing snapshot
            //   - if snapshot is empty, break the cycle and wait for the next fetch cycle
            // - using the healthy node, try to fetch nodes from topology
            //   - if failure, sleep and retry
            // - try send fetched nodes to the listener
            //   - failure should never happen, but we trace it if it does
            loop {
                let snapshot = self.routing_snapshot.load();
                if let Some(node) = snapshot.next_node() {
                    match self.fetcher.fetch((&node).into()).await {
                        Ok(nodes) => {
                            let msg = Some(FetchedNodes { nodes });
                            match self.fetch_sender.send(msg) {
                                Ok(()) => break, // message sent successfully, exist the loop
                                Err(_err) => {
                                    log!(error, "{NODES_FETCH_ACTOR}: failed to send results to {HEALTH_MANAGER_ACTOR}: {_err:?}");
                                }
                            }
                        }
                        Err(_err) => {
                            log!(
                                error,
                                "{NODES_FETCH_ACTOR}: failed to fetch nodes: {_err:?}"
                            );
                        }
                    };
                } else {
                    // No healthy nodes in the snapshot, break the cycle and wait for the next fetch cycle
                    log!(error, "{NODES_FETCH_ACTOR}: no nodes in the snapshot");
                    break;
                };
                log!(
                    warn,
                    "Retrying to fetch the nodes in {:?}",
                    self.fetch_retry_interval
                );
                crate::util::sleep(self.fetch_retry_interval).await;
            }
            futures_util::select! {
                _ = crate::util::sleep(self.period).fuse() => {
                    continue;
                }
                _ = self.token.clone().fuse() => {
                    log!(warn, "{NODES_FETCH_ACTOR}: was gracefully cancelled");
                    break;
                }
            }
        }
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/test_utils.rs
================================================
use std::collections::{HashMap, HashSet};
use std::time::Duration;
use std::{fmt::Debug, hash::Hash, sync::Arc};

use arc_swap::ArcSwap;
use async_trait::async_trait;
use url::Url;

use crate::agent::route_provider::{
    dynamic_routing::{
        dynamic_route_provider::DynamicRouteProviderError,
        health_check::{HealthCheck, HealthCheckStatus},
        node::Node,
        nodes_fetch::Fetch,
        type_aliases::AtomicSwap,
    },
    RouteProvider,
};

pub(super) fn route_n_times(n: usize, f: Arc<impl RouteProvider + ?Sized>) -> Vec<String> {
    (0..n)
        .map(|_| f.route().unwrap().domain().unwrap().to_string())
        .collect()
}

pub(super) fn assert_routed_domains<T>(
    actual: Vec<T>,
    expected: Vec<&str>,
    expected_repetitions: usize,
) where
    T: AsRef<str> + Eq + Hash + Debug + Ord,
{
    fn build_count_map<T>(items: &[T]) -> HashMap<&str, usize>
    where
        T: AsRef<str>,
    {
        items.iter().fold(HashMap::new(), |mut map, item| {
            *map.entry(item.as_ref()).or_insert(0) += 1;
            map
        })
    }
    let count_actual = build_count_map(&actual);
    let count_expected = build_count_map(&expected);

    let mut keys_actual = count_actual.keys().collect::<Vec<_>>();
    keys_actual.sort();
    let mut keys_expected = count_expected.keys().collect::<Vec<_>>();
    keys_expected.sort();
    // Assert all routed domains are present.
    assert_eq!(keys_actual, keys_expected);

    // Assert the expected repetition count of each routed domain.
    let actual_repetitions = count_actual.values().collect::<Vec<_>>();
    assert!(actual_repetitions
        .iter()
        .all(|&x| x == &expected_repetitions));
}

#[derive(Debug)]
pub(super) struct NodesFetcherMock {
    // A set of nodes, existing in the topology.
    pub nodes: AtomicSwap<Vec<Node>>,
}

#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
impl Fetch for NodesFetcherMock {
    async fn fetch(&self, _url: Url) -> Result<Vec<Node>, DynamicRouteProviderError> {
        let nodes = (*self.nodes.load_full()).clone();
        Ok(nodes)
    }
}

impl Default for NodesFetcherMock {
    fn default() -> Self {
        Self::new()
    }
}

impl NodesFetcherMock {
    pub fn new() -> Self {
        Self {
            nodes: Arc::new(ArcSwap::from_pointee(vec![])),
        }
    }

    pub fn overwrite_nodes(&self, nodes: Vec<Node>) {
        self.nodes.store(Arc::new(nodes));
    }
}

#[derive(Debug)]
pub(super) struct NodeHealthCheckerMock {
    healthy_nodes: Arc<ArcSwap<HashSet<Node>>>,
}

impl Default for NodeHealthCheckerMock {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg_attr(target_family = "wasm", async_trait(?Send))]
#[cfg_attr(not(target_family = "wasm"), async_trait)]
impl HealthCheck for NodeHealthCheckerMock {
    async fn check(&self, node: &Node) -> Result<HealthCheckStatus, DynamicRouteProviderError> {
        let nodes = self.healthy_nodes.load_full();
        let latency = match nodes.contains(node) {
            true => Some(Duration::from_secs(1)),
            false => None,
        };
        Ok(HealthCheckStatus::new(latency))
    }
}

impl NodeHealthCheckerMock {
    pub fn new() -> Self {
        Self {
            healthy_nodes: Arc::new(ArcSwap::from_pointee(HashSet::new())),
        }
    }

    pub fn overwrite_healthy_nodes(&self, healthy_nodes: Vec<Node>) {
        self.healthy_nodes
            .store(Arc::new(HashSet::from_iter(healthy_nodes)));
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/type_aliases.rs
================================================
use arc_swap::ArcSwap;
use std::sync::Arc;

/// A type alias for the sender end of a watch channel.
pub(super) type SenderWatch<T> = async_watch::Sender<Option<T>>;

/// A type alias for the receiver end of a watch channel.
pub(super) type ReceiverWatch<T> = async_watch::Receiver<Option<T>>;

/// A type alias for the sender end of a multi-producer, single-consumer channel.
pub(super) type SenderMpsc<T> = async_channel::Sender<T>;

/// A type alias for the receiver end of a multi-producer, single-consumer channel.
pub(super) type ReceiverMpsc<T> = async_channel::Receiver<T>;

/// A type alias for an atomic swap operation on a shared value.
pub(super) type AtomicSwap<T> = Arc<ArcSwap<T>>;



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/snapshot/latency_based_routing.rs
================================================
use std::{
    collections::{HashMap, HashSet, VecDeque},
    sync::Arc,
    time::Duration,
};

use arc_swap::ArcSwap;
use rand::Rng;

use crate::agent::route_provider::{
    dynamic_routing::{
        health_check::HealthCheckStatus, node::Node, snapshot::routing_snapshot::RoutingSnapshot,
    },
    RoutesStats,
};

// Determines the size of the sliding window used for storing latencies and availabilities of nodes.
const WINDOW_SIZE: usize = 15;
// Determines the decay rate of the exponential decay function, which is used for generating weights over the sliding window.
const LAMBDA_DECAY: f64 = 0.3;

/// Generates exponentially decaying weights for the sliding window.
/// Weights are higher for more recent observations and decay exponentially for older ones.
fn generate_exp_decaying_weights(n: usize, lambda: f64) -> Vec<f64> {
    let mut weights: Vec<f64> = Vec::with_capacity(n);
    for i in 0..n {
        let weight = (-lambda * i as f64).exp();
        weights.push(weight);
    }
    weights
}

/// A node candidate eligible for final routing selection based on its score.
///
/// # Overview
/// This struct represents a node that has passed initial pre-selection criteria and is part of the
/// routing candidate pool. The selection process happens in two phases:
/// 1. Pre-selection: depending on the settings, either the k-top nodes or all healthy nodes are chosen
/// 2. Final selection: a node is probabilistically selected from the candidate pool based on its score
#[derive(Clone, Debug)]
struct RoutingCandidateNode {
    node: Node,
    score: f64,
}

impl RoutingCandidateNode {
    fn new(node: Node, score: f64) -> Self {
        Self { node, score }
    }
}

// Stores node's meta information and metrics (latencies, availabilities).
// Routing nodes are probabilistically selected based on the score field.
#[derive(Clone, Debug)]
struct NodeMetrics {
    // Size of the sliding window used to store latencies and availabilities of the node.
    window_size: usize,
    /// Reflects the status of the most recent health check. It should be the same as the last element in `availabilities`.
    is_healthy: bool,
    /// Sliding window with latency measurements.
    latencies: VecDeque<f64>,
    /// Sliding window with availability measurements.
    availabilities: VecDeque<bool>,
    /// Overall score of the node. Calculated based on latencies and availabilities arrays. This score is used in `next_n_nodes()` method for the final nodes selection.
    score: f64,
}

impl NodeMetrics {
    pub fn new(window_size: usize) -> Self {
        Self {
            window_size,
            is_healthy: false,
            latencies: VecDeque::with_capacity(window_size + 1),
            availabilities: VecDeque::with_capacity(window_size + 1),
            score: 0.0,
        }
    }

    pub fn add_latency_measurement(&mut self, latency: Option<Duration>) {
        self.is_healthy = latency.is_some();
        if let Some(duration) = latency {
            self.latencies.push_back(duration.as_secs_f64());
            while self.latencies.len() > self.window_size {
                self.latencies.pop_front();
            }
            self.availabilities.push_back(true);
        } else {
            self.availabilities.push_back(false);
        }
        while self.availabilities.len() > self.window_size {
            self.availabilities.pop_front();
        }
    }
}

/// Computes the score of the node based on the latencies, availabilities and window weights.
/// `window_weights_sum` is passed for efficiency reasons, as it is pre-calculated.
fn compute_score(
    window_weights: &[f64],
    window_weights_sum: f64,
    availabilities: &VecDeque<bool>,
    latencies: &VecDeque<f64>,
    use_availability_penalty: bool,
) -> f64 {
    let weights_size = window_weights.len();
    let availabilities_size = availabilities.len();
    let latencies_size = latencies.len();

    if weights_size < availabilities_size {
        panic!(
            "Configuration error: Weights array of size {weights_size} is smaller than array of availabilities of size {availabilities_size}.",
        );
    } else if weights_size < latencies_size {
        panic!(
            "Configuration error: Weights array of size {weights_size} is smaller than array of latencies of size {latencies_size}.",
        );
    }

    // Compute normalized availability score [0.0, 1.0].
    let score_a = if !use_availability_penalty {
        1.0
    } else if availabilities.is_empty() {
        0.0
    } else {
        let mut score = 0.0;

        // Compute weighted score. Weights are applied in reverse order.
        for (idx, availability) in availabilities.iter().rev().enumerate() {
            score += window_weights[idx] * (*availability as u8 as f64);
        }

        // Normalize the score.
        let weights_sum = if availabilities_size < weights_size {
            // Use partial sum of weights, if the window is not full.
            let partial_weights_sum: f64 = window_weights.iter().take(availabilities_size).sum();
            partial_weights_sum
        } else {
            // Use pre-calculated sum, if the window is full.
            window_weights_sum
        };

        score /= weights_sum;

        score
    };

    // Compute latency score (not normalized).
    let score_l = if latencies.is_empty() {
        0.0
    } else {
        let mut score = 0.0;

        // Compute weighted score. Weights are applied in reverse order. Latency is inverted, so that smaller latencies have higher score.
        for (idx, latency) in latencies.iter().rev().enumerate() {
            score += window_weights[idx] / latency;
        }

        let weights_sum = if latencies_size < weights_size {
            let partial_weights_sum: f64 = window_weights.iter().take(latencies.len()).sum();
            partial_weights_sum
        } else {
            // Use pre-calculated sum.
            window_weights_sum
        };

        score /= weights_sum;

        score
    };

    // Combine availability and latency scores via product to emphasize the importance of both metrics.
    score_l * score_a
}

/// # Latency-based dynamic routing
///
/// This module implements a routing strategy that uses weighted random selection of nodes based on their historical data (latencies and availabilities).
///
/// Summary of the routing strategy:
/// - Uses sliding windows for storing latencies and availabilities of each node
/// - Latency and availability scores are first computed separately from the sliding windows using an additional array of weights, allowing prioritization of more recent observations. By default, exponentially decaying weights are used.
/// - The final overall score of each node is computed as a product of latency and availability scores, namely `score = score_l * score_a`
/// - Nodes pre-selection phase for routing candidate pool (snapshot):
///   - Criteria: if k-top-nodes setting is enabled, then only k nodes with highest scores are filtered into the routing candidate pool (snapshot), otherwise all healthy nodes are used
///   - Trigger conditions: topology updates, node health check status updates
/// - Final selection of nodes for routing from the candidate pool is probabilistic and is proportional to the score of the node
///
/// ## Configuration Options
/// - `k_top_nodes`: Limit routing to only top k nodes with highest score
/// - `use_availability_penalty`: Whether to penalize nodes for being unavailable
/// - Custom window weights can be provided for specialized decay functions
#[derive(Default, Debug, Clone)]
pub struct LatencyRoutingSnapshot {
    // If set, only k nodes with best scores are used for routing
    k_top_nodes: Option<usize>,
    // Stores all existing nodes in the topology along with their historical data (latencies and availabilities)
    existing_nodes: HashMap<Node, NodeMetrics>,
    // Snapshot of nodes, which are pre-selected as candidates for routing. Snapshot is published via publish_routing_nodes() when either: topology changes or a health check of some node is received.
    routing_candidates: Arc<ArcSwap<Vec<RoutingCandidateNode>>>,
    // Weights used to compute the availability score of a node.
    window_weights: Vec<f64>,
    // Pre-computed weights sum, passed for efficiency purpose as this sum doesn't change.
    window_weights_sum: f64,
    // Whether or not penalize nodes score for being unavailable
    use_availability_penalty: bool,
}

/// Implementation of the `LatencyRoutingSnapshot`.
impl LatencyRoutingSnapshot {
    /// Creates a new `LatencyRoutingSnapshot` with default configuration.
    pub fn new() -> Self {
        // Weights are ordered from left to right, where the leftmost weight is for the most recent health check.
        let window_weights = generate_exp_decaying_weights(WINDOW_SIZE, LAMBDA_DECAY);
        // Pre-calculate the sum of weights for efficiency reasons.
        let window_weights_sum: f64 = window_weights.iter().sum();

        Self {
            k_top_nodes: None,
            existing_nodes: HashMap::new(),
            routing_candidates: Arc::new(ArcSwap::new(vec![].into())),
            use_availability_penalty: true,
            window_weights,
            window_weights_sum,
        }
    }

    /// Sets whether to use only k nodes with the highest score for routing.
    #[allow(unused)]
    pub fn set_k_top_nodes(mut self, k_top_nodes: usize) -> Self {
        self.k_top_nodes = Some(k_top_nodes);
        self
    }

    /// Sets whether to use availability penalty in the score computation.
    #[allow(unused)]
    pub fn set_availability_penalty(mut self, use_penalty: bool) -> Self {
        self.use_availability_penalty = use_penalty;
        self
    }

    /// Sets the weights for the sliding window.
    /// The weights are ordered from left to right, where the leftmost weight is for the most recent health check.
    #[allow(unused)]
    pub fn set_window_weights(mut self, weights: &[f64]) -> Self {
        self.window_weights_sum = weights.iter().sum();
        self.window_weights = weights.to_vec();
        self
    }

    /// Atomically updates the `routing_candidates`
    fn publish_routing_candidates(&self) {
        let mut routing_candidates: Vec<RoutingCandidateNode> = self
            .existing_nodes
            .iter()
            .filter(|(_, v)| v.is_healthy)
            .map(|(k, v)| RoutingCandidateNode::new(k.clone(), v.score))
            .collect();

        // In case requests are routed to only k-top nodes, pre-select these candidates
        if let Some(k_top) = self.k_top_nodes {
            routing_candidates.sort_by(|a, b| {
                b.score
                    .partial_cmp(&a.score)
                    .unwrap_or(std::cmp::Ordering::Equal)
            });

            if routing_candidates.len() > k_top {
                routing_candidates.truncate(k_top);
            }
        }
        // Atomically update the table of routing candidates
        self.routing_candidates.store(Arc::new(routing_candidates));
    }
}

/// Helper function to sample nodes based on their weights.
/// Node index is selected based on the input number in range [0.0, 1.0]
#[inline(always)]
fn weighted_sample(weighted_nodes: &[RoutingCandidateNode], number: f64) -> Option<usize> {
    if !(0.0..=1.0).contains(&number) || weighted_nodes.is_empty() {
        return None;
    }
    let sum: f64 = weighted_nodes.iter().map(|n| n.score).sum();

    if sum == 0.0 {
        return None;
    }

    let mut weighted_number = number * sum;
    for (idx, node) in weighted_nodes.iter().enumerate() {
        weighted_number -= node.score;
        if weighted_number <= 0.0 {
            return Some(idx);
        }
    }

    // If this part is reached due to floating-point precision, return the last index
    Some(weighted_nodes.len() - 1)
}

impl RoutingSnapshot for LatencyRoutingSnapshot {
    fn has_nodes(&self) -> bool {
        !self.routing_candidates.load().is_empty()
    }

    fn next_node(&self) -> Option<Node> {
        self.next_n_nodes(1).into_iter().next()
    }

    // Uses weighted random sampling algorithm n times. Node can be selected at most once (sampling without replacement).
    fn next_n_nodes(&self, n: usize) -> Vec<Node> {
        if n == 0 {
            return Vec::new();
        }

        let mut routing_candidates: Vec<RoutingCandidateNode> =
            self.routing_candidates.load().as_ref().clone();

        // Limit the number of returned nodes to the number of available nodes
        let n = std::cmp::min(n, routing_candidates.len());
        let mut nodes = Vec::with_capacity(n);
        let mut rng = rand::thread_rng();

        for _ in 0..n {
            let rand_num = rng.gen::<f64>();
            if let Some(idx) = weighted_sample(routing_candidates.as_slice(), rand_num) {
                let removed_node = routing_candidates.swap_remove(idx);
                nodes.push(removed_node.node);
            }
        }

        nodes
    }

    fn sync_nodes(&mut self, nodes: &[Node]) -> bool {
        let new_nodes: HashSet<&Node> = nodes.iter().collect();
        let mut has_changes = false;

        // Remove nodes that are no longer present
        self.existing_nodes.retain(|node, _| {
            let keep = new_nodes.contains(node);
            if !keep {
                has_changes = true;
            }
            keep
        });

        // Add new nodes that don't exist yet
        for node in nodes {
            if !self.existing_nodes.contains_key(node) {
                self.existing_nodes
                    .insert(node.clone(), NodeMetrics::new(self.window_weights.len()));
                has_changes = true;
            }
        }

        if has_changes {
            self.publish_routing_candidates();
        }

        has_changes
    }

    fn update_node(&mut self, node: &Node, health: HealthCheckStatus) -> bool {
        // Get mut reference to the existing node metrics or return false if not found
        let updated_node: &mut NodeMetrics = match self.existing_nodes.get_mut(node) {
            Some(metrics) => metrics,
            None => return false,
        };
        // Update the node's metrics
        updated_node.add_latency_measurement(health.latency());

        updated_node.score = compute_score(
            &self.window_weights,
            self.window_weights_sum,
            &updated_node.availabilities,
            &updated_node.latencies,
            self.use_availability_penalty,
        );

        self.publish_routing_candidates();

        true
    }

    fn routes_stats(&self) -> RoutesStats {
        RoutesStats::new(
            self.existing_nodes.len(),
            Some(self.routing_candidates.load().len()),
        )
    }
}

#[cfg(test)]
mod tests {
    use std::{
        collections::{HashMap, VecDeque},
        time::Duration,
    };

    use crate::agent::route_provider::{
        dynamic_routing::{
            health_check::HealthCheckStatus,
            node::Node,
            snapshot::{
                latency_based_routing::{
                    compute_score, weighted_sample, LatencyRoutingSnapshot, NodeMetrics,
                    RoutingCandidateNode,
                },
                routing_snapshot::RoutingSnapshot,
            },
        },
        RoutesStats,
    };

    #[test]
    fn test_snapshot_init() {
        // Arrange
        let snapshot = LatencyRoutingSnapshot::new();
        // Assert
        assert!(snapshot.existing_nodes.is_empty());
        assert!(!snapshot.has_nodes());
        assert!(snapshot.next_node().is_none());
        assert!(snapshot.next_n_nodes(1).is_empty());
        assert_eq!(snapshot.routes_stats(), RoutesStats::new(0, Some(0)));
    }

    #[test]
    fn test_update_for_non_existing_node_fails() {
        // Arrange
        let mut snapshot = LatencyRoutingSnapshot::new();
        let node = Node::new("api1.com").unwrap();
        let health = HealthCheckStatus::new(Some(Duration::from_secs(1)));
        // Act
        let is_updated = snapshot.update_node(&node, health);
        // Assert
        assert!(!is_updated);
        assert!(snapshot.existing_nodes.is_empty());
        assert!(!snapshot.has_nodes());
        assert!(snapshot.next_node().is_none());
        assert_eq!(snapshot.routes_stats(), RoutesStats::new(0, Some(0)));
    }

    #[test]
    fn test_update_for_existing_node_succeeds() {
        // Arrange
        let mut snapshot = LatencyRoutingSnapshot::new()
            .set_window_weights(&[2.0, 1.0])
            .set_availability_penalty(false);
        let node = Node::new("api1.com").unwrap();
        let health = HealthCheckStatus::new(Some(Duration::from_secs(1)));
        snapshot.sync_nodes(&[node.clone()]);
        assert_eq!(snapshot.routes_stats(), RoutesStats::new(1, Some(0)));
        // Check first update
        let is_updated = snapshot.update_node(&node, health);
        assert!(is_updated);
        assert!(snapshot.has_nodes());
        let metrics = snapshot.existing_nodes.get(&node).unwrap();
        assert_eq!(metrics.score, (2.0 / 1.0) / 2.0);
        assert_eq!(snapshot.next_node().unwrap(), node);
        assert_eq!(snapshot.routes_stats(), RoutesStats::new(1, Some(1)));
        // Check second update
        let health = HealthCheckStatus::new(Some(Duration::from_secs(2)));
        let is_updated = snapshot.update_node(&node, health);
        assert!(is_updated);
        let metrics = snapshot.existing_nodes.get(&node).unwrap();
        assert_eq!(metrics.score, (2.0 / 2.0 + 1.0 / 1.0) / 3.0);
        // Check third update with none
        let health = HealthCheckStatus::new(None);
        let is_updated = snapshot.update_node(&node, health);
        assert!(is_updated);
        let metrics = snapshot.existing_nodes.get(&node).unwrap();
        assert_eq!(metrics.score, (2.0 / 2.0 + 1.0 / 1.0) / 3.0);
        assert!(!snapshot.has_nodes());
        assert_eq!(snapshot.existing_nodes.len(), 1);
        assert!(snapshot.next_node().is_none());
        assert_eq!(snapshot.routes_stats(), RoutesStats::new(1, Some(0)));
        // Check fourth update
        let health = HealthCheckStatus::new(Some(Duration::from_secs(3)));
        let is_updated = snapshot.update_node(&node, health);
        assert!(is_updated);
        let metrics = snapshot.existing_nodes.get(&node).unwrap();
        assert_eq!(metrics.score, (2.0 / 3.0 + 1.0 / 2.0) / 3.0);
    }

    #[test]
    fn test_sync_node_scenarios() {
        // Arrange
        let mut snapshot = LatencyRoutingSnapshot::new();
        let node_1 = Node::new("api1.com").unwrap();
        // Sync with node_1
        let nodes_changed = snapshot.sync_nodes(&[node_1.clone()]);
        assert!(nodes_changed);
        assert!(snapshot.existing_nodes.contains_key(&node_1));
        assert!(!snapshot.has_nodes());
        // Sync with node_1 again
        let nodes_changed = snapshot.sync_nodes(&[node_1.clone()]);
        assert!(!nodes_changed);
        assert_eq!(
            snapshot.existing_nodes.keys().collect::<Vec<_>>(),
            vec![&node_1]
        );
        // Sync with node_2
        let node_2 = Node::new("api2.com").unwrap();
        let nodes_changed = snapshot.sync_nodes(&[node_2.clone()]);
        assert!(nodes_changed);
        assert_eq!(
            snapshot.existing_nodes.keys().collect::<Vec<_>>(),
            vec![&node_2]
        );
        assert!(!snapshot.has_nodes());
        // Sync with [node_2, node_3]
        let node_3 = Node::new("api3.com").unwrap();
        let nodes_changed = snapshot.sync_nodes(&[node_3.clone(), node_2.clone()]);
        assert!(nodes_changed);
        let mut keys = snapshot.existing_nodes.keys().collect::<Vec<_>>();
        keys.sort_by(|a, b| a.domain().cmp(b.domain()));
        assert_eq!(keys, vec![&node_2, &node_3]);
        assert!(!snapshot.has_nodes());
        // Sync with [node_2, node_3] again
        let nodes_changed = snapshot.sync_nodes(&[node_3.clone(), node_2.clone()]);
        assert!(!nodes_changed);
        let mut keys = snapshot.existing_nodes.keys().collect::<Vec<_>>();
        keys.sort_by(|a, b| a.domain().cmp(b.domain()));
        assert_eq!(keys, vec![&node_2, &node_3]);
        assert!(!snapshot.has_nodes());
        // Sync with []
        let nodes_changed = snapshot.sync_nodes(&[]);
        assert!(nodes_changed);
        assert!(snapshot.existing_nodes.is_empty());
        // Sync with [] again
        let nodes_changed = snapshot.sync_nodes(&[]);
        assert!(!nodes_changed);
        assert!(snapshot.existing_nodes.is_empty());
        assert!(!snapshot.has_nodes());
    }

    #[test]
    fn test_weighted_sample() {
        let node = Node::new("api1.com").unwrap();
        // Case 1: empty array
        let arr: &[RoutingCandidateNode] = &[];
        let idx = weighted_sample(arr, 0.5);
        assert_eq!(idx, None);
        // Case 2: single element in array
        let arr = &[RoutingCandidateNode::new(node.clone(), 1.0)];
        let idx = weighted_sample(arr, 0.0);
        assert_eq!(idx, Some(0));
        let idx = weighted_sample(arr, 1.0);
        assert_eq!(idx, Some(0));
        // check bounds
        let idx = weighted_sample(arr, -1.0);
        assert_eq!(idx, None);
        let idx = weighted_sample(arr, 1.1);
        assert_eq!(idx, None);
        // Case 3: two elements in array (second element has twice the weight of the first)
        let arr = &[
            RoutingCandidateNode::new(node.clone(), 1.0),
            RoutingCandidateNode::new(node.clone(), 2.0),
        ]; // prefixed_sum = [1.0, 3.0]
        let idx = weighted_sample(arr, 0.0); // 0.0 * 3.0 < 1.0
        assert_eq!(idx, Some(0));
        let idx = weighted_sample(arr, 0.33); // 0.33 * 3.0 < 1.0
        assert_eq!(idx, Some(0)); // selection probability ~0.33
        let idx = weighted_sample(arr, 0.35); // 0.35 * 3.0 > 1.0
        assert_eq!(idx, Some(1)); // selection probability ~0.66
        let idx = weighted_sample(arr, 1.0); // 1.0 * 3.0 > 1.0
        assert_eq!(idx, Some(1));
        // check bounds
        let idx = weighted_sample(arr, -1.0);
        assert_eq!(idx, None);
        let idx = weighted_sample(arr, 1.1);
        assert_eq!(idx, None);
        // Case 4: four elements in array
        let arr = &[
            RoutingCandidateNode::new(node.clone(), 1.0),
            RoutingCandidateNode::new(node.clone(), 2.0),
            RoutingCandidateNode::new(node.clone(), 1.5),
            RoutingCandidateNode::new(node.clone(), 2.5),
        ]; // prefixed_sum = [1.0, 3.0, 4.5, 7.0]
        let idx = weighted_sample(arr, 0.14); // 0.14 * 7 < 1.0
        assert_eq!(idx, Some(0)); // probability ~0.14
        let idx = weighted_sample(arr, 0.15); // 0.15 * 7 > 1.0
        assert_eq!(idx, Some(1));
        let idx = weighted_sample(arr, 0.42); // 0.42 * 7 < 3.0
        assert_eq!(idx, Some(1)); // probability ~0.28
        let idx = weighted_sample(arr, 0.43); // 0.43 * 7 > 3.0
        assert_eq!(idx, Some(2));
        let idx = weighted_sample(arr, 0.64); // 0.64 * 7 < 4.5
        assert_eq!(idx, Some(2)); // probability ~0.22
        let idx = weighted_sample(arr, 0.65); // 0.65 * 7 > 4.5
        assert_eq!(idx, Some(3));
        let idx = weighted_sample(arr, 0.99);
        assert_eq!(idx, Some(3)); // probability ~0.35
                                  // check bounds
        let idx = weighted_sample(arr, -1.0);
        assert_eq!(idx, None);
        let idx = weighted_sample(arr, 1.1);
        assert_eq!(idx, None);
    }

    #[test]
    fn test_compute_score_with_penalty() {
        let use_penalty = true;

        // Test empty arrays
        let weights: &[f64] = &[];
        let weights_sum: f64 = weights.iter().sum();
        let availabilities = VecDeque::new();
        let latencies = VecDeque::new();

        let score = compute_score(
            weights,
            weights_sum,
            &availabilities,
            &latencies,
            use_penalty,
        );
        assert_eq!(score, 0.0);

        // Test arrays with one element.
        let weights: &[f64] = &[2.0, 1.0];
        let weights_sum: f64 = weights.iter().sum();
        let availabilities = vec![true].into();
        let latencies = vec![2.0].into();
        let score = compute_score(
            weights,
            weights_sum,
            &availabilities,
            &latencies,
            use_penalty,
        );
        let score_l = (2.0 / 2.0) / 2.0;
        let score_a = 1.0;
        assert_eq!(score, score_l * score_a);

        // Test arrays with two element.
        let weights: &[f64] = &[2.0, 1.0];
        let weights_sum: f64 = weights.iter().sum();
        let availabilities = vec![true, false].into();
        let latencies = vec![1.0, 2.0].into();
        let score = compute_score(
            weights,
            weights_sum,
            &availabilities,
            &latencies,
            use_penalty,
        );
        let score_l = (2.0 / 2.0 + 1.0 / 1.0) / weights_sum;
        let score_a = (2.0 * 0.0 + 1.0 * 1.0) / weights_sum;
        assert_eq!(score, score_l * score_a);

        // Test arrays of different sizes.
        let weights: &[f64] = &[3.0, 2.0, 1.0];
        let weights_sum: f64 = weights.iter().sum();
        let availabilities = vec![true, false, true].into();
        let latencies = vec![1.0, 2.0].into();
        let score = compute_score(
            weights,
            weights_sum,
            &availabilities,
            &latencies,
            use_penalty,
        );
        let score_l = (3.0 / 2.0 + 2.0 / 1.0) / 5.0;
        let score_a = (3.0 * 1.0 + 2.0 * 0.0 + 1.0 * 1.0) / weights_sum;
        assert_eq!(score, score_l * score_a);
    }

    #[test]
    #[ignore]
    // This test is for manual runs to see the statistics for nodes selection probability.
    fn test_stats_for_next_n_nodes() {
        // Arrange
        let mut snapshot = LatencyRoutingSnapshot::new();

        let window_size = 1;

        let node_1 = Node::new("api1.com").unwrap();
        let node_2 = Node::new("api2.com").unwrap();
        let node_3 = Node::new("api3.com").unwrap();
        let node_4 = Node::new("api4.com").unwrap();

        let mut metrics_1 = NodeMetrics::new(window_size);
        let mut metrics_2 = NodeMetrics::new(window_size);
        let mut metrics_3 = NodeMetrics::new(window_size);
        let mut metrics_4 = NodeMetrics::new(window_size);

        metrics_1.is_healthy = true;
        metrics_2.is_healthy = true;
        metrics_3.is_healthy = true;
        metrics_4.is_healthy = false;
        metrics_1.score = 16.0;
        metrics_2.score = 8.0;
        metrics_3.score = 4.0;
        // even though the score is high, this node should never be selected as it is unhealthy
        metrics_4.score = 30.0;

        snapshot.existing_nodes.extend(vec![
            (node_1, metrics_1),
            (node_2, metrics_2),
            (node_3, metrics_3),
            (node_4, metrics_4),
        ]);
        snapshot.publish_routing_candidates();
        let mut stats = HashMap::new();
        let experiments = 30;
        let select_nodes_count = 1;
        for i in 0..experiments {
            let nodes = snapshot.next_n_nodes(select_nodes_count);
            println!("Experiment {i}: selected nodes {nodes:?}");
            for item in nodes.into_iter() {
                *stats.entry(item).or_insert(1) += 1;
            }
        }
        for (node, count) in stats {
            println!(
                "Node {:?} is selected with probability {}",
                node.domain(),
                count as f64 / experiments as f64
            );
        }
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/snapshot/mod.rs
================================================
/// Snapshot of the routing table.
pub mod latency_based_routing;
/// Node implementation.
pub mod round_robin_routing;
/// Routing snapshot implementation.
pub mod routing_snapshot;



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/snapshot/round_robin_routing.rs
================================================
use std::{
    collections::HashSet,
    sync::{
        atomic::{AtomicUsize, Ordering},
        Arc,
    },
};

use crate::agent::route_provider::{
    dynamic_routing::{
        health_check::HealthCheckStatus, node::Node, snapshot::routing_snapshot::RoutingSnapshot,
    },
    RoutesStats,
};

/// Routing snapshot, which samples nodes in a round-robin fashion.
#[derive(Default, Debug, Clone)]
pub struct RoundRobinRoutingSnapshot {
    current_idx: Arc<AtomicUsize>,
    healthy_nodes: HashSet<Node>,
    existing_nodes: HashSet<Node>,
}

impl RoundRobinRoutingSnapshot {
    /// Creates a new instance of `RoundRobinRoutingSnapshot`.
    pub fn new() -> Self {
        Self {
            current_idx: Arc::new(AtomicUsize::new(0)),
            healthy_nodes: HashSet::new(),
            existing_nodes: HashSet::new(),
        }
    }
}

impl RoutingSnapshot for RoundRobinRoutingSnapshot {
    fn has_nodes(&self) -> bool {
        !self.healthy_nodes.is_empty()
    }

    fn next_node(&self) -> Option<Node> {
        if self.healthy_nodes.is_empty() {
            return None;
        }
        let prev_idx = self.current_idx.fetch_add(1, Ordering::Relaxed);
        self.healthy_nodes
            .iter()
            .nth(prev_idx % self.healthy_nodes.len())
            .cloned()
    }

    fn next_n_nodes(&self, n: usize) -> Vec<Node> {
        if n == 0 {
            return Vec::new();
        }

        let healthy_nodes = Vec::from_iter(self.healthy_nodes.clone());
        let healthy_count = healthy_nodes.len();

        if n >= healthy_count {
            return healthy_nodes.clone();
        }

        let idx = self.current_idx.fetch_add(n, Ordering::Relaxed) % healthy_count;
        let mut nodes = Vec::with_capacity(n);

        if healthy_count - idx >= n {
            nodes.extend_from_slice(&healthy_nodes[idx..idx + n]);
        } else {
            nodes.extend_from_slice(&healthy_nodes[idx..]);
            nodes.extend_from_slice(&healthy_nodes[..n - nodes.len()]);
        }

        nodes
    }

    fn sync_nodes(&mut self, nodes: &[Node]) -> bool {
        let new_nodes = HashSet::from_iter(nodes.iter().cloned());
        // Find nodes removed from topology.
        let nodes_removed: Vec<_> = self
            .existing_nodes
            .difference(&new_nodes)
            .cloned()
            .collect();
        let has_removed_nodes = !nodes_removed.is_empty();
        // Find nodes added to topology.
        let nodes_added: Vec<_> = new_nodes
            .difference(&self.existing_nodes)
            .cloned()
            .collect();
        let has_added_nodes = !nodes_added.is_empty();
        // NOTE: newly added nodes will appear in the healthy_nodes later.
        // This happens after the first node health check round and a consequent update_node() invocation.
        self.existing_nodes.extend(nodes_added);
        nodes_removed.iter().for_each(|node| {
            self.existing_nodes.remove(node);
            self.healthy_nodes.remove(node);
        });

        has_added_nodes || has_removed_nodes
    }

    fn update_node(&mut self, node: &Node, health: HealthCheckStatus) -> bool {
        if !self.existing_nodes.contains(node) {
            return false;
        }
        if health.is_healthy() {
            self.healthy_nodes.insert(node.clone())
        } else {
            self.healthy_nodes.remove(node)
        }
    }

    fn routes_stats(&self) -> RoutesStats {
        RoutesStats::new(self.existing_nodes.len(), Some(self.healthy_nodes.len()))
    }
}

#[cfg(test)]
mod tests {
    use std::collections::HashMap;
    use std::time::Duration;
    use std::{collections::HashSet, sync::atomic::Ordering};

    use crate::agent::route_provider::dynamic_routing::{
        health_check::HealthCheckStatus,
        node::Node,
        snapshot::{
            round_robin_routing::RoundRobinRoutingSnapshot, routing_snapshot::RoutingSnapshot,
        },
    };

    #[test]
    fn test_snapshot_init() {
        // Arrange
        let snapshot = RoundRobinRoutingSnapshot::new();
        // Assert
        assert!(snapshot.healthy_nodes.is_empty());
        assert!(snapshot.existing_nodes.is_empty());
        assert!(!snapshot.has_nodes());
        assert_eq!(snapshot.current_idx.load(Ordering::SeqCst), 0);
        assert!(snapshot.next_node().is_none());
    }

    #[test]
    fn test_update_of_non_existing_node_always_returns_false() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        // This node is not present in existing_nodes
        let node = Node::new("api1.com").unwrap();
        let healthy = HealthCheckStatus::new(Some(Duration::from_secs(1)));
        let unhealthy = HealthCheckStatus::new(None);
        // Act 1
        let is_updated = snapshot.update_node(&node, healthy);
        // Assert
        assert!(!is_updated);
        assert!(snapshot.existing_nodes.is_empty());
        assert!(snapshot.next_node().is_none());
        // Act 2
        let is_updated = snapshot.update_node(&node, unhealthy);
        // Assert
        assert!(!is_updated);
        assert!(snapshot.existing_nodes.is_empty());
        assert!(snapshot.next_node().is_none());
    }

    #[test]
    fn test_update_of_existing_unhealthy_node_with_healthy_node_returns_true() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        let node = Node::new("api1.com").unwrap();
        // node is present in existing_nodes, but not in healthy_nodes
        snapshot.existing_nodes.insert(node.clone());
        let health = HealthCheckStatus::new(Some(Duration::from_secs(1)));
        // Act
        let is_updated = snapshot.update_node(&node, health);
        assert!(is_updated);
        assert!(snapshot.has_nodes());
        assert_eq!(snapshot.next_node().unwrap(), node);
        assert_eq!(snapshot.current_idx.load(Ordering::SeqCst), 1);
    }

    #[test]
    fn test_update_of_existing_healthy_node_with_unhealthy_node_returns_true() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        let node = Node::new("api1.com").unwrap();
        snapshot.existing_nodes.insert(node.clone());
        snapshot.healthy_nodes.insert(node.clone());
        let unhealthy = HealthCheckStatus::new(None);
        // Act
        let is_updated = snapshot.update_node(&node, unhealthy);
        assert!(is_updated);
        assert!(!snapshot.has_nodes());
        assert!(snapshot.next_node().is_none());
    }

    #[test]
    fn test_sync_node_scenarios() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        let node_1 = Node::new("api1.com").unwrap();
        // Sync with node_1
        let nodes_changed = snapshot.sync_nodes(&[node_1.clone()]);
        assert!(nodes_changed);
        assert!(snapshot.healthy_nodes.is_empty());
        assert_eq!(
            snapshot.existing_nodes,
            HashSet::from_iter(vec![node_1.clone()])
        );
        // Add node_1 to healthy_nodes manually
        snapshot.healthy_nodes.insert(node_1.clone());
        // Sync with node_1 again
        let nodes_changed = snapshot.sync_nodes(&[node_1.clone()]);
        assert!(!nodes_changed);
        assert_eq!(
            snapshot.existing_nodes,
            HashSet::from_iter(vec![node_1.clone()])
        );
        assert_eq!(snapshot.healthy_nodes, HashSet::from_iter(vec![node_1]));
        // Sync with node_2
        let node_2 = Node::new("api2.com").unwrap();
        let nodes_changed = snapshot.sync_nodes(&[node_2.clone()]);
        assert!(nodes_changed);
        assert_eq!(
            snapshot.existing_nodes,
            HashSet::from_iter(vec![node_2.clone()])
        );
        // Make sure node_1 was removed from healthy nodes
        assert!(snapshot.healthy_nodes.is_empty());
        // Add node_2 to healthy_nodes manually
        snapshot.healthy_nodes.insert(node_2.clone());
        // Sync with [node_2, node_3]
        let node_3 = Node::new("api3.com").unwrap();
        let nodes_changed = snapshot.sync_nodes(&[node_3.clone(), node_2.clone()]);
        assert!(nodes_changed);
        assert_eq!(
            snapshot.existing_nodes,
            HashSet::from_iter(vec![node_3.clone(), node_2.clone()])
        );
        assert_eq!(snapshot.healthy_nodes, HashSet::from_iter(vec![node_2]));
        snapshot.healthy_nodes.insert(node_3);
        // Sync with []
        let nodes_changed = snapshot.sync_nodes(&[]);
        assert!(nodes_changed);
        assert!(snapshot.existing_nodes.is_empty());
        // Make sure all nodes were removed from the healthy_nodes
        assert!(snapshot.healthy_nodes.is_empty());
        // Sync with [] again
        let nodes_changed = snapshot.sync_nodes(&[]);
        assert!(!nodes_changed);
        assert!(snapshot.existing_nodes.is_empty());
    }

    #[test]
    fn test_next_node() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        let node_1 = Node::new("api1.com").unwrap();
        let node_2 = Node::new("api2.com").unwrap();
        let node_3 = Node::new("api3.com").unwrap();
        let nodes = vec![node_1, node_2, node_3];
        snapshot.existing_nodes.extend(nodes.clone());
        snapshot.healthy_nodes.extend(nodes.clone());
        // Act
        let n = 6;
        let mut count_map = HashMap::new();
        for _ in 0..n {
            let node = snapshot.next_node().unwrap();
            count_map.entry(node).and_modify(|v| *v += 1).or_insert(1);
        }
        // Assert each node was returned 2 times
        let k = 2;
        assert_eq!(
            count_map.len(),
            nodes.len(),
            "The number of unique elements is not {}",
            nodes.len()
        );
        for (item, &count) in &count_map {
            assert_eq!(
                count, k,
                "Element {:?} does not appear exactly {} times",
                item, k
            );
        }
    }

    #[test]
    fn test_n_nodes() {
        // Arrange
        let mut snapshot = RoundRobinRoutingSnapshot::new();
        let node_1 = Node::new("api1.com").unwrap();
        let node_2 = Node::new("api2.com").unwrap();
        let node_3 = Node::new("api3.com").unwrap();
        let node_4 = Node::new("api4.com").unwrap();
        let node_5 = Node::new("api5.com").unwrap();
        let nodes = vec![
            node_1.clone(),
            node_2.clone(),
            node_3.clone(),
            node_4.clone(),
            node_5.clone(),
        ];
        snapshot.healthy_nodes.extend(nodes.clone());
        // First call
        let mut n_nodes: Vec<_> = snapshot.next_n_nodes(3);
        // Second call
        n_nodes.extend(snapshot.next_n_nodes(3));
        // Third call
        n_nodes.extend(snapshot.next_n_nodes(4));
        // Fourth call
        n_nodes.extend(snapshot.next_n_nodes(5));
        // Assert each node was returned 3 times
        let k = 3;
        let mut count_map = HashMap::new();
        for item in n_nodes.iter() {
            count_map.entry(item).and_modify(|v| *v += 1).or_insert(1);
        }
        assert_eq!(
            count_map.len(),
            nodes.len(),
            "The number of unique elements is not {}",
            nodes.len()
        );
        for (item, &count) in &count_map {
            assert_eq!(
                count, k,
                "Element {:?} does not appear exactly {} times",
                item, k
            );
        }
    }
}



================================================
FILE: ic-agent/src/agent/route_provider/dynamic_routing/snapshot/routing_snapshot.rs
================================================
use std::fmt::Debug;

use crate::agent::route_provider::{
    dynamic_routing::{health_check::HealthCheckStatus, node::Node},
    RoutesStats,
};

/// A trait for interacting with the snapshot of nodes (routing table).
pub trait RoutingSnapshot: Send + Sync + Clone + Debug {
    /// Returns `true` if the snapshot has nodes.
    #[allow(unused)]
    fn has_nodes(&self) -> bool;
    /// Get next node from the snapshot.
    fn next_node(&self) -> Option<Node>;
    /// Get up to n different nodes from the snapshot.
    fn next_n_nodes(&self, n: usize) -> Vec<Node>;
    /// Syncs the nodes in the snapshot with the provided list of nodes, returning `true` if the snapshot was updated.
    fn sync_nodes(&mut self, nodes: &[Node]) -> bool;
    /// Updates the health status of a specific node, returning `true` if the node was found and updated.
    fn update_node(&mut self, node: &Node, health: HealthCheckStatus) -> bool;
    /// Returns statistics about the routes (nodes).
    fn routes_stats(&self) -> RoutesStats;
}



================================================
FILE: ic-agent/src/identity/anonymous.rs
================================================
use crate::{agent::EnvelopeContent, export::Principal, identity::Identity, Signature};

/// The anonymous identity.
///
/// The caller will be represented as [`Principal::anonymous`], or `2vxsx-fae`.
#[derive(Debug, Copy, Clone)]
pub struct AnonymousIdentity;

impl Identity for AnonymousIdentity {
    fn sender(&self) -> Result<Principal, String> {
        Ok(Principal::anonymous())
    }

    fn public_key(&self) -> Option<Vec<u8>> {
        None
    }

    fn sign(&self, _: &EnvelopeContent) -> Result<Signature, String> {
        Ok(Signature {
            signature: None,
            public_key: None,
            delegations: None,
        })
    }

    fn sign_arbitrary(&self, _: &[u8]) -> Result<Signature, String> {
        Ok(Signature {
            public_key: None,
            signature: None,
            delegations: None,
        })
    }
}



================================================
FILE: ic-agent/src/identity/basic.rs
================================================
use crate::{agent::EnvelopeContent, export::Principal, Identity, Signature};

#[cfg(feature = "pem")]
use crate::identity::error::PemError;

use ic_ed25519::PrivateKey;

use std::fmt;

use super::Delegation;

/// A cryptographic identity which signs using an Ed25519 key pair.
///
/// The caller will be represented via [`Principal::self_authenticating`], which contains the SHA-224 hash of the public key.
pub struct BasicIdentity {
    private_key: KeyCompat,
    der_encoded_public_key: Vec<u8>,
}

impl fmt::Debug for BasicIdentity {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("BasicIdentity")
            .field("der_encoded_public_key", &self.der_encoded_public_key)
            .finish_non_exhaustive()
    }
}

impl BasicIdentity {
    /// Create a `BasicIdentity` from reading a PEM file at the path.
    #[cfg(feature = "pem")]
    pub fn from_pem_file<P: AsRef<std::path::Path>>(file_path: P) -> Result<Self, PemError> {
        Self::from_pem(std::fs::File::open(file_path)?)
    }

    /// Create a `BasicIdentity` from reading a PEM File from a Reader.
    #[cfg(feature = "pem")]
    pub fn from_pem<R: std::io::Read>(pem_reader: R) -> Result<Self, PemError> {
        use der::{asn1::OctetString, Decode, ErrorKind, SliceReader, Tag, TagNumber};
        use pkcs8::PrivateKeyInfo;

        let bytes: Vec<u8> = pem_reader.bytes().collect::<Result<_, _>>()?;
        let pem = pem::parse(bytes)?;
        let pki_res = PrivateKeyInfo::decode(&mut SliceReader::new(pem.contents())?);
        let mut truncated;
        let pki = match pki_res {
            Ok(pki) => pki,
            Err(e) => {
                if e.kind()
                    == (ErrorKind::Noncanonical {
                        tag: Tag::ContextSpecific {
                            constructed: true,
                            number: TagNumber::new(1),
                        },
                    })
                {
                    // Very old versions of dfx generated nonconforming containers. They can only be imported if the extra data is removed.
                    truncated = pem.into_contents();
                    if truncated[48..52] != *b"\xA1\x23\x03\x21" {
                        return Err(e.into());
                    }
                    // hatchet surgery
                    truncated.truncate(48);
                    truncated[1] = 46;
                    truncated[4] = 0;
                    PrivateKeyInfo::decode(&mut SliceReader::new(&truncated)?).map_err(|_| e)?
                } else {
                    return Err(e.into());
                }
            }
        };
        let decoded_key = OctetString::from_der(pki.private_key)?; // ed25519 uses an octet string within another octet string
        let key_len = decoded_key.as_bytes().len();
        if key_len != 32 {
            Err(PemError::InvalidPrivateKey(format!(
                "Ed25519 expects a 32 octets private key, but got {key_len} octets",
            )))
        } else {
            let raw_key: [u8; 32] = decoded_key.as_bytes().try_into().unwrap();
            Ok(Self::from_raw_key(&raw_key))
        }
    }

    /// Create a `BasicIdentity` from a raw 32-byte private key as described in RFC 8032 5.1.5.
    pub fn from_raw_key(key: &[u8; 32]) -> Self {
        let private_key = PrivateKey::deserialize_raw_32(key);
        let public_key = private_key.public_key();
        let der_encoded_public_key = public_key.serialize_rfc8410_der();
        Self {
            private_key: KeyCompat::Standard(private_key),
            der_encoded_public_key,
        }
    }

    /// Create a `BasicIdentity` from a `SigningKey` from `ed25519-consensus`.
    ///
    /// # Note
    ///
    /// This constructor is kept for backwards compatibility.
    /// The signing won't use `ed25519-consensus` anymore.
    #[deprecated(since = "0.41.0", note = "use BasicIdentity::from_raw_key instead")]
    pub fn from_signing_key(key: ed25519_consensus::SigningKey) -> Self {
        let raw_key = key.to_bytes();
        Self::from_raw_key(&raw_key)
    }

    /// Create a `BasicIdentity` from an `Ed25519KeyPair` from `ring`.
    #[cfg(feature = "ring")]
    pub fn from_key_pair(key_pair: ring::signature::Ed25519KeyPair) -> Self {
        use ic_ed25519::PublicKey;
        use ring::signature::KeyPair;
        let raw_public_key = key_pair.public_key().as_ref().to_vec();
        // Unwrap safe: we trust that the public key is valid, as it comes from a valid key pair.
        let public_key = PublicKey::deserialize_raw(&raw_public_key).unwrap();
        let der_encoded_public_key = public_key.serialize_rfc8410_der();
        Self {
            private_key: KeyCompat::Ring(key_pair),
            der_encoded_public_key,
        }
    }
}

enum KeyCompat {
    /// ic_ed25519::PrivateKey
    Standard(PrivateKey),
    #[cfg(feature = "ring")]
    Ring(ring::signature::Ed25519KeyPair),
}

impl KeyCompat {
    fn sign(&self, payload: &[u8]) -> Vec<u8> {
        match self {
            Self::Standard(k) => k.sign_message(payload).to_vec(),
            #[cfg(feature = "ring")]
            Self::Ring(k) => k.sign(payload).as_ref().to_vec(),
        }
    }
}

impl Identity for BasicIdentity {
    fn sender(&self) -> Result<Principal, String> {
        Ok(Principal::self_authenticating(&self.der_encoded_public_key))
    }

    fn public_key(&self) -> Option<Vec<u8>> {
        Some(self.der_encoded_public_key.clone())
    }

    fn sign(&self, content: &EnvelopeContent) -> Result<Signature, String> {
        self.sign_arbitrary(&content.to_request_id().signable())
    }

    fn sign_delegation(&self, content: &Delegation) -> Result<Signature, String> {
        self.sign_arbitrary(&content.signable())
    }

    fn sign_arbitrary(&self, content: &[u8]) -> Result<Signature, String> {
        let signature = self.private_key.sign(content);
        Ok(Signature {
            signature: Some(signature),
            public_key: self.public_key(),
            delegations: None,
        })
    }
}



================================================
FILE: ic-agent/src/identity/delegated.rs
================================================
use candid::Principal;
use der::{Decode, SliceReader};
use ecdsa::signature::Verifier;
use k256::Secp256k1;
use p256::NistP256;
use pkcs8::{spki::SubjectPublicKeyInfoRef, AssociatedOid, ObjectIdentifier};
use sec1::{EcParameters, EncodedPoint};

use crate::{agent::EnvelopeContent, Signature};

use super::{error::DelegationError, Delegation, Identity, SignedDelegation};

/// An identity that has been delegated the authority to authenticate as a different principal.
pub struct DelegatedIdentity {
    to: Box<dyn Identity>,
    chain: Vec<SignedDelegation>,
    from_key: Vec<u8>,
}

impl DelegatedIdentity {
    /// Creates a delegated identity that signs using `to`, for the principal corresponding to the public key `from_key`.
    ///
    /// `chain` must be a list of delegations connecting `from_key` to `to.public_key()`, and in that order;
    /// otherwise, this function will return an error.
    pub fn new(
        from_key: Vec<u8>,
        to: Box<dyn Identity>,
        chain: Vec<SignedDelegation>,
    ) -> Result<Self, DelegationError> {
        let mut last_verified = &from_key;
        for delegation in &chain {
            let spki = SubjectPublicKeyInfoRef::decode(
                &mut SliceReader::new(&last_verified[..]).map_err(|_| DelegationError::Parse)?,
            )
            .map_err(|_| DelegationError::Parse)?;
            if spki.algorithm.oid == elliptic_curve::ALGORITHM_OID {
                let Some(params) = spki.algorithm.parameters else {
                    return Err(DelegationError::UnknownAlgorithm);
                };
                let params = params
                    .decode_as::<EcParameters>()
                    .map_err(|_| DelegationError::Parse)?;
                let curve = params
                    .named_curve()
                    .ok_or(DelegationError::UnknownAlgorithm)?;
                if curve == Secp256k1::OID {
                    let pt = EncodedPoint::from_bytes(spki.subject_public_key.raw_bytes())
                        .map_err(|_| DelegationError::Parse)?;
                    let vk = k256::ecdsa::VerifyingKey::from_encoded_point(&pt)
                        .map_err(|_| DelegationError::Parse)?;
                    let sig = k256::ecdsa::Signature::try_from(&delegation.signature[..])
                        .map_err(|_| DelegationError::Parse)?;
                    vk.verify(&delegation.delegation.signable(), &sig)
                        .map_err(|_| DelegationError::BrokenChain {
                            from: last_verified.clone(),
                            to: Some(delegation.delegation.clone()),
                        })?;
                } else if curve == NistP256::OID {
                    let pt = EncodedPoint::from_bytes(spki.subject_public_key.raw_bytes())
                        .map_err(|_| DelegationError::Parse)?;
                    let vk = p256::ecdsa::VerifyingKey::from_encoded_point(&pt)
                        .map_err(|_| DelegationError::Parse)?;
                    let sig = p256::ecdsa::Signature::try_from(&delegation.signature[..])
                        .map_err(|_| DelegationError::Parse)?;
                    vk.verify(&delegation.delegation.signable(), &sig)
                        .map_err(|_| DelegationError::BrokenChain {
                            from: last_verified.clone(),
                            to: Some(delegation.delegation.clone()),
                        })?;
                } else {
                    return Err(DelegationError::UnknownAlgorithm);
                }
            } else if spki.algorithm.oid == ObjectIdentifier::new_unwrap("1.3.101.112") {
                let vk =
                    ic_ed25519::PublicKey::deserialize_raw(spki.subject_public_key.raw_bytes())
                        .map_err(|_| DelegationError::Parse)?;
                vk.verify_signature(&delegation.delegation.signable(), &delegation.signature[..])
                    .map_err(|_| DelegationError::BrokenChain {
                        from: last_verified.clone(),
                        to: Some(delegation.delegation.clone()),
                    })?;
            } else {
                return Err(DelegationError::UnknownAlgorithm);
            }
            last_verified = &delegation.delegation.pubkey;
        }
        let delegated_principal = Principal::self_authenticating(last_verified);
        if delegated_principal != to.sender().map_err(DelegationError::IdentityError)? {
            return Err(DelegationError::BrokenChain {
                from: last_verified.clone(),
                to: None,
            });
        }

        Ok(Self::new_unchecked(from_key, to, chain))
    }

    /// Creates a delegated identity that signs using `to`, for the principal corresponding to the public key `from_key`.
    ///
    /// `chain` must be a list of delegations connecting `from_key` to `to.public_key()`, and in that order;
    /// otherwise, the replica will reject this delegation when used as an identity.
    pub fn new_unchecked(
        from_key: Vec<u8>,
        to: Box<dyn Identity>,
        chain: Vec<SignedDelegation>,
    ) -> Self {
        Self {
            to,
            chain,
            from_key,
        }
    }

    fn chain_signature(&self, mut sig: Signature) -> Signature {
        sig.public_key = self.public_key();
        sig.delegations
            .get_or_insert(vec![])
            .extend(self.chain.iter().cloned());
        sig
    }
}

impl Identity for DelegatedIdentity {
    fn sender(&self) -> Result<Principal, String> {
        Ok(Principal::self_authenticating(&self.from_key))
    }
    fn public_key(&self) -> Option<Vec<u8>> {
        Some(self.from_key.clone())
    }
    fn sign(&self, content: &EnvelopeContent) -> Result<Signature, String> {
        self.to.sign(content).map(|sig| self.chain_signature(sig))
    }
    fn sign_delegation(&self, content: &Delegation) -> Result<Signature, String> {
        self.to
            .sign_delegation(content)
            .map(|sig| self.chain_signature(sig))
    }
    fn sign_arbitrary(&self, content: &[u8]) -> Result<Signature, String> {
        self.to
            .sign_arbitrary(content)
            .map(|sig| self.chain_signature(sig))
    }
    fn delegation_chain(&self) -> Vec<SignedDelegation> {
        let mut chain = self.to.delegation_chain();
        chain.extend(self.chain.iter().cloned());
        chain
    }
}



================================================
FILE: ic-agent/src/identity/error.rs
================================================
use ic_transport_types::Delegation;
use thiserror::Error;

/// An error happened while reading a PEM file.
#[cfg(feature = "pem")]
#[derive(Error, Debug)]
pub enum PemError {
    /// An error occurred with disk I/O.
    #[error(transparent)]
    Io(#[from] std::io::Error),

    /// An unsupported curve was detected
    #[error("Only {0} curve is supported: {1:?}")]
    UnsupportedKeyCurve(String, Vec<u8>),

    /// An error occurred while reading the file in PEM format.
    #[cfg(feature = "pem")]
    #[error("An error occurred while reading the file: {0}")]
    PemError(#[from] pem::PemError),

    /// An error occurred while reading the file in DER format.
    #[cfg(feature = "pem")]
    #[error("An error occurred while reading the file: {0}")]
    DerError(#[from] der::Error),

    /// The private key is invalid.
    #[error("Invalid private key: {0}")]
    InvalidPrivateKey(String),

    /// The key was rejected by k256.
    #[error("A key was rejected by k256: {0}")]
    ErrorStack(#[from] k256::pkcs8::Error),
}

/// An error occurred constructing a [`DelegatedIdentity`](super::delegated::DelegatedIdentity).
#[derive(Error, Debug)]
pub enum DelegationError {
    /// Parsing error in delegation bytes.
    #[error("A delegation could not be parsed")]
    Parse,
    /// A key in the chain did not match the signature of the next chain link.
    #[error("A link was missing in the delegation chain")]
    BrokenChain {
        /// The key that should have matched the next delegation
        from: Vec<u8>,
        /// The delegation that didn't match, or `None` if the `Identity` didn't match
        to: Option<Delegation>,
    },
    /// A key with an unknown algorithm was used. The IC supports Ed25519, secp256k1, and prime256v1, and in ECDSA the curve must be specified.
    #[error("The delegation chain contained a key with an unknown algorithm")]
    UnknownAlgorithm,
    /// One of `Identity`'s functions returned an error.
    #[error("A delegated-to identity encountered an error: {0}")]
    IdentityError(String),
}



================================================
FILE: ic-agent/src/identity/mod.rs
================================================
//! Types and traits dealing with identity across the Internet Computer.
use std::sync::Arc;

use crate::{agent::EnvelopeContent, export::Principal};

pub(crate) mod anonymous;
pub(crate) mod basic;
pub(crate) mod delegated;
pub(crate) mod error;
pub(crate) mod prime256v1;
pub(crate) mod secp256k1;

#[doc(inline)]
pub use anonymous::AnonymousIdentity;
#[doc(inline)]
pub use basic::BasicIdentity;
#[doc(inline)]
pub use delegated::DelegatedIdentity;
#[doc(inline)]
pub use error::DelegationError;
#[doc(inline)]
pub use ic_transport_types::{Delegation, SignedDelegation};
#[doc(inline)]
pub use prime256v1::Prime256v1Identity;
#[doc(inline)]
pub use secp256k1::Secp256k1Identity;

#[cfg(feature = "pem")]
#[doc(inline)]
pub use error::PemError;

/// A cryptographic signature, signed by an [Identity].
#[derive(Clone, Debug)]
pub struct Signature {
    /// This is the DER-encoded public key.
    pub public_key: Option<Vec<u8>>,
    /// The signature bytes.
    pub signature: Option<Vec<u8>>,
    /// A list of delegations connecting `public_key` to the key that signed `signature`, and in that order.
    pub delegations: Option<Vec<SignedDelegation>>,
}

/// An `Identity` produces [`Signatures`](Signature) for requests or delegations. It knows or
/// represents the [`Principal`] of the sender.
///
/// [`Agents`](crate::Agent) are assigned a single `Identity` object, but there can be multiple
/// identities used.
pub trait Identity: Send + Sync {
    /// Returns a sender, ie. the Principal ID that is used to sign a request.
    ///
    /// Only one sender can be used per request.
    fn sender(&self) -> Result<Principal, String>;

    /// Produce the public key commonly returned in [`Signature`].
    ///
    /// Should only return `None` if `sign` would do the same.
    fn public_key(&self) -> Option<Vec<u8>>;

    /// Sign a request ID derived from a content map.
    ///
    /// Implementors should call `content.to_request_id().signable()` for the actual bytes that need to be signed.
    fn sign(&self, content: &EnvelopeContent) -> Result<Signature, String>;

    /// Sign a delegation to let another key be used to authenticate [`sender`](Identity::sender).
    ///
    /// Not all `Identity` implementations support this operation, though all `ic-agent` implementations other than `AnonymousIdentity` do.
    ///
    /// Implementors should call `content.signable()` for the actual bytes that need to be signed.
    fn sign_delegation(&self, content: &Delegation) -> Result<Signature, String> {
        let _ = content; // silence unused warning
        Err(String::from("unsupported"))
    }

    /// Sign arbitrary bytes.
    ///
    /// Not all `Identity` implementations support this operation, though all `ic-agent` implementations do.
    fn sign_arbitrary(&self, content: &[u8]) -> Result<Signature, String> {
        let _ = content; // silence unused warning
        Err(String::from("unsupported"))
    }

    /// A list of signed delegations connecting [`sender`](Identity::sender)
    /// to [`public_key`](Identity::public_key), and in that order.
    fn delegation_chain(&self) -> Vec<SignedDelegation> {
        vec![]
    }
}

macro_rules! delegating_impl {
    ($implementor:ty, $name:ident => $self_expr:expr) => {
        impl Identity for $implementor {
            fn sender(&$name) -> Result<Principal, String> {
                $self_expr.sender()
            }

            fn public_key(&$name) -> Option<Vec<u8>> {
                $self_expr.public_key()
            }

            fn sign(&$name, content: &EnvelopeContent) -> Result<Signature, String> {
                $self_expr.sign(content)
            }

            fn sign_delegation(&$name, content: &Delegation) -> Result<Signature, String> {
                $self_expr.sign_delegation(content)
            }

            fn sign_arbitrary(&$name, content: &[u8]) -> Result<Signature, String> {
                $self_expr.sign_arbitrary(content)
            }

            fn delegation_chain(&$name) -> Vec<SignedDelegation> {
                $self_expr.delegation_chain()
            }
        }
    };
}

delegating_impl!(Box<dyn Identity>, self => **self);
delegating_impl!(Arc<dyn Identity>, self => **self);
delegating_impl!(&dyn Identity, self => *self);



================================================
FILE: ic-agent/src/identity/prime256v1.rs
================================================
use crate::{agent::EnvelopeContent, export::Principal, Identity, Signature};

#[cfg(feature = "pem")]
use crate::identity::error::PemError;

use p256::{
    ecdsa::{self, signature::Signer, SigningKey, VerifyingKey},
    pkcs8::{Document, EncodePublicKey},
    SecretKey,
};
#[cfg(feature = "pem")]
use std::{fs::File, io, path::Path};

use super::Delegation;

/// A cryptographic identity based on the Prime256v1 elliptic curve.
///
/// The caller will be represented via [`Principal::self_authenticating`], which contains the SHA-224 hash of the public key.
#[derive(Clone, Debug)]
pub struct Prime256v1Identity {
    private_key: SigningKey,
    _public_key: VerifyingKey,
    der_encoded_public_key: Document,
}

impl Prime256v1Identity {
    /// Creates an identity from a PEM file. Shorthand for calling `from_pem` with `std::fs::read`.
    #[cfg(feature = "pem")]
    pub fn from_pem_file<P: AsRef<Path>>(file_path: P) -> Result<Self, PemError> {
        Self::from_pem(File::open(file_path)?)
    }

    /// Creates an identity from a PEM certificate.
    #[cfg(feature = "pem")]
    pub fn from_pem<R: io::Read>(pem_reader: R) -> Result<Self, PemError> {
        use sec1::{pem::PemLabel, EcPrivateKey};

        const EC_PARAMETERS: &str = "EC PARAMETERS";
        const PRIME256V1: &[u8] = b"\x06\x08\x2a\x86\x48\xce\x3d\x03\x01\x07";

        let contents = pem_reader.bytes().collect::<Result<Vec<u8>, io::Error>>()?;

        for pem in pem::parse_many(contents)? {
            if pem.tag() == EC_PARAMETERS && pem.contents() != PRIME256V1 {
                return Err(PemError::UnsupportedKeyCurve(
                    "prime256v1".to_string(),
                    pem.contents().to_vec(),
                ));
            }

            if pem.tag() != EcPrivateKey::PEM_LABEL {
                continue;
            }
            let private_key =
                SecretKey::from_sec1_der(pem.contents()).map_err(|_| pkcs8::Error::KeyMalformed)?;
            return Ok(Self::from_private_key(private_key));
        }
        Err(pem::PemError::MissingData.into())
    }

    /// Creates an identity from a private key.
    pub fn from_private_key(private_key: SecretKey) -> Self {
        let public_key = private_key.public_key();
        let der_encoded_public_key = public_key
            .to_public_key_der()
            .expect("Cannot DER encode prime256v1 public key.");
        Self {
            private_key: private_key.into(),
            _public_key: public_key.into(),
            der_encoded_public_key,
        }
    }
}

impl Identity for Prime256v1Identity {
    fn sender(&self) -> Result<Principal, String> {
        Ok(Principal::self_authenticating(
            self.der_encoded_public_key.as_ref(),
        ))
    }

    fn public_key(&self) -> Option<Vec<u8>> {
        Some(self.der_encoded_public_key.as_ref().to_vec())
    }

    fn sign(&self, content: &EnvelopeContent) -> Result<Signature, String> {
        self.sign_arbitrary(&content.to_request_id().signable())
    }

    fn sign_delegation(&self, content: &Delegation) -> Result<Signature, String> {
        self.sign_arbitrary(&content.signable())
    }

    fn sign_arbitrary(&self, content: &[u8]) -> Result<Signature, String> {
        let ecdsa_sig: ecdsa::Signature = self
            .private_key
            .try_sign(content)
            .map_err(|err| format!("Cannot create prime256v1 signature: {err}"))?;
        let r = ecdsa_sig.r().as_ref().to_bytes();
        let s = ecdsa_sig.s().as_ref().to_bytes();
        let mut bytes = [0u8; 64];
        if r.len() > 32 || s.len() > 32 {
            return Err("Cannot create prime256v1 signature: malformed signature.".to_string());
        }
        bytes[(32 - r.len())..32].clone_from_slice(&r);
        bytes[32 + (32 - s.len())..].clone_from_slice(&s);
        let signature = Some(bytes.to_vec());
        let public_key = self.public_key();
        Ok(Signature {
            public_key,
            signature,
            delegations: None,
        })
    }
}

#[cfg(feature = "pem")]
#[cfg(test)]
mod test {
    use super::*;
    use candid::Encode;
    use p256::{
        ecdsa::{signature::Verifier, Signature},
        elliptic_curve::PrimeField,
        FieldBytes, Scalar,
    };

    // WRONG_CURVE_IDENTITY_FILE is generated from the following command:
    // > openssl ecparam -name secp160r2 -genkey
    // it uses the secp160r2 curve instead of prime256v1 and should
    // therefore be rejected by Prime256v1Identity when loading an identity
    const WRONG_CURVE_IDENTITY_FILE: &str = "\
-----BEGIN EC PARAMETERS-----
BgUrgQQAHg==
-----END EC PARAMETERS-----
-----BEGIN EC PRIVATE KEY-----
MFACAQEEFI9cF6zXxMKhtjn1gBD7AHPbzehfoAcGBSuBBAAeoSwDKgAEh5NXszgR
oGSXVWaGxcQhQWlFG4pbnOG+93xXzfRD7eKWOdmun2bKxQ==
-----END EC PRIVATE KEY-----
";

    // WRONG_CURVE_IDENTITY_FILE_NO_PARAMS is generated from the following command:
    // > openssl ecparam -name secp160r2 -genkey -noout
    // it uses the secp160r2 curve instead of prime256v1 and should
    // therefore be rejected by Prime256v1Identity when loading an identity
    const WRONG_CURVE_IDENTITY_FILE_NO_PARAMS: &str = "\
-----BEGIN EC PRIVATE KEY-----
MFACAQEEFI9cF6zXxMKhtjn1gBD7AHPbzehfoAcGBSuBBAAeoSwDKgAEh5NXszgR
oGSXVWaGxcQhQWlFG4pbnOG+93xXzfRD7eKWOdmun2bKxQ==
-----END EC PRIVATE KEY-----
";

    // IDENTITY_FILE was generated from the the following commands:
    // > openssl ecparam -name prime256v1 -genkey -noout -out identity.pem
    // > cat identity.pem
    const IDENTITY_FILE: &str = "\
-----BEGIN EC PRIVATE KEY-----
MHcCAQEEIL1ybmbwx+uKYsscOZcv71MmKhrNqfPP0ke1unET5AY4oAoGCCqGSM49
AwEHoUQDQgAEUbbZV4NerZTPWfbQ749/GNLu8TaH8BUS/I7/+ipsu+MPywfnBFIZ
Sks4xGbA/ZbazsrMl4v446U5UIVxCGGaKw==
-----END EC PRIVATE KEY-----
";

    // DER_ENCODED_PUBLIC_KEY was generated from the the following commands:
    // > openssl ec -in identity.pem -pubout -outform DER -out public.der
    // > hexdump -ve '1/1 "%.2x"' public.der
    const DER_ENCODED_PUBLIC_KEY: &str = "3059301306072a8648ce3d020106082a8648ce3d0301070342000451b6d957835ead94cf59f6d0ef8f7f18d2eef13687f01512fc8efffa2a6cbbe30fcb07e70452194a4b38c466c0fd96dacecacc978bf8e3a53950857108619a2b";

    #[test]
    #[should_panic(expected = "UnsupportedKeyCurve")]
    fn test_prime256v1_reject_wrong_curve() {
        Prime256v1Identity::from_pem(WRONG_CURVE_IDENTITY_FILE.as_bytes()).unwrap();
    }

    #[test]
    #[should_panic(expected = "KeyMalformed")]
    fn test_prime256v1_reject_wrong_curve_no_id() {
        Prime256v1Identity::from_pem(WRONG_CURVE_IDENTITY_FILE_NO_PARAMS.as_bytes()).unwrap();
    }

    #[test]
    fn test_prime256v1_public_key() {
        // Create a prime256v1 identity from a PEM file.
        let identity = Prime256v1Identity::from_pem(IDENTITY_FILE.as_bytes())
            .expect("Cannot create prime256v1 identity from PEM file.");

        // Assert the DER-encoded prime256v1 public key matches what we would expect.
        assert!(DER_ENCODED_PUBLIC_KEY == hex::encode(identity.der_encoded_public_key));
    }

    #[test]
    fn test_prime256v1_signature() {
        // Create a prime256v1 identity from a PEM file.
        let identity = Prime256v1Identity::from_pem(IDENTITY_FILE.as_bytes())
            .expect("Cannot create prime256v1 identity from PEM file.");

        // Create a prime256v1 signature for a hello-world canister.
        let message = EnvelopeContent::Call {
            nonce: None,
            ingress_expiry: 0,
            sender: identity.sender().unwrap(),
            canister_id: "bkyz2-fmaaa-aaaaa-qaaaq-cai".parse().unwrap(),
            method_name: "greet".to_string(),
            arg: Encode!(&"world").unwrap(),
        };
        let signature = identity
            .sign(&message)
            .expect("Cannot create prime256v1 signature.")
            .signature
            .expect("Cannot find prime256v1 signature bytes.");

        // Import the prime256v1 signature.
        let r: Scalar = Option::from(Scalar::from_repr(*FieldBytes::from_slice(
            &signature[0..32],
        )))
        .expect("Cannot extract r component from prime256v1 signature bytes.");
        let s: Scalar = Option::from(Scalar::from_repr(*FieldBytes::from_slice(&signature[32..])))
            .expect("Cannot extract s component from prime256v1 signature bytes.");
        let ecdsa_sig = Signature::from_scalars(r, s)
            .expect("Cannot create prime256v1 signature from r and s components.");

        // Assert the prime256v1 signature is valid.
        identity
            ._public_key
            .verify(&message.to_request_id().signable(), &ecdsa_sig)
            .expect("Cannot verify prime256v1 signature.");
    }
}



================================================
FILE: ic-agent/src/identity/secp256k1.rs
================================================
use crate::{agent::EnvelopeContent, export::Principal, Identity, Signature};

#[cfg(feature = "pem")]
use crate::identity::error::PemError;

use k256::{
    ecdsa::{self, signature::Signer, SigningKey, VerifyingKey},
    pkcs8::{Document, EncodePublicKey},
    SecretKey,
};
#[cfg(feature = "pem")]
use std::{fs::File, io, path::Path};

use super::Delegation;

/// A cryptographic identity based on the Secp256k1 elliptic curve.
///
/// The caller will be represented via [`Principal::self_authenticating`], which contains the SHA-224 hash of the public key.
#[derive(Clone, Debug)]
pub struct Secp256k1Identity {
    private_key: SigningKey,
    _public_key: VerifyingKey,
    der_encoded_public_key: Document,
}

impl Secp256k1Identity {
    /// Creates an identity from a PEM file. Shorthand for calling `from_pem` with `std::fs::read`.
    #[cfg(feature = "pem")]
    pub fn from_pem_file<P: AsRef<Path>>(file_path: P) -> Result<Self, PemError> {
        Self::from_pem(File::open(file_path)?)
    }

    /// Creates an identity from a PEM certificate.
    #[cfg(feature = "pem")]
    pub fn from_pem<R: io::Read>(pem_reader: R) -> Result<Self, PemError> {
        use sec1::{pem::PemLabel, EcPrivateKey};

        const EC_PARAMETERS: &str = "EC PARAMETERS";
        const SECP256K1: &[u8] = b"\x06\x05\x2b\x81\x04\x00\x0a";

        let contents = pem_reader.bytes().collect::<Result<Vec<u8>, io::Error>>()?;

        for pem in pem::parse_many(contents)? {
            if pem.tag() == EC_PARAMETERS && pem.contents() != SECP256K1 {
                return Err(PemError::UnsupportedKeyCurve(
                    "secp256k1".to_string(),
                    pem.contents().to_vec(),
                ));
            }

            if pem.tag() != EcPrivateKey::PEM_LABEL {
                continue;
            }
            let private_key =
                SecretKey::from_sec1_der(pem.contents()).map_err(|_| pkcs8::Error::KeyMalformed)?;
            return Ok(Self::from_private_key(private_key));
        }
        Err(pem::PemError::MissingData.into())
    }

    /// Creates an identity from a private key.
    pub fn from_private_key(private_key: SecretKey) -> Self {
        let public_key = private_key.public_key();
        let der_encoded_public_key = public_key
            .to_public_key_der()
            .expect("Cannot DER encode secp256k1 public key.");
        Self {
            private_key: private_key.into(),
            _public_key: public_key.into(),
            der_encoded_public_key,
        }
    }
}

impl Identity for Secp256k1Identity {
    fn sender(&self) -> Result<Principal, String> {
        Ok(Principal::self_authenticating(
            self.der_encoded_public_key.as_ref(),
        ))
    }

    fn public_key(&self) -> Option<Vec<u8>> {
        Some(self.der_encoded_public_key.as_ref().to_vec())
    }

    fn sign(&self, content: &EnvelopeContent) -> Result<Signature, String> {
        self.sign_arbitrary(&content.to_request_id().signable())
    }

    fn sign_delegation(&self, content: &Delegation) -> Result<Signature, String> {
        self.sign_arbitrary(&content.signable())
    }

    fn sign_arbitrary(&self, content: &[u8]) -> Result<Signature, String> {
        let ecdsa_sig: ecdsa::Signature = self
            .private_key
            .try_sign(content)
            .map_err(|err| format!("Cannot create secp256k1 signature: {err}"))?;
        let r = ecdsa_sig.r().as_ref().to_bytes();
        let s = ecdsa_sig.s().as_ref().to_bytes();
        let mut bytes = [0u8; 64];
        if r.len() > 32 || s.len() > 32 {
            return Err("Cannot create secp256k1 signature: malformed signature.".to_string());
        }
        bytes[(32 - r.len())..32].clone_from_slice(&r);
        bytes[32 + (32 - s.len())..].clone_from_slice(&s);
        let signature = Some(bytes.to_vec());
        let public_key = self.public_key();
        Ok(Signature {
            public_key,
            signature,
            delegations: None,
        })
    }
}

#[cfg(feature = "pem")]
#[cfg(test)]
mod test {
    use super::*;
    use candid::Encode;
    use k256::{
        ecdsa::{signature::Verifier, Signature},
        elliptic_curve::PrimeField,
        FieldBytes, Scalar,
    };

    // WRONG_CURVE_IDENTITY_FILE is generated from the following command:
    // > openssl ecparam -name secp160r2 -genkey
    // it uses hte secp160r2 curve instead of secp256k1 and should
    // therefore be rejected by Secp256k1Identity when loading an identity
    const WRONG_CURVE_IDENTITY_FILE: &str = "-----BEGIN EC PARAMETERS-----
BgUrgQQAHg==
-----END EC PARAMETERS-----
-----BEGIN EC PRIVATE KEY-----
MFACAQEEFI9cF6zXxMKhtjn1gBD7AHPbzehfoAcGBSuBBAAeoSwDKgAEh5NXszgR
oGSXVWaGxcQhQWlFG4pbnOG+93xXzfRD7eKWOdmun2bKxQ==
-----END EC PRIVATE KEY-----
";

    // WRONG_CURVE_IDENTITY_FILE_NO_PARAMS is generated from the following command:
    // > openssl ecparam -name secp160r2 -genkey -noout
    // it uses hte secp160r2 curve instead of secp256k1 and should
    // therefore be rejected by Secp256k1Identity when loading an identity
    const WRONG_CURVE_IDENTITY_FILE_NO_PARAMS: &str = "-----BEGIN EC PRIVATE KEY-----
MFACAQEEFI9cF6zXxMKhtjn1gBD7AHPbzehfoAcGBSuBBAAeoSwDKgAEh5NXszgR
oGSXVWaGxcQhQWlFG4pbnOG+93xXzfRD7eKWOdmun2bKxQ==
-----END EC PRIVATE KEY-----
";

    // IDENTITY_FILE was generated from the the following commands:
    // > openssl ecparam -name secp256k1 -genkey -noout -out identity.pem
    // > cat identity.pem
    const IDENTITY_FILE: &str = "-----BEGIN EC PARAMETERS-----
BgUrgQQACg==
-----END EC PARAMETERS-----
-----BEGIN EC PRIVATE KEY-----
MHQCAQEEIAgy7nZEcVHkQ4Z1Kdqby8SwyAiyKDQmtbEHTIM+WNeBoAcGBSuBBAAK
oUQDQgAEgO87rJ1ozzdMvJyZQ+GABDqUxGLvgnAnTlcInV3NuhuPv4O3VGzMGzeB
N3d26cRxD99TPtm8uo2OuzKhSiq6EQ==
-----END EC PRIVATE KEY-----
";

    // DER_ENCODED_PUBLIC_KEY was generated from the the following commands:
    // > openssl ec -in identity.pem -pubout -outform DER -out public.der
    // > hexdump -ve '1/1 "%.2x"' public.der
    const DER_ENCODED_PUBLIC_KEY: &str = "3056301006072a8648ce3d020106052b8104000a0342000480ef3bac9d68cf374cbc9c9943e180043a94c462ef8270274e57089d5dcdba1b8fbf83b7546ccc1b3781377776e9c4710fdf533ed9bcba8d8ebb32a14a2aba11";

    #[test]
    #[should_panic(expected = "UnsupportedKeyCurve")]
    fn test_secp256k1_reject_wrong_curve() {
        Secp256k1Identity::from_pem(WRONG_CURVE_IDENTITY_FILE.as_bytes()).unwrap();
    }

    #[test]
    #[should_panic(expected = "KeyMalformed")]
    fn test_secp256k1_reject_wrong_curve_no_id() {
        Secp256k1Identity::from_pem(WRONG_CURVE_IDENTITY_FILE_NO_PARAMS.as_bytes()).unwrap();
    }

    #[test]
    fn test_secp256k1_public_key() {
        // Create a secp256k1 identity from a PEM file.
        let identity = Secp256k1Identity::from_pem(IDENTITY_FILE.as_bytes())
            .expect("Cannot create secp256k1 identity from PEM file.");

        // Assert the DER-encoded secp256k1 public key matches what we would expect.
        assert!(DER_ENCODED_PUBLIC_KEY == hex::encode(identity.der_encoded_public_key));
    }

    #[test]
    fn test_secp256k1_signature() {
        // Create a secp256k1 identity from a PEM file.
        let identity = Secp256k1Identity::from_pem(IDENTITY_FILE.as_bytes())
            .expect("Cannot create secp256k1 identity from PEM file.");

        // Create a secp256k1 signature for a hello-world canister.
        let message = EnvelopeContent::Call {
            nonce: None,
            ingress_expiry: 0,
            sender: identity.sender().unwrap(),
            canister_id: "bkyz2-fmaaa-aaaaa-qaaaq-cai".parse().unwrap(),
            method_name: "greet".to_string(),
            arg: Encode!(&"world").unwrap(),
        };
        let signature = identity
            .sign(&message)
            .expect("Cannot create secp256k1 signature.")
            .signature
            .expect("Cannot find secp256k1 signature bytes.");

        // Import the secp256k1 signature into OpenSSL.
        let r: Scalar = Option::from(Scalar::from_repr(*FieldBytes::from_slice(
            &signature[0..32],
        )))
        .expect("Cannot extract r component from secp256k1 signature bytes.");
        let s: Scalar = Option::from(Scalar::from_repr(*FieldBytes::from_slice(&signature[32..])))
            .expect("Cannot extract s component from secp256k1 signature bytes.");
        let ecdsa_sig = Signature::from_scalars(r, s)
            .expect("Cannot create secp256k1 signature from r and s components.");

        // Assert the secp256k1 signature is valid.
        identity
            ._public_key
            .verify(&message.to_request_id().signable(), &ecdsa_sig)
            .expect("Cannot verify secp256k1 signature.");
    }
}



================================================
FILE: ic-certification/README.md
================================================
# IC Certification

This library has been moved to https://github.com/dfinity/response-verification.



================================================
FILE: ic-identity-hsm/README.md
================================================
`ic-identity-hsm` is a crate to manage identities related to HSM (Hardware Security Module), allowing users to sign Internet Computer messages with their hardware key. Also supports SoftHSM.

## Useful links

- [Documentation (master)](https://agent-rust.netlify.app/ic_identity_hsm)
- [Documentation (published)](https://docs.rs/ic_identity_hsm)



================================================
FILE: ic-identity-hsm/Cargo.toml
================================================
[package]
name = "ic-identity-hsm"
version.workspace = true
authors.workspace = true
edition.workspace = true
repository.workspace = true
license.workspace = true
rust-version.workspace = true
description = "Identity implementation for HSM for the ic-agent package."
homepage = "https://docs.rs/ic-identity-hsm"
documentation = "https://docs.rs/ic-identity-hsm"
readme = "README.md"
categories = ["api-bindings", "data-structures", "no-std"]
keywords = ["internet-computer", "agent", "utility", "icp", "dfinity"]
include = ["src", "Cargo.toml", "../LICENSE", "README.md"]

[dependencies]
hex = { workspace = true }
ic-agent = { workspace = true, default-features = false }
pkcs11 = "0.5.0"
sha2 = { workspace = true }
simple_asn1 = "0.6.0"
thiserror = { workspace = true }

[dev-dependencies]
ic-agent = { workspace = true }



================================================
FILE: ic-identity-hsm/src/hsm.rs
================================================
use ic_agent::{
    agent::EnvelopeContent, export::Principal, identity::Delegation, Identity, Signature,
};

use pkcs11::{
    types::{
        CKA_CLASS, CKA_EC_PARAMS, CKA_EC_POINT, CKA_ID, CKA_KEY_TYPE, CKF_LOGIN_REQUIRED,
        CKF_SERIAL_SESSION, CKK_ECDSA, CKM_ECDSA, CKO_PRIVATE_KEY, CKO_PUBLIC_KEY, CKU_USER,
        CK_ATTRIBUTE, CK_ATTRIBUTE_TYPE, CK_KEY_TYPE, CK_MECHANISM, CK_OBJECT_CLASS,
        CK_OBJECT_HANDLE, CK_SESSION_HANDLE, CK_SLOT_ID,
    },
    Ctx,
};
use sha2::{
    digest::{generic_array::GenericArray, OutputSize
